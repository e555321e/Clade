"""é€šç”¨æµå¼è°ƒç”¨åŠ©æ‰‹ - æä¾›å¸¦å¿ƒè·³æ£€æµ‹çš„ LLM è°ƒç”¨å°è£…

æ‰€æœ‰ LLM æ¨¡å—éƒ½åº”ä½¿ç”¨æ­¤æ¨¡å—æ¥ç¡®ä¿ï¼š
1. æµå¼ä¼ è¾“å¿ƒè·³æ£€æµ‹ï¼ˆé˜²æ­¢å‰ç«¯è¶…æ—¶ï¼‰
2. æ™ºèƒ½ç©ºé—²è¶…æ—¶ï¼ˆåªæœ‰çœŸæ­£å¡ä½æ‰è¶…æ—¶ï¼‰
3. ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—
"""
from __future__ import annotations

import asyncio
import logging
from typing import Any, Callable

logger = logging.getLogger(__name__)


async def stream_call_with_heartbeat(
    router: Any,
    capability: str,
    messages: list[dict[str, str]],
    response_format: dict | None = None,
    task_name: str = "AIå¤„ç†",
    idle_timeout: float = 60.0,
    heartbeat_interval: float = 1.5,
    event_callback: Callable[[str, str, str], None] | None = None,
) -> str:
    """é€šç”¨æµå¼è°ƒç”¨ - å¸¦æ™ºèƒ½å¿ƒè·³å’Œç©ºé—²è¶…æ—¶
    
    æ™ºèƒ½è¶…æ—¶æœºåˆ¶ï¼š
    - åªè¦æŒç»­æ”¶åˆ° chunkï¼Œå°±ä¸ä¼šè§¦å‘è¶…æ—¶
    - åªæœ‰åœ¨ idle_timeout ç§’å†…æ²¡æœ‰æ”¶åˆ°ä»»ä½• chunk æ‰è§¦å‘è¶…æ—¶
    - è¿™æ ·å³ä½¿ AI æ€è€ƒ+è¾“å‡ºå¾ˆé•¿æ—¶é—´ï¼Œåªè¦åœ¨è¾“å‡ºå°±ä¸ä¼šè¶…æ—¶
    
    Args:
        router: ModelRouter å®ä¾‹
        capability: AI èƒ½åŠ›åç§°
        messages: æ¶ˆæ¯åˆ—è¡¨
        response_format: å“åº”æ ¼å¼ï¼ˆå¦‚ {"type": "json_object"}ï¼‰
        task_name: ä»»åŠ¡åç§°ï¼ˆç”¨äºå¿ƒè·³æ¶ˆæ¯å’Œæ—¥å¿—ï¼‰
        idle_timeout: ç©ºé—²è¶…æ—¶ç§’æ•°ï¼ˆä¸¤ä¸ªchunkä¹‹é—´çš„æœ€å¤§é—´éš”ï¼‰
        heartbeat_interval: å¿ƒè·³å‘é€é—´éš”ç§’æ•°
        event_callback: äº‹ä»¶å›è°ƒå‡½æ•° (event_type, message, category)
        
    Returns:
        å®Œæ•´çš„ AI å“åº”å†…å®¹
        
    Raises:
        asyncio.TimeoutError: ç©ºé—²è¶…æ—¶
        Exception: å…¶ä»–è°ƒç”¨é”™è¯¯
    """
    chunks: list[str] = []
    chunk_count = 0
    last_heartbeat_time = asyncio.get_event_loop().time()
    last_chunk_time = asyncio.get_event_loop().time()
    
    def emit_event(event_type: str, message: str, **kwargs):
        """å‘é€äº‹ä»¶ï¼ˆå¦‚æœæœ‰å›è°ƒï¼‰"""
        if event_callback:
            try:
                event_callback(event_type, message, "AI")
            except Exception as e:
                logger.debug(f"[æµå¼å¿ƒè·³] äº‹ä»¶å›è°ƒå¤±è´¥: {e}")
    
    async def iter_with_idle_timeout():
        """å¸¦ç©ºé—²è¶…æ—¶çš„è¿­ä»£å™¨åŒ…è£…"""
        nonlocal last_chunk_time
        
        async for item in router.astream_capability(
            capability=capability,
            messages=messages,
            response_format=response_format,
        ):
            last_chunk_time = asyncio.get_event_loop().time()
            yield item
    
    try:
        stream_iter = iter_with_idle_timeout()
        
        while True:
            try:
                # è®¡ç®—å‰©ä½™ç©ºé—²è¶…æ—¶æ—¶é—´
                elapsed_idle = asyncio.get_event_loop().time() - last_chunk_time
                remaining_timeout = max(1.0, idle_timeout - elapsed_idle)
                
                # å°è¯•è·å–ä¸‹ä¸€ä¸ª itemï¼Œå¸¦è¶…æ—¶ä¿æŠ¤
                item = await asyncio.wait_for(
                    stream_iter.__anext__(),
                    timeout=remaining_timeout
                )
                
            except StopAsyncIteration:
                break
            except asyncio.TimeoutError:
                emit_event(
                    "ai_idle_timeout",
                    f"â° {task_name} ç©ºé—²è¶…æ—¶ ({idle_timeout:.0f}sæ— è¾“å‡º)"
                )
                logger.warning(
                    f"[æµå¼è°ƒç”¨] {task_name} ç©ºé—²è¶…æ—¶ "
                    f"(å·²æ”¶åˆ°{chunk_count}ä¸ªchunks, ç©ºé—²{idle_timeout}ç§’)"
                )
                # å¦‚æœå·²ç»æ”¶åˆ°ä¸€äº›å†…å®¹ï¼Œå°è¯•è¿”å›
                if chunks:
                    logger.info(f"[æµå¼è°ƒç”¨] {task_name} ä½¿ç”¨å·²æ¥æ”¶çš„éƒ¨åˆ†å†…å®¹ ({len(''.join(chunks))} chars)")
                    break
                raise asyncio.TimeoutError(f"ç©ºé—²è¶…æ—¶: {idle_timeout}ç§’å†…æ— è¾“å‡º")
            
            # å¤„ç†çŠ¶æ€äº‹ä»¶
            if isinstance(item, dict):
                state = item.get("state", "")
                if state == "connected":
                    emit_event("ai_stream_start", f"ğŸ”— {task_name} å·²è¿æ¥")
                elif state == "receiving":
                    emit_event("ai_stream_receiving", f"ğŸ“¥ {task_name} æ­£åœ¨æ¥æ”¶...")
                elif state == "completed":
                    emit_event("ai_stream_complete", f"âœ… {task_name} æ¥æ”¶å®Œæˆ")
                elif item.get("type") == "error":
                    error_msg = item.get("message", "æœªçŸ¥é”™è¯¯")
                    emit_event("ai_stream_error", f"âŒ {task_name} é”™è¯¯: {error_msg}")
            else:
                # è¿™æ˜¯æ–‡æœ¬ chunk
                chunks.append(str(item))
                chunk_count += 1
                
                # å‘é€ chunk å¿ƒè·³ï¼ˆé™åˆ¶é¢‘ç‡ï¼‰
                current_time = asyncio.get_event_loop().time()
                if current_time - last_heartbeat_time >= heartbeat_interval:
                    emit_event(
                        "ai_chunk_heartbeat",
                        f"ğŸ’“ {task_name} è¾“å‡ºä¸­ ({chunk_count} chunks)"
                    )
                    last_heartbeat_time = current_time
        
        full_content = "".join(chunks)
        logger.debug(f"[æµå¼è°ƒç”¨] {task_name} å®Œæˆï¼Œå…± {chunk_count} chunks, æ€»é•¿åº¦ {len(full_content)}")
        return full_content
        
    except Exception as e:
        logger.error(f"[æµå¼è°ƒç”¨] {task_name} å¤±è´¥: {e}")
        emit_event("ai_stream_error", f"âŒ {task_name} æµå¼è°ƒç”¨å¤±è´¥: {e}")
        raise


async def stream_invoke_with_heartbeat(
    router: Any,
    capability: str,
    payload: dict,
    task_name: str = "AIå¤„ç†",
    idle_timeout: float = 90.0,
    heartbeat_interval: float = 2.0,
    event_callback: Callable[[str, str, str], None] | None = None,
) -> dict:
    """æµå¼è°ƒç”¨çš„å¿ƒè·³å°è£… - ä½¿ç”¨ astream (æ¨è)
    
    æ™ºèƒ½è¶…æ—¶æœºåˆ¶ï¼š
    - åªè¦æŒç»­æ”¶åˆ° chunkï¼Œå°±ä¸ä¼šè§¦å‘è¶…æ—¶
    - åªæœ‰åœ¨ idle_timeout ç§’å†…æ²¡æœ‰æ”¶åˆ°ä»»ä½• chunk æ‰è§¦å‘è¶…æ—¶
    - è¿™æ ·å³ä½¿ AI æ€è€ƒ+è¾“å‡ºå¾ˆé•¿æ—¶é—´ï¼Œåªè¦åœ¨è¾“å‡ºå°±ä¸ä¼šè¶…æ—¶
    
    Args:
        router: ModelRouter å®ä¾‹
        capability: AI èƒ½åŠ›åç§°
        payload: è¯·æ±‚è½½è·ï¼ˆä¼šä¼ ç»™ prompt æ¨¡æ¿ï¼‰
        task_name: ä»»åŠ¡åç§°
        idle_timeout: ç©ºé—²è¶…æ—¶ç§’æ•°ï¼ˆä¸¤ä¸ªchunkä¹‹é—´çš„æœ€å¤§é—´éš”ï¼‰
        heartbeat_interval: å¿ƒè·³å‘é€é—´éš”ç§’æ•°
        event_callback: äº‹ä»¶å›è°ƒå‡½æ•°
        
    Returns:
        AI å“åº”å­—å…¸ {"content": parsed_json_or_text}
    """
    import json
    
    chunks: list[str] = []
    chunk_count = 0
    last_heartbeat_time = asyncio.get_event_loop().time()
    last_chunk_time = asyncio.get_event_loop().time()
    
    def emit_event(event_type: str, message: str):
        if event_callback:
            try:
                event_callback(event_type, message, "AI")
            except Exception:
                pass
    
    emit_event("ai_stream_start", f"ğŸš€ {task_name} å¼€å§‹æµå¼è¯·æ±‚")
    
    async def iter_with_idle_timeout():
        """å¸¦ç©ºé—²è¶…æ—¶çš„è¿­ä»£å™¨åŒ…è£…"""
        nonlocal last_chunk_time
        
        async for item in router.astream(capability, payload):
            last_chunk_time = asyncio.get_event_loop().time()
            yield item
    
    try:
        stream_iter = iter_with_idle_timeout()
        
        while True:
            try:
                # è®¡ç®—å‰©ä½™ç©ºé—²è¶…æ—¶æ—¶é—´
                elapsed_idle = asyncio.get_event_loop().time() - last_chunk_time
                remaining_timeout = max(1.0, idle_timeout - elapsed_idle)
                
                item = await asyncio.wait_for(
                    stream_iter.__anext__(),
                    timeout=remaining_timeout
                )
                
            except StopAsyncIteration:
                break
            except asyncio.TimeoutError:
                emit_event("ai_idle_timeout", f"â° {task_name} ç©ºé—²è¶…æ—¶ ({idle_timeout:.0f}sæ— è¾“å‡º)")
                logger.warning(f"[æµå¼è°ƒç”¨] {task_name} ç©ºé—²è¶…æ—¶ (å·²æ”¶åˆ°{chunk_count}ä¸ªchunks, ç©ºé—²{idle_timeout}ç§’)")
                if chunks:
                    logger.info(f"[æµå¼è°ƒç”¨] {task_name} ä½¿ç”¨å·²æ¥æ”¶çš„éƒ¨åˆ†å†…å®¹ ({len(''.join(chunks))} chars)")
                    break
                raise asyncio.TimeoutError(f"ç©ºé—²è¶…æ—¶: {idle_timeout}ç§’å†…æ— è¾“å‡º")
            
            # å¤„ç†çŠ¶æ€äº‹ä»¶
            if isinstance(item, dict):
                state = item.get("state", "")
                if state == "connected":
                    emit_event("ai_stream_connected", f"ğŸ”— {task_name} å·²è¿æ¥")
                elif state == "receiving":
                    emit_event("ai_stream_receiving", f"ğŸ“¥ {task_name} æ­£åœ¨æ¥æ”¶...")
                elif state == "completed":
                    emit_event("ai_stream_complete", f"âœ… {task_name} æ¥æ”¶å®Œæˆ")
                elif item.get("type") == "error":
                    error_msg = item.get("message", "æœªçŸ¥é”™è¯¯")
                    emit_event("ai_stream_error", f"âŒ {task_name} é”™è¯¯: {error_msg}")
                    raise Exception(f"æµå¼é”™è¯¯: {error_msg}")
            else:
                # è¿™æ˜¯æ–‡æœ¬ chunk
                chunks.append(str(item))
                chunk_count += 1
                
                # å‘é€ chunk å¿ƒè·³ï¼ˆé™åˆ¶é¢‘ç‡ï¼‰
                current_time = asyncio.get_event_loop().time()
                if current_time - last_heartbeat_time >= heartbeat_interval:
                    emit_event("ai_chunk_heartbeat", f"ğŸ’“ {task_name} è¾“å‡ºä¸­ ({chunk_count} chunks)")
                    last_heartbeat_time = current_time
        
        full_content = "".join(chunks)
        logger.debug(f"[æµå¼è°ƒç”¨] {task_name} å®Œæˆï¼Œå…± {chunk_count} chunks, æ€»é•¿åº¦ {len(full_content)}")
        
        # å°è¯•è§£æ JSON
        try:
            parsed = json.loads(full_content)
            return {"content": parsed}
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯ JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
            return {"content": full_content}
        
    except Exception as e:
        logger.error(f"[æµå¼è°ƒç”¨] {task_name} å¤±è´¥: {e}")
        emit_event("ai_stream_error", f"âŒ {task_name} æµå¼è°ƒç”¨å¤±è´¥: {e}")
        raise


async def invoke_with_heartbeat(
    router: Any,
    capability: str,
    payload: dict,
    task_name: str = "AIå¤„ç†",
    timeout: float = 60.0,
    heartbeat_interval: float = 2.0,
    event_callback: Callable[[str, str, str], None] | None = None,
) -> dict:
    """éæµå¼è°ƒç”¨çš„å¿ƒè·³å°è£… - ä½¿ç”¨ ainvoke (ä¸æ¨èï¼Œå®¹æ˜“è¶…æ—¶)
    
    âš ï¸ å»ºè®®ä½¿ç”¨ stream_invoke_with_heartbeat æ›¿ä»£ï¼Œå®ƒæœ‰æ™ºèƒ½ç©ºé—²è¶…æ—¶æœºåˆ¶
    
    å¯¹äºä¸æ”¯æŒæµå¼çš„åœºæ™¯ï¼Œé€šè¿‡å®šæ—¶å¿ƒè·³æ¥ä¿æŒè¿æ¥æ´»è·ƒã€‚
    
    Args:
        router: ModelRouter å®ä¾‹
        capability: AI èƒ½åŠ›åç§°
        payload: è¯·æ±‚è½½è·
        task_name: ä»»åŠ¡åç§°
        timeout: æ€»è¶…æ—¶ç§’æ•°ï¼ˆç¡¬è¶…æ—¶ï¼Œä¸ç®¡ AI æ˜¯å¦åœ¨è¾“å‡ºï¼‰
        heartbeat_interval: å¿ƒè·³å‘é€é—´éš”ç§’æ•°
        event_callback: äº‹ä»¶å›è°ƒå‡½æ•°
        
    Returns:
        AI å“åº”å­—å…¸
    """
    def emit_event(event_type: str, message: str):
        if event_callback:
            try:
                event_callback(event_type, message, "AI")
            except Exception:
                pass
    
    emit_event("ai_request_start", f"ğŸš€ {task_name} å¼€å§‹è¯·æ±‚")
    
    # åˆ›å»ºå¿ƒè·³ä»»åŠ¡
    heartbeat_task = None
    heartbeat_count = 0
    
    async def send_heartbeats():
        nonlocal heartbeat_count
        while True:
            await asyncio.sleep(heartbeat_interval)
            heartbeat_count += 1
            emit_event("ai_heartbeat", f"ğŸ’“ {task_name} ç­‰å¾…ä¸­ ({heartbeat_count * heartbeat_interval:.0f}s)")
    
    try:
        # å¯åŠ¨å¿ƒè·³
        heartbeat_task = asyncio.create_task(send_heartbeats())
        
        # æ‰§è¡Œè¯·æ±‚
        response = await asyncio.wait_for(
            router.ainvoke(capability, payload),
            timeout=timeout
        )
        
        emit_event("ai_request_complete", f"âœ… {task_name} å®Œæˆ")
        return response
        
    except asyncio.TimeoutError:
        emit_event("ai_request_timeout", f"â° {task_name} è¶…æ—¶ ({timeout}s)")
        logger.error(f"[AIè¯·æ±‚] {task_name} è¶…æ—¶ ({timeout}s)")
        raise
    except Exception as e:
        emit_event("ai_request_error", f"âŒ {task_name} å¤±è´¥: {e}")
        logger.error(f"[AIè¯·æ±‚] {task_name} å¤±è´¥: {e}")
        raise
    finally:
        if heartbeat_task:
            heartbeat_task.cancel()
            try:
                await heartbeat_task
            except asyncio.CancelledError:
                pass


async def acall_with_heartbeat(
    router: Any,
    capability: str,
    messages: list[dict[str, str]],
    response_format: dict | None = None,
    task_name: str = "AIå¤„ç†",
    timeout: float = 60.0,
    heartbeat_interval: float = 2.0,
    event_callback: Callable[[str, str, str], None] | None = None,
) -> str:
    """éæµå¼ acall_capability çš„å¿ƒè·³å°è£…
    
    Args:
        router: ModelRouter å®ä¾‹
        capability: AI èƒ½åŠ›åç§°
        messages: æ¶ˆæ¯åˆ—è¡¨
        response_format: å“åº”æ ¼å¼
        task_name: ä»»åŠ¡åç§°
        timeout: æ€»è¶…æ—¶ç§’æ•°
        heartbeat_interval: å¿ƒè·³å‘é€é—´éš”ç§’æ•°
        event_callback: äº‹ä»¶å›è°ƒå‡½æ•°
        
    Returns:
        AI å“åº”å†…å®¹
    """
    def emit_event(event_type: str, message: str):
        if event_callback:
            try:
                event_callback(event_type, message, "AI")
            except Exception:
                pass
    
    emit_event("ai_request_start", f"ğŸš€ {task_name} å¼€å§‹è¯·æ±‚")
    
    heartbeat_task = None
    heartbeat_count = 0
    
    async def send_heartbeats():
        nonlocal heartbeat_count
        while True:
            await asyncio.sleep(heartbeat_interval)
            heartbeat_count += 1
            emit_event("ai_heartbeat", f"ğŸ’“ {task_name} ç­‰å¾…ä¸­ ({heartbeat_count * heartbeat_interval:.0f}s)")
    
    try:
        heartbeat_task = asyncio.create_task(send_heartbeats())
        
        response = await asyncio.wait_for(
            router.acall_capability(capability, messages, response_format),
            timeout=timeout
        )
        
        emit_event("ai_request_complete", f"âœ… {task_name} å®Œæˆ")
        return response
        
    except asyncio.TimeoutError:
        emit_event("ai_request_timeout", f"â° {task_name} è¶…æ—¶ ({timeout}s)")
        logger.error(f"[AIè¯·æ±‚] {task_name} è¶…æ—¶ ({timeout}s)")
        raise
    except Exception as e:
        emit_event("ai_request_error", f"âŒ {task_name} å¤±è´¥: {e}")
        logger.error(f"[AIè¯·æ±‚] {task_name} å¤±è´¥: {e}")
        raise
    finally:
        if heartbeat_task:
            heartbeat_task.cancel()
            try:
                await heartbeat_task
            except asyncio.CancelledError:
                pass

