"""
âš ï¸âš ï¸âš ï¸ å·²å¼ƒç”¨ - Legacy API Routes âš ï¸âš ï¸âš ï¸

æ­¤æ–‡ä»¶ä¸ºå†å²é—ç•™çš„å·¨å‹è·¯ç”±æ¨¡å—ï¼Œå·²è¢«æ‹†åˆ†åˆ°ä»¥ä¸‹é¢†åŸŸæ¨¡å—ï¼š
- api/simulation.py: å›åˆæ¨æ¼”ã€å­˜æ¡£ç®¡ç†ã€å‹åŠ›é˜Ÿåˆ—
- api/species.py: ç‰©ç§ç®¡ç†ã€å¹²é¢„æ§åˆ¶ã€ç³»è°±æ ‘
- api/divine.py: èƒ½é‡ã€æˆå°±ã€æç¤ºã€æ‚äº¤ã€ç¥æ ¼ç³»ç»Ÿ
- api/ecosystem.py: é£Ÿç‰©ç½‘ã€ç”Ÿæ€å¥åº·åˆ†æ
- api/analytics.py: å¯¼å‡ºã€åœ°å›¾ã€é…ç½®ã€ç³»ç»Ÿè¯Šæ–­

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âŒ ç¦æ­¢å‘æ­¤æ–‡ä»¶æ·»åŠ æ–°ä»£ç  âŒ                                â”‚
â”‚  æ‰€æœ‰æ–°åŠŸèƒ½å¿…é¡»åœ¨ api/*.py é¢†åŸŸæ¨¡å—ä¸­å®ç°                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é€€åœºè®¡åˆ’ä¸æ—¶é—´çº¿ï¼š
==================
é˜¶æ®µ 1ï¼ˆå½“å‰ - v1.5ï¼‰ï¼š
  - USE_LEGACY_ROUTES=true æ—¶ä»å¯å¯ç”¨ï¼ˆé»˜è®¤ falseï¼‰
  - ä»…ç”¨äºç´§æ€¥å›é€€å’Œå›å½’æµ‹è¯•
  - ä¸æ¥å—æ–°åŠŸèƒ½ PR

é˜¶æ®µ 2ï¼ˆv1.5 - v2.0ï¼‰ï¼š
  - ç§»é™¤ USE_LEGACY_ROUTES å¼€å…³
  - æ­¤æ–‡ä»¶ä»…ä½œä¸ºå‚è€ƒä¿ç•™åœ¨ docs/ ç›®å½•
  - æ–°è·¯ç”±å®Œå…¨æ›¿ä»£

é˜¶æ®µ 3ï¼ˆv2.0+ï¼‰ï¼š
  - å½»åº•åˆ é™¤æ­¤æ–‡ä»¶

å…¼å®¹æ€§ä¿è¯ï¼š
-----------
- æ‰€æœ‰ç«¯ç‚¹ç­¾ååœ¨æ–°è·¯ç”±ä¸­ä¿æŒä¸€è‡´
- å“åº”æ ¼å¼ä¸å˜
- è¿ç§»åå‰ç«¯æ— éœ€ä¿®æ”¹

è¿ç§»æŒ‡å—ï¼š
---------
- æ‰€æœ‰æ–°å¼€å‘åº”ä½¿ç”¨ api/*.py çš„é¢†åŸŸæ¨¡å—
- é€šè¿‡ Depends() æ³¨å…¥æœåŠ¡ï¼Œä¸ä½¿ç”¨æ¨¡å—çº§å•ä¾‹
- ä½¿ç”¨ SessionManager è¿›è¡ŒçŠ¶æ€ç®¡ç†å’Œå¹¶å‘æ§åˆ¶
- ä½¿ç”¨ ConfigService è·å–é…ç½®

æœ€åæ›´æ–°ï¼š2025-01 (é‡æ„åä¿ç•™ä½œä¸ºå…¼å®¹å±‚)
"""

from __future__ import annotations

import logging
import warnings
from pathlib import Path
import uuid
import json
import httpx
import asyncio
from queue import Queue

from fastapi import APIRouter, HTTPException, BackgroundTasks, Request, Query
from fastapi.responses import JSONResponse, StreamingResponse

logger = logging.getLogger(__name__)

# å‘å‡ºå¼ƒç”¨è­¦å‘Šï¼ˆä»…åœ¨é¦–æ¬¡å¯¼å…¥æ—¶ï¼‰
warnings.warn(
    "api/routes.py å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨æ–°çš„é¢†åŸŸè·¯ç”±æ¨¡å— (api/simulation.py, api/species.py ç­‰)ã€‚"
    "è®¾ç½® USE_LEGACY_ROUTES=false ä»¥ä½¿ç”¨æ–°è·¯ç”±ï¼ˆé»˜è®¤ï¼‰ã€‚",
    DeprecationWarning,
    stacklevel=2
)
from sqlmodel import select

from ..core.config import get_settings
from ..core.ai_router_config import configure_model_router
from ..ai.prompts import PROMPT_TEMPLATES
from ..models.config import UIConfig, ProviderConfig, CapabilityRouteConfig
from ..repositories.genus_repository import genus_repository
from ..repositories.history_repository import history_repository
from ..repositories.environment_repository import environment_repository
from ..repositories.species_repository import species_repository
from ..schemas.requests import (
    PressureConfig, 
    QueueRequest, 
    SpeciesEditRequest, 
    TurnCommand, 
    WatchlistRequest,
    CreateSaveRequest,
    SaveGameRequest,
    LoadGameRequest,
    GenerateSpeciesRequest,
    GenerateSpeciesAdvancedRequest,
    NicheCompareRequest,
    ProtectSpeciesRequest,
    SuppressSpeciesRequest,
    IntroduceSpeciesRequest,
    SetSymbiosisRequest,
)
from ..schemas.responses import (
    ActionQueueStatus,
    ExportRecord,
    MapOverview,
    PressureTemplate,
    LineageNode,
    LineageTree,
    SpeciesDetail,
    TurnReport,
    NicheCompareResult,
    SpeciesList,
    SpeciesListItem,
    EcosystemHealthResponse,
    TrophicDistributionItem,
    ExtinctionRiskItem,
    InterventionResponse,
)
from ..services.species.background import BackgroundConfig, BackgroundSpeciesManager
from ..services.species.gene_flow import GeneFlowService
from ..services.species.genetic_distance import GeneticDistanceCalculator
from ..services.species.hybridization import HybridizationService
from ..services.analytics.critical_analyzer import CriticalAnalyzer
from ..services.analytics.exporter import ExportService
from ..services.system.embedding import EmbeddingService
from ..services.system.divine_progression import divine_progression_service
from ..services.analytics.focus_processor import FocusBatchProcessor
from ..services.geo.map_evolution import MapEvolutionService
from ..services.geo.map_manager import MapStateManager
from ..services.species.migration import MigrationAdvisor
from ..services.species.reproduction import ReproductionService
from ..services.species.habitat_manager import habitat_manager
from ..services.species.dispersal_engine import dispersal_engine  # çŸ©é˜µåŒ–æ‰©æ•£å¼•æ“
from ..ai.model_router import ModelConfig, ModelRouter
from ..services.species.niche import NicheAnalyzer
from ..services.system.pressure import PressureEscalationService
from ..services.analytics.report_builder import ReportBuilder
from ..services.analytics.report_builder_v2 import ReportBuilderV2
from ..services.species.speciation import SpeciationService
from ..services.species.tiering import SpeciesTieringService, TieringConfig
from ..services.system.save_manager import SaveManager
from ..services.species.species_generator import SpeciesGenerator
from ..services.analytics.ecosystem_health import EcosystemHealthService
from ..services.species.predation import PredationService
from ..services.analytics.embedding_integration import EmbeddingIntegrationService
from ..simulation.engine import SimulationEngine
from ..simulation.environment import EnvironmentSystem
from ..simulation.species import MortalityEngine


def _infer_ecological_role(species) -> str:
    """æ ¹æ®ç‰©ç§è¥å…»çº§æ¨æ–­ç”Ÿæ€è§’è‰²
    
    è¥å…»çº§åˆ’åˆ†è§„åˆ™ï¼š
    - T < 1.5: çº¯ç”Ÿäº§è€… (producer) - çº¯è‡ªå…»ç”Ÿç‰©
    - 1.5 â‰¤ T < 2.0: æ··åˆè¥å…» (mixotroph) - æ—¢èƒ½è‡ªå…»åˆèƒ½æ‘„é£Ÿ
    - 2.0 â‰¤ T < 2.8: è‰é£Ÿè€… (herbivore) - ä»¥ç”Ÿäº§è€…ä¸ºé£Ÿ
    - 2.8 â‰¤ T < 3.5: æ‚é£Ÿè€… (omnivore) - æ¤ç‰©å’ŒåŠ¨ç‰©éƒ½åƒ
    - T â‰¥ 3.5: è‚‰é£Ÿè€… (carnivore) - ä»¥å…¶ä»–åŠ¨ç‰©ä¸ºé£Ÿ
    
    ç‰¹æ®Šæƒ…å†µï¼šè…é£Ÿè€…(detritivore)é€šè¿‡ diet_type è¯†åˆ«
    """
    diet_type = getattr(species, 'diet_type', None)
    
    # ç‰¹æ®Šå¤„ç†ï¼šè…é£Ÿè€…ï¼ˆåˆ†è§£è€…ï¼‰
    if diet_type == "detritivore":
        return "decomposer"
    
    # ã€ä¿®å¤ã€‘ä¼˜å…ˆä½¿ç”¨ diet_type æ¥æ¨æ–­ç”Ÿæ€è§’è‰²ï¼ˆæ›´å¯é ï¼‰
    if diet_type == "autotroph":
        return "producer"
    elif diet_type == "herbivore":
        return "herbivore"
    elif diet_type == "carnivore":
        return "carnivore"
    elif diet_type == "omnivore":
        return "omnivore"
    
    # å›é€€æ–¹æ¡ˆï¼šåŸºäºè¥å…»çº§åˆ¤æ–­
    trophic = getattr(species, 'trophic_level', None)
    # ã€ä¿®å¤ã€‘ç¡®ä¿ trophic æ˜¯æœ‰æ•ˆçš„æ•°å­—
    if trophic is None or not isinstance(trophic, (int, float)):
        trophic = 2.0  # é»˜è®¤ä¸ºåˆçº§æ¶ˆè´¹è€…
    
    if trophic < 1.5:
        return "producer"
    elif trophic < 2.0:
        return "mixotroph"
    elif trophic < 2.8:
        return "herbivore"
    elif trophic < 3.5:
        return "omnivore"
    else:
        return "carnivore"


router = APIRouter(prefix="", tags=["simulation"])

settings = get_settings()
environment_system = EnvironmentSystem(settings.map_width, settings.map_height)
mortality_engine = MortalityEngine(settings.batch_rule_limit)
embedding_service = EmbeddingService(settings.embedding_provider)
model_router = ModelRouter(
    {
        # ========== æ ¸å¿ƒæ¨æ¼”èƒ½åŠ›ï¼ˆæœ¬åœ°æ¨¡æ¿ï¼‰==========
        "turn_report": ModelConfig(provider="local", model="template-narrator"),
        "focus_batch": ModelConfig(
            provider="local", 
            model="focus-template",
            extra_body={"response_format": {"type": "json_object"}}
        ),
        "critical_detail": ModelConfig(provider="local", model="critical-template"),
        
        # ========== ç‰©ç§åˆ†åŒ–èƒ½åŠ›ï¼ˆéœ€è¦ LLMï¼‰==========
        "speciation": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
        "speciation_batch": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
        "plant_speciation_batch": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
        
        # ========== æ‚äº¤èƒ½åŠ›ï¼ˆéœ€è¦ LLMï¼‰==========
        "hybridization": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
        "forced_hybridization": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
        
        # ========== ç‰©ç§ç”Ÿæˆèƒ½åŠ›ï¼ˆéœ€è¦ LLMï¼‰==========
        "species_generation": ModelConfig(
            provider="openai", 
            model=settings.speciation_model,
            extra_body={"response_format": {"type": "json_object"}}
        ),
    },
    base_url=settings.ai_base_url,
    api_key=settings.ai_api_key,
    timeout=settings.ai_request_timeout,
)
for capability, prompt in PROMPT_TEMPLATES.items():
    try:
        model_router.set_prompt(capability, prompt)
    except KeyError:
        # Prompt for capabilities not yet registered; skip
        pass
# ã€ä¼˜åŒ–ã€‘ä½¿ç”¨å¹¶è¡ŒåŒ–æŠ¥å‘Šç”Ÿæˆå™¨V2ï¼Œæå‡å¤§è§„æ¨¡ç‰©ç§åœºæ™¯ä¸‹çš„æ€§èƒ½
# å¯é€šè¿‡ç¯å¢ƒå˜é‡ USE_REPORT_V2=false å›é€€åˆ°æ—§ç‰ˆæœ¬
_use_report_v2 = settings.use_report_v2 if hasattr(settings, 'use_report_v2') else True
if _use_report_v2:
    report_builder = ReportBuilderV2(model_router, batch_size=settings.focus_batch_size)
    logger.info("[æŠ¥å‘Šç”Ÿæˆ] ä½¿ç”¨å¹¶è¡ŒåŒ–æŠ¥å‘Šç”Ÿæˆå™¨ V2")
else:
    report_builder = ReportBuilder(model_router)
    logger.info("[æŠ¥å‘Šç”Ÿæˆ] ä½¿ç”¨ä¼ ç»ŸæŠ¥å‘Šç”Ÿæˆå™¨ V1")
export_service = ExportService(settings.reports_dir, settings.exports_dir)
niche_analyzer = NicheAnalyzer(embedding_service, settings.global_carrying_capacity)
speciation_service = SpeciationService(model_router)
background_manager = BackgroundSpeciesManager(
    BackgroundConfig(
        population_threshold=settings.background_population_threshold,
        mass_extinction_threshold=settings.mass_extinction_threshold,
        promotion_quota=settings.background_promotion_quota,
    )
)
tiering_service = SpeciesTieringService(
    TieringConfig(
        critical_limit=settings.critical_species_limit,
        focus_batch_size=settings.focus_batch_size,
        focus_batch_limit=settings.focus_batch_limit,
        background_threshold=settings.background_population_threshold,
    )
)
focus_processor = FocusBatchProcessor(model_router, settings.focus_batch_size)
critical_analyzer = CriticalAnalyzer(model_router)
pressure_escalation = PressureEscalationService(
    window=settings.minor_pressure_window,
    threshold=settings.escalation_threshold,
    cooldown=settings.high_event_cooldown,
)
map_evolution = MapEvolutionService(settings.map_width, settings.map_height)
migration_advisor = MigrationAdvisor(pressure_migration_threshold=0.45, min_population=500)  # ä½¿ç”¨é»˜è®¤å‚æ•°
# primordial_mode=True è¡¨ç¤º28äº¿å¹´å‰çš„åŸå§‹åœ°è´¨çŠ¶æ€ï¼Œåœ°è¡¨æ— æ¤è¢«è¦†ç›–
# æ¤è¢«ä¼šéšç€æ¤ç‰©ç‰©ç§çš„ç¹è¡è€ŒåŠ¨æ€æ›´æ–°
map_manager = MapStateManager(settings.map_width, settings.map_height, primordial_mode=True)
reproduction_service = ReproductionService(
    global_carrying_capacity=settings.global_carrying_capacity,  # ä»é…ç½®è¯»å–
    turn_years=500_000,  # æ¯å›åˆ50ä¸‡å¹´
)
# ä¼ å…¥embedding_serviceä»¥æ”¯æŒæè¿°è¯­ä¹‰è·ç¦»è®¡ç®—
genetic_distance_calculator = GeneticDistanceCalculator(embedding_service=embedding_service)
hybridization_service = HybridizationService(genetic_distance_calculator, router=model_router)
gene_flow_service = GeneFlowService()
save_manager = SaveManager(settings.saves_dir, embedding_service=embedding_service)
species_generator = SpeciesGenerator(model_router)
ui_config_path = Path(settings.ui_config_path)

# ã€å¯¼å…¥æ–°çš„å‹åŠ›æ¨¡æ¿ï¼ˆå¸¦ tier å’Œ base_costï¼‰ã€‘
from .pressure_templates import PRESSURE_TEMPLATES as pressure_templates

pressure_queue: list[list[PressureConfig]] = []
# äº‹ä»¶é˜Ÿåˆ—ï¼šç”¨äºå®æ—¶æ¨é€æ¼”åŒ–æ—¥å¿—åˆ°å‰ç«¯
simulation_events: Queue = Queue()
simulation_running = False

# è‡ªåŠ¨ä¿å­˜ç›¸å…³
current_save_name: str | None = None  # å½“å‰å­˜æ¡£åç§°
autosave_counter: int = 0  # è‡ªåŠ¨ä¿å­˜å›åˆè®¡æ•°å™¨


def _serialize_species_detail(species) -> SpeciesDetail:
    """æ„å»ºç»Ÿä¸€çš„ SpeciesDetail å“åº”ï¼Œä¾›å¤šä¸ªç«¯ç‚¹å¤ç”¨"""
    morphology_stats = {
        k: v for k, v in (species.morphology_stats or {}).items()
        if isinstance(v, (int, float))
    }
    return SpeciesDetail(
        lineage_code=species.lineage_code,
        latin_name=species.latin_name,
        common_name=species.common_name,
        description=species.description,
        morphology_stats=morphology_stats,
        abstract_traits=species.abstract_traits,
        hidden_traits=species.hidden_traits,
        status=species.status,
        organs=species.organs,
        capabilities=species.capabilities,
        genus_code=species.genus_code,
        taxonomic_rank=species.taxonomic_rank,
        trophic_level=species.trophic_level,
        hybrid_parent_codes=species.hybrid_parent_codes,
        hybrid_fertility=species.hybrid_fertility,
        parent_code=species.parent_code,
        created_turn=species.created_turn,
        dormant_genes=species.dormant_genes,
        stress_exposure=species.stress_exposure,
        gene_diversity_radius=getattr(species, "gene_diversity_radius", 0.0),
        explored_directions=getattr(species, "explored_directions", []) or [],
        gene_stability=getattr(species, "gene_stability", 0.0),
    )


def apply_ui_config(config: UIConfig) -> UIConfig:
    """åº”ç”¨ UI é…ç½®åˆ°è¿è¡Œæ—¶æœåŠ¡ï¼ŒåŒ…å«æ—§é…ç½®è¿ç§»é€»è¾‘"""
    
    # --- 1. æ•°æ®è¿ç§»ï¼šæ—§é…ç½® -> æ–°å¤šæœåŠ¡å•†é…ç½® ---
    has_legacy_config = config.ai_api_key and not config.providers
    if has_legacy_config:
        logger.debug("[é…ç½®] æ£€æµ‹åˆ°æ—§ç‰ˆé…ç½®ï¼Œæ­£åœ¨è¿ç§»åˆ°å¤šæœåŠ¡å•†ç»“æ„...")
        default_provider_id = str(uuid.uuid4())[:8]
        provider = ProviderConfig(
            id=default_provider_id,
            name="Default Provider",
            type=config.ai_provider or "openai",
            base_url=config.ai_base_url,
            api_key=config.ai_api_key,
        )
        config.providers[default_provider_id] = provider
        config.default_provider_id = default_provider_id
        config.default_model = config.ai_model
        
        # è¿ç§»æ—§çš„ capability_configs
        if config.capability_configs and isinstance(config.capability_configs, dict):
            first_val = next(iter(config.capability_configs.values()), None)
            if first_val and isinstance(first_val, dict) and "api_key" in first_val:
                for cap, old_conf in config.capability_configs.items():
                    if old_conf.get("api_key") or old_conf.get("base_url"):
                        custom_pid = f"custom_{cap}"
                        custom_provider = ProviderConfig(
                            id=custom_pid,
                            name=f"Custom for {cap}",
                            type=old_conf.get("provider", "openai"),
                            base_url=old_conf.get("base_url") or config.ai_base_url,
                            api_key=old_conf.get("api_key") or config.ai_api_key
                        )
                        config.providers[custom_pid] = custom_provider
                        config.capability_routes[cap] = CapabilityRouteConfig(
                            provider_id=custom_pid,
                            model=old_conf.get("model"),
                            timeout=old_conf.get("timeout", 60)
                        )
                    else:
                        config.capability_routes[cap] = CapabilityRouteConfig(
                            provider_id=default_provider_id,
                            model=old_conf.get("model"),
                            timeout=old_conf.get("timeout", 60)
                        )
    
    return configure_model_router(config, model_router, embedding_service, settings)


ui_config = apply_ui_config(environment_repository.load_ui_config(ui_config_path))

# ã€æ–°å¢ã€‘Embedding é›†æˆæœåŠ¡ - ç®¡ç†åˆ†ç±»å­¦ã€æ¼”åŒ–é¢„æµ‹ã€å™äº‹ç”Ÿæˆç­‰æ‰©å±•åŠŸèƒ½
embedding_integration = EmbeddingIntegrationService(embedding_service, model_router)

# ã€ä¿®å¤ã€‘ä» UI é…ç½®ä¸­è·å–å„å­é…ç½®ï¼Œæ³¨å…¥åˆ° SimulationEngine
_engine_configs = {
    "ecology": getattr(ui_config, 'ecology_balance', None),
    "mortality": getattr(ui_config, 'mortality', None),
    "speciation": getattr(ui_config, 'speciation', None),
    "food_web": getattr(ui_config, 'food_web', None),
}

simulation_engine = SimulationEngine(
    environment=environment_system,
    mortality=mortality_engine,
    embeddings=embedding_service,
    router=model_router,
    report_builder=report_builder,
    exporter=export_service,
    niche_analyzer=niche_analyzer,
    speciation=speciation_service,
    background_manager=background_manager,
    tiering=tiering_service,
    focus_processor=focus_processor,
    critical_analyzer=critical_analyzer,
    escalation_service=pressure_escalation,
    map_evolution=map_evolution,
    migration_advisor=migration_advisor,
    map_manager=map_manager,
    reproduction_service=reproduction_service,
    gene_flow_service=gene_flow_service,
    embedding_integration=embedding_integration,  # ã€æ–°å¢ã€‘Embeddingé›†æˆæœåŠ¡
    configs=_engine_configs,  # ã€ä¿®å¤ã€‘æ³¨å…¥é…ç½®
)
watchlist: set[str] = set()
action_queue = {"queued_rounds": 0, "running": False}

# åç«¯ä¼šè¯IDï¼šæ¯æ¬¡åç«¯å¯åŠ¨æ—¶ç”Ÿæˆæ–°çš„UUID
# ç”¨äºè®©å‰ç«¯æ£€æµ‹åç«¯æ˜¯å¦é‡å¯ï¼Œå®ç°"åç«¯é‡å¯å›ä¸»èœå•"çš„é€»è¾‘
# ã€è¿ç§»è¯´æ˜ã€‘è¿™äº›å…¨å±€å˜é‡å°†é€æ­¥è¿ç§»åˆ° core/session.py çš„ SimulationSessionManager
_backend_session_id: str = ""


def set_backend_session_id(session_id: str) -> None:
    """è®¾ç½®åç«¯ä¼šè¯IDï¼ˆç”± main.py åœ¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰
    
    ã€è¿ç§»è¯´æ˜ã€‘æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
    æ–°ä»£ç åº”ä½¿ç”¨ core/session.py çš„ get_session_manager().generate_session_id()
    """
    global _backend_session_id
    _backend_session_id = session_id
    # ã€æ¡¥æ¥ã€‘åŒæ—¶è®¾ç½®åˆ°æ–°çš„ SessionManager
    try:
        from ..core.session import get_session_manager
        session = get_session_manager()
        session._session_id = session_id  # ç›´æ¥è®¾ç½®ä»¥ä¿æŒåŒæ­¥
    except Exception:
        pass  # åˆå§‹åŒ–é˜¶æ®µå¯èƒ½å¤±è´¥ï¼Œå¿½ç•¥


def get_backend_session_id() -> str:
    """è·å–åç«¯ä¼šè¯ID
    
    ã€è¿ç§»è¯´æ˜ã€‘æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
    æ–°ä»£ç åº”ä½¿ç”¨ core/session.py çš„ get_session_manager().session_id
    """
    return _backend_session_id


def initialize_environment() -> None:
    """å¯åŠ¨æ—¶çš„ç¯å¢ƒåˆå§‹åŒ–ï¼šç¡®ä¿æ•°æ®åº“ç»“æ„å®Œæ•´ï¼Œæ¢å¤å›åˆè®¡æ•°å™¨"""
    try:
        logger.info("[ç¯å¢ƒåˆå§‹åŒ–] å¼€å§‹æ£€æŸ¥æ•°æ®åº“ç»“æ„...")
        # ç¡®ä¿æ•°æ®åº“åˆ—å®Œæ•´
        environment_repository.ensure_map_state_columns()
        environment_repository.ensure_tile_columns()
        
        # æ£€æŸ¥åœ°å›¾æ˜¯å¦å­˜åœ¨ï¼ˆä½†ä¸è‡ªåŠ¨ç”Ÿæˆï¼‰
        tiles = environment_repository.list_tiles(limit=10)
        if len(tiles) > 0:
            logger.info(f"[ç¯å¢ƒåˆå§‹åŒ–] å‘ç°ç°æœ‰åœ°å›¾ï¼Œåœ°å—æ•°é‡: {len(tiles)}")
            logger.debug(f"[ç¯å¢ƒåˆå§‹åŒ–] ç¤ºä¾‹åœ°å—: x={tiles[0].x}, y={tiles[0].y}, biome={tiles[0].biome}")
        else:
            logger.info(f"[ç¯å¢ƒåˆå§‹åŒ–] æœªå‘ç°åœ°å›¾æ•°æ®ï¼Œç­‰å¾…åˆ›å»ºå­˜æ¡£æ—¶ç”Ÿæˆ")
        
        # ã€å…³é”®ä¿®å¤ã€‘æ¢å¤å›åˆè®¡æ•°å™¨ï¼šä¼˜å…ˆä» MapStateï¼Œå…¶æ¬¡ä»å†å²è®°å½•
        # æ³¨æ„ï¼šMapState.turn_index ä¿å­˜çš„æ˜¯"ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„å›åˆæ•°"ï¼ˆåœ¨ FinalizeStage ä¸­ä¿å­˜ï¼‰
        try:
            # æ–¹æ³•1ï¼šä» MapState æ¢å¤ï¼ˆæœ€å¯é ï¼‰
            map_state = environment_repository.get_state()
            if map_state and map_state.turn_index > 0:
                simulation_engine.turn_counter = map_state.turn_index  # ç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦ +1
                logger.info(f"[ç¯å¢ƒåˆå§‹åŒ–] ä» MapState æ¢å¤å›åˆè®¡æ•°å™¨: {simulation_engine.turn_counter}")
            else:
                # æ–¹æ³•2ï¼šä»å†å²è®°å½•æ¢å¤ï¼ˆå†å²è®°å½•ä¿å­˜çš„æ˜¯å·²å®Œæˆå›åˆçš„ç´¢å¼•ï¼‰
                logs = history_repository.list_turns(limit=1)
                if logs:
                    last_turn = logs[0].turn_index
                    simulation_engine.turn_counter = last_turn + 1  # å†å²è®°å½•éœ€è¦ +1
                    logger.info(f"[ç¯å¢ƒåˆå§‹åŒ–] ä»å†å²è®°å½•æ¢å¤å›åˆè®¡æ•°å™¨: {simulation_engine.turn_counter}")
                else:
                    logger.info(f"[ç¯å¢ƒåˆå§‹åŒ–] æœªå‘ç°å†å²è®°å½•ï¼Œå›åˆè®¡æ•°å™¨ä¿æŒä¸º 0")
        except Exception as e:
            logger.warning(f"[ç¯å¢ƒåˆå§‹åŒ–] æ¢å¤å›åˆè®¡æ•°å™¨å¤±è´¥: {e}")
            
    except Exception as e:
        logger.error(f"[ç¯å¢ƒåˆå§‹åŒ–é”™è¯¯] {str(e)}")
        import traceback
        logger.error(traceback.format_exc())


def push_simulation_event(event_type: str, message: str, category: str = "å…¶ä»–", force: bool = False, **extra):
    """æ¨é€æ¼”åŒ–äº‹ä»¶åˆ°å‰ç«¯
    
    Args:
        event_type: äº‹ä»¶ç±»å‹ (start, complete, error, stage, etc.)
        message: äº‹ä»¶æ¶ˆæ¯
        category: äº‹ä»¶åˆ†ç±»
        force: æ˜¯å¦å¼ºåˆ¶æ¨é€ï¼ˆå³ä½¿ simulation_running=Falseï¼‰
        **extra: é¢å¤–å‚æ•°
        
    ã€è¿ç§»è¯´æ˜ã€‘æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
    æ–°ä»£ç åº”ä½¿ç”¨ core/session.py çš„ get_session_manager().push_event()
    """
    global simulation_events, simulation_running
    # å…è®¸åœ¨ simulation_running=False æ—¶ä¹Ÿèƒ½æ¨é€å…³é”®äº‹ä»¶ï¼ˆå¦‚ complete, errorï¼‰
    if simulation_running or force or event_type in ("complete", "error", "turn_complete"):
        try:
            event = {
                "type": event_type,
                "message": message,
                "category": category,
                "timestamp": __import__("time").time()
            }
            # æ·»åŠ é¢å¤–å‚æ•°ï¼ˆå¦‚AIè¿›åº¦ä¿¡æ¯ï¼‰
            event.update(extra)
            simulation_events.put(event)
            # å¯¹äºå…³é”®äº‹ä»¶ï¼Œæ‰“å°æ—¥å¿—ç¡®è®¤
            if event_type in ("complete", "error", "turn_complete"):
                logger.debug(f"[SSEäº‹ä»¶] å·²æ¨é€ {event_type}: {message}")
        except Exception as e:
            logger.warning(f"[äº‹ä»¶æ¨é€é”™è¯¯] {str(e)}")


@router.get("/events/stream")
async def stream_simulation_events():
    """Server-Sent Events ç«¯ç‚¹ï¼Œå®æ—¶æ¨é€æ¼”åŒ–äº‹ä»¶"""
    async def event_generator():
        global simulation_events
        
        # å‘é€è¿æ¥ç¡®è®¤
        yield f"data: {json.dumps({'type': 'connected', 'message': 'å·²è¿æ¥åˆ°äº‹ä»¶æµ'})}\n\n"
        
        idle_count = 0
        while True:
            try:
                # æ‰¹é‡è·å–æ‰€æœ‰å¾…å‘é€äº‹ä»¶ï¼ˆæé«˜ååé‡ï¼‰
                events_sent = 0
                while not simulation_events.empty() and events_sent < 20:
                    event = simulation_events.get_nowait()
                    yield f"data: {json.dumps(event)}\n\n"
                    events_sent += 1
                    idle_count = 0
                
                if events_sent == 0:
                    idle_count += 1
                    # ç©ºé—²æ—¶å‘é€ SSE å¿ƒè·³ä¿æŒè¿æ¥
                    if idle_count >= 50:  # æ¯5ç§’å‘ä¸€æ¬¡å¿ƒè·³
                        yield f": keepalive\n\n"
                        idle_count = 0
                    await asyncio.sleep(0.1)
            except Exception as e:
                logger.warning(f"[SSEé”™è¯¯] {str(e)}")
                break
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
            "Connection": "keep-alive",
        }
    )


def _perform_autosave(turn_index: int) -> bool:
    """æ‰§è¡Œè‡ªåŠ¨ä¿å­˜
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸä¿å­˜
    
    ã€å¥å£®æ€§æ”¹è¿›ã€‘
    - ä½¿ç”¨ simulation_engine.turn_counter ä½œä¸ºæƒå¨å›åˆæ•°æº
    - ä¼ å…¥çš„ turn_index ä½œä¸ºå¤‡é€‰ï¼Œä½†ä¼˜å…ˆä½¿ç”¨å¼•æ“çŠ¶æ€
    """
    global current_save_name, autosave_counter
    
    if not current_save_name:
        logger.debug("[è‡ªåŠ¨ä¿å­˜] è·³è¿‡: æ²¡æœ‰å½“å‰å­˜æ¡£")
        return False
    
    # è¯»å–é…ç½®
    config = environment_repository.load_ui_config(ui_config_path)
    
    if not config.autosave_enabled:
        return False
    
    autosave_counter += 1
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¿å­˜é—´éš”
    if autosave_counter < config.autosave_interval:
        logger.debug(f"[è‡ªåŠ¨ä¿å­˜] è·³è¿‡: è®¡æ•° {autosave_counter}/{config.autosave_interval}")
        return False
    
    # é‡ç½®è®¡æ•°å™¨
    autosave_counter = 0
    
    try:
        # ã€å…³é”®ã€‘ä½¿ç”¨ simulation_engine.turn_counter ä½œä¸ºæƒå¨å›åˆæ•°
        authoritative_turn = simulation_engine.turn_counter
        
        # å¦‚æœä¼ å…¥çš„ turn_index ä¸å¼•æ“çŠ¶æ€ä¸ä¸€è‡´ï¼Œè®°å½•è­¦å‘Š
        if turn_index != authoritative_turn:
            logger.warning(
                f"[è‡ªåŠ¨ä¿å­˜] å›åˆæ•°ä¸ä¸€è‡´: ä¼ å…¥={turn_index}, å¼•æ“={authoritative_turn}ï¼Œä½¿ç”¨å¼•æ“å€¼"
            )
        
        # ç”Ÿæˆè‡ªåŠ¨ä¿å­˜å­˜æ¡£åç§°
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        autosave_name = f"autosave_{current_save_name}_{timestamp}"
        
        logger.info(f"[è‡ªåŠ¨ä¿å­˜] å¼€å§‹ä¿å­˜: {autosave_name}, å›åˆ={authoritative_turn}")
        push_simulation_event("autosave", f"ğŸ’¾ è‡ªåŠ¨ä¿å­˜ä¸­...", "ç³»ç»Ÿ")
        
        # åˆ›å»ºè‡ªåŠ¨ä¿å­˜
        save_manager.create_save(autosave_name, f"è‡ªåŠ¨ä¿å­˜ - T{authoritative_turn}")
        save_manager.save_game(autosave_name, authoritative_turn)
        
        # æ¸…ç†æ—§çš„è‡ªåŠ¨ä¿å­˜ï¼ˆä¿ç•™æœ€æ–°çš„Nä¸ªï¼‰
        _cleanup_old_autosaves(current_save_name, config.autosave_max_slots)
        
        logger.info(f"[è‡ªåŠ¨ä¿å­˜] å®Œæˆ: {autosave_name}")
        push_simulation_event("autosave_complete", f"âœ… è‡ªåŠ¨ä¿å­˜å®Œæˆ (T{authoritative_turn})", "ç³»ç»Ÿ")
        return True
    except Exception as e:
        logger.error(f"[è‡ªåŠ¨ä¿å­˜] å¤±è´¥: {str(e)}")
        push_simulation_event("autosave_error", f"âš ï¸ è‡ªåŠ¨ä¿å­˜å¤±è´¥: {str(e)}", "é”™è¯¯")
        return False


def _cleanup_old_autosaves(base_save_name: str, max_slots: int) -> None:
    """æ¸…ç†æ—§çš„è‡ªåŠ¨ä¿å­˜ï¼Œåªä¿ç•™æœ€æ–°çš„Nä¸ª"""
    try:
        all_saves = save_manager.list_saves()
        
        # ç­›é€‰å‡ºå±äºå½“å‰å­˜æ¡£çš„è‡ªåŠ¨ä¿å­˜
        autosaves = [
            s for s in all_saves 
            if s.get("name", "").startswith(f"autosave_{base_save_name}_")
        ]
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆä»æ–°åˆ°æ—§ï¼‰
        autosaves.sort(key=lambda s: s.get("timestamp", 0), reverse=True)
        
        # åˆ é™¤è¶…å‡ºé™åˆ¶çš„æ—§å­˜æ¡£
        for old_save in autosaves[max_slots:]:
            save_name = old_save.get("name")
            if save_name:
                logger.info(f"[è‡ªåŠ¨ä¿å­˜] æ¸…ç†æ—§å­˜æ¡£: {save_name}")
                save_manager.delete_save(save_name)
    except Exception as e:
        logger.warning(f"[è‡ªåŠ¨ä¿å­˜] æ¸…ç†æ—§å­˜æ¡£å¤±è´¥: {str(e)}")


@router.post("/turns/run")  # ç§»é™¤ response_modelï¼Œé¿å… Pydantic éªŒè¯é˜»å¡
async def run_turns(command: TurnCommand, background_tasks: BackgroundTasks):
    import traceback
    import time as time_module
    global simulation_running, autosave_counter
    
    start_time = time_module.time()
    
    try:
        logger.info(f"[æ¨æ¼”å¼€å§‹] å›åˆæ•°: {command.rounds}, å‹åŠ›æ•°: {len(command.pressures)}")
        
        # æ¸…ç©ºäº‹ä»¶é˜Ÿåˆ—
        while not simulation_events.empty():
            simulation_events.get_nowait()
        
        simulation_running = True
        action_queue["running"] = True
        
        push_simulation_event("start", f"å¼€å§‹æ¨æ¼” {command.rounds} å›åˆ", "ç³»ç»Ÿ")
        
        simulation_engine.update_watchlist(watchlist)
        pressures = list(command.pressures)
        if not pressures and pressure_queue:
            pressures = pressure_queue.pop(0)
            action_queue["queued_rounds"] = max(action_queue["queued_rounds"] - 1, 0)
        command.pressures = pressures
        logger.info(f"[æ¨æ¼”æ‰§è¡Œ] åº”ç”¨å‹åŠ›: {[p.kind for p in pressures]}")
        
        current_turn = simulation_engine.turn_counter
        
        # ã€èƒ½é‡ç³»ç»Ÿã€‘æ£€æŸ¥å‹åŠ›æ¶ˆè€—
        # ã€ä¿®æ”¹ã€‘è‡ªç„¶æ¼”åŒ–ï¼ˆæ— å‹åŠ›å‚æ•°ï¼‰ä¸æ¶ˆè€—èƒ½é‡
        if pressures and energy_service.enabled:
            # è¿‡æ»¤æ‰å¼ºåº¦ä¸º0çš„æ— æ•ˆå‹åŠ›
            valid_pressures = [p for p in pressures if p.intensity > 0]
            
            if valid_pressures:
                pressure_dicts = [{"kind": p.kind, "intensity": p.intensity} for p in valid_pressures]
                total_cost = energy_service.get_pressure_cost(pressure_dicts)
                current_energy = energy_service.get_state().current
                
                if current_energy < total_cost:
                    action_queue["running"] = False
                    simulation_running = False
                    raise HTTPException(
                        status_code=400, 
                        detail=f"èƒ½é‡ä¸è¶³ï¼æ–½åŠ å‹åŠ›éœ€è¦ {total_cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {current_energy}"
                    )
                
                # æ¶ˆè€—èƒ½é‡
                success, msg = energy_service.spend(
                    "pressure", 
                    current_turn,
                    details=f"å‹åŠ›: {', '.join([p.kind for p in valid_pressures])}",
                    intensity=sum(p.intensity for p in valid_pressures) / len(valid_pressures)
                )
                if success:
                    push_simulation_event("energy", f"âš¡ æ¶ˆè€— {total_cost} èƒ½é‡ï¼ˆç¯å¢ƒå‹åŠ›ï¼‰", "ç³»ç»Ÿ")
            else:
                # è™½ç„¶æœ‰å‚æ•°ä½†éƒ½æ˜¯0å¼ºåº¦ï¼Œè§†ä¸ºè‡ªç„¶æ¼”åŒ–
                pressures = []
        
        push_simulation_event("pressure", f"åº”ç”¨å‹åŠ›: {', '.join([p.kind for p in pressures]) if pressures else 'è‡ªç„¶æ¼”åŒ–'}", "ç¯å¢ƒ")
        
        # å°†æ¨é€å‡½æ•°ä¼ é€’ç»™å¼•æ“
        simulation_engine._event_callback = push_simulation_event
        
        # AI å‹åŠ›è·¯å¾„å·²ç§»é™¤
        
        reports = await simulation_engine.run_turns_async(command)
        
        elapsed = time_module.time() - start_time
        logger.info(f"[æ¨æ¼”å®Œæˆ] ç”Ÿæˆäº† {len(reports)} ä¸ªæŠ¥å‘Š, è€—æ—¶ {elapsed:.1f}ç§’")
        
        # ã€è¯Šæ–­æ—¥å¿—ã€‘è®°å½•å“åº”æ•°æ®é‡ï¼Œå¸®åŠ©æ’æŸ¥å¡é¡¿é—®é¢˜
        if reports:
            total_species = sum(len(r.species) for r in reports)
            logger.info(f"[å“åº”å‡†å¤‡] è¿”å› {len(reports)} ä¸ªæŠ¥å‘Š, å…± {total_species} ä¸ªç‰©ç§å¿«ç…§")
        
        # ã€èƒ½é‡ç³»ç»Ÿã€‘å›åˆç»“æŸåæ¢å¤èƒ½é‡
        final_turn = simulation_engine.turn_counter
        regen = energy_service.regenerate(final_turn)
        if regen > 0:
            push_simulation_event("energy", f"âš¡ ç¥åŠ›æ¢å¤ +{regen}", "ç³»ç»Ÿ")
        
        # ã€å…³é”®ã€‘å…ˆå‘é€å®Œæˆäº‹ä»¶ï¼Œè®©å‰ç«¯çŸ¥é“æ¨æ¼”å·²å®Œæˆ
        push_simulation_event("complete", f"æ¨æ¼”å®Œæˆï¼ç”Ÿæˆäº† {len(reports)} ä¸ªæŠ¥å‘Š", "ç³»ç»Ÿ")
        push_simulation_event("turn_complete", f"å›åˆæ¨æ¼”å®Œæˆ", "ç³»ç»Ÿ")
        
        action_queue["running"] = False
        action_queue["queued_rounds"] = max(action_queue["queued_rounds"] - command.rounds, 0)
        simulation_running = False
        
        # ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨ BackgroundTasks æ‰§è¡Œè‡ªåŠ¨ä¿å­˜
        # è¿™ä¼šåœ¨å“åº”å®Œå…¨å‘é€åæ‰æ‰§è¡Œï¼Œé¿å…å“åº”è¢«é˜»å¡
        # ã€ä¿®å¤ã€‘ç›´æ¥ä½¿ç”¨å¼•æ“çš„ turn_counterï¼Œè€Œä¸æ˜¯æŠ¥å‘Šä¸­çš„ turn_index
        # final_turn å·²åœ¨ä¸Šé¢è·å–ï¼Œæ˜¯æƒå¨çš„å›åˆæ•°
        
        def do_autosave():
            """åœ¨åå°æ‰§è¡Œè‡ªåŠ¨ä¿å­˜"""
            try:
                _perform_autosave(final_turn)
            except Exception as e:
                logger.warning(f"[åå°ä»»åŠ¡] è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")
        
        # æ·»åŠ åˆ° BackgroundTasksï¼Œä¼šåœ¨å“åº”å‘é€åæ‰§è¡Œ
        background_tasks.add_task(do_autosave)
        
        # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ç›´æ¥ä½¿ç”¨ json.dumps åºåˆ—åŒ–ï¼Œå®Œå…¨ç»•è¿‡ FastAPI/Pydantic
        logger.info(f"[HTTPå“åº”] å¼€å§‹åºåˆ—åŒ–å“åº”...")
        try:
            # ä½¿ç”¨ model_dump è½¬æ¢ä¸º dict
            response_data = [r.model_dump(mode="json") for r in reports]
            # ä½¿ç”¨æ ‡å‡† json æ¨¡å—åºåˆ—åŒ–
            json_str = json.dumps(response_data, ensure_ascii=False, default=str)
            logger.info(f"[HTTPå“åº”] åºåˆ—åŒ–å®Œæˆï¼Œæ•°æ®å¤§å°: {len(json_str)} å­—èŠ‚ï¼Œæ­£åœ¨è¿”å›...")
            # ä½¿ç”¨æœ€åŸå§‹çš„ Response è¿”å›
            from starlette.responses import Response
            return Response(
                content=json_str,
                media_type="application/json",
                headers={"Content-Length": str(len(json_str.encode('utf-8')))}
            )
        except Exception as e:
            logger.error(f"[HTTPå“åº”] åºåˆ—åŒ–å¤±è´¥: {e}")
            import traceback as tb
            logger.error(tb.format_exc())
            # é™çº§ï¼šè¿”å›ç®€åŒ–çš„å“åº”
            return JSONResponse(content={"error": str(e), "reports_count": len(reports)})
        
    except Exception as e:
        elapsed = time_module.time() - start_time
        logger.error(f"[æ¨æ¼”é”™è¯¯] {str(e)}, è€—æ—¶ {elapsed:.1f}ç§’")
        logger.error(traceback.format_exc())
        
        # ã€å…³é”®ä¿®å¤ã€‘å…ˆå‘é€ error äº‹ä»¶ï¼Œå†è®¾ç½® simulation_running=False
        # ä½¿ç”¨ force=True ç¡®ä¿äº‹ä»¶ä¸€å®šèƒ½å‘é€
        push_simulation_event("error", f"æ¨æ¼”å¤±è´¥: {str(e)}", "é”™è¯¯", force=True)
        
        action_queue["running"] = False
        simulation_running = False
        
        raise HTTPException(status_code=500, detail=f"æ¨æ¼”æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/species/edit", response_model=SpeciesDetail)
def edit_species(request: SpeciesEditRequest) -> SpeciesDetail:
    species = species_repository.get_by_lineage(request.lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail="Species not found")
    if request.description:
        species.description = request.description
    if request.trait_overrides:
        species.morphology_stats.update(request.trait_overrides)
    if request.abstract_overrides:
        species.abstract_traits.update(request.abstract_overrides)
    if request.open_new_lineage:
        species.status = "split"
    species_repository.upsert(species)
    # è¿”å›æœ€æ–°çš„ç‰©ç§è¯¦æƒ…ï¼Œä¸ `/species/{code}` ä¿æŒä¸€è‡´
    return _serialize_species_detail(species)


@router.get("/watchlist")
def get_watchlist() -> dict[str, list[str]]:
    """è·å–å½“å‰ç©å®¶å…³æ³¨çš„ç‰©ç§åˆ—è¡¨ï¼ˆCritical å±‚ï¼‰"""
    return {"watching": sorted(watchlist)}


@router.post("/watchlist")
def update_watchlist(request: WatchlistRequest) -> dict[str, list[str]]:
    """æ›´æ–°ç©å®¶å…³æ³¨çš„ç‰©ç§åˆ—è¡¨ï¼ˆCritical å±‚ï¼‰"""
    watchlist.clear()
    watchlist.update(request.lineage_codes)
    simulation_engine.update_watchlist(watchlist)
    return {"watching": sorted(watchlist)}


import hashlib
import time

# æ—è°±ç¼“å­˜ï¼ˆç®€å•å†…å­˜ç¼“å­˜ï¼‰
_lineage_cache: dict[str, tuple[LineageTree, str, float]] = {}  # key -> (data, etag, timestamp)
_lineage_cache_ttl = 30  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰

def _invalidate_lineage_cache():
    """åœ¨ç‰©ç§å˜åŒ–æ—¶è°ƒç”¨ä»¥æ¸…é™¤ç¼“å­˜"""
    _lineage_cache.clear()

@router.get("/lineage")
def get_lineage_tree(
    request: Request,
    status: str | None = None,
    prefix: str | None = None,
    include_genetic_distances: bool = False,
    limit: int | None = None,
    offset: int = 0
):
    """
    è·å–æ—è°±æ ‘æ•°æ®
    
    Args:
        status: å¯é€‰ï¼Œç­›é€‰çŠ¶æ€ ("alive", "extinct")
        prefix: å¯é€‰ï¼ŒæŒ‰lineage_codeå‰ç¼€ç­›é€‰ï¼ˆå¦‚ "A1" è·å–A1åŠå…¶åä»£ï¼‰
        include_genetic_distances: æ˜¯å¦åŒ…å«é—ä¼ è·ç¦»æ•°æ®ï¼ˆé»˜è®¤Falseï¼Œå‡å°‘å“åº”ä½“ç§¯ï¼‰
        limit: å¯é€‰ï¼Œè¿”å›æ•°é‡é™åˆ¶ï¼ˆç”¨äºåˆ†é¡µï¼‰
        offset: åˆ†é¡µåç§»é‡
        
    æ”¯æŒ ETag æ¡ä»¶è¯·æ±‚ï¼Œå‡å°‘é‡å¤ä¼ è¾“ã€‚
    """
    # æ„å»ºç¼“å­˜é”®
    cache_key = f"{status}:{prefix}:{include_genetic_distances}:{limit}:{offset}"
    current_time = time.time()
    
    # æ£€æŸ¥ç¼“å­˜
    if cache_key in _lineage_cache:
        cached_data, cached_etag, cached_time = _lineage_cache[cache_key]
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if current_time - cached_time < _lineage_cache_ttl:
            # æ£€æŸ¥ If-None-Match å¤´
            if_none_match = request.headers.get("if-none-match")
            if if_none_match == cached_etag:
                return JSONResponse(status_code=304, content=None, headers={"ETag": cached_etag})
            
            # è¿”å›ç¼“å­˜æ•°æ®
            response = JSONResponse(content=cached_data.model_dump())
            response.headers["ETag"] = cached_etag
            response.headers["Cache-Control"] = f"max-age={_lineage_cache_ttl}"
            return response
    
    nodes: list[LineageNode] = []
    
    # è·å–ç‰©ç§åˆ—è¡¨ï¼ˆæ”¯æŒè¿‡æ»¤å’Œåˆ†é¡µï¼‰
    all_species = species_repository.list_species(
        status=status,
        prefix=prefix,
        limit=limit,
        offset=offset
    )
    
    if not all_species:
        return LineageTree(nodes=[], total_count=0)
    
    # è·å–æ€»æ•°ï¼ˆç”¨äºåˆ†é¡µï¼‰
    total_count = species_repository.count_species(status=status, prefix=prefix)
    
    # æ‰¹é‡è·å–äººå£ç»Ÿè®¡ä¿¡æ¯ï¼ˆå•æ¬¡æŸ¥è¯¢æ›¿ä»£ O(N) æ¬¡æŸ¥è¯¢ï¼‰
    species_ids = [s.id for s in all_species]
    population_stats = species_repository.get_population_stats_batch(species_ids)
    
    # åªåœ¨éœ€è¦æ—¶åŠ è½½é—ä¼ è·ç¦»æ•°æ®
    genus_distances = {}
    if include_genetic_distances:
        all_genera = genus_repository.list_all()
        for genus in all_genera:
            genus_distances[genus.code] = genus.genetic_distances
    
    # è®¡ç®—åä»£æ•°é‡ï¼ˆå†…å­˜è®¡ç®—ï¼ŒO(N)ï¼‰
    descendant_map: dict[str, int] = {}
    for species in all_species:
        if species.parent_code:
            descendant_map[species.parent_code] = descendant_map.get(species.parent_code, 0) + 1
    
    # æ„å»ºèŠ‚ç‚¹ï¼ˆæ— æ•°æ®åº“æŸ¥è¯¢ï¼‰
    for species in all_species:
        # å½“å‰ç§ç¾¤ä» morphology_stats è·å–
        current_pop = int(species.morphology_stats.get("population", 0) or 0)
        
        # ä»æ‰¹é‡æŸ¥è¯¢ç»“æœè·å–å³°å€¼äººå£å’Œæœ€åå›åˆ
        stats = population_stats.get(species.id, {})
        historical_peak = stats.get("peak_population", 0)
        peak_pop = max(int(historical_peak), current_pop)
        
        # ç­ç»å›åˆ
        extinction_turn = None
        if species.status == "extinct":
            extinction_turn = stats.get("last_turn", 0)
        
        # æ¨æ–­ç”Ÿæ€è§’è‰²
        ecological_role = _infer_ecological_role(species)
        
        # æ¨æ–­tier
        tier = "background" if species.is_background else None
        
        # é—ä¼ è·ç¦»ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
        genetic_distances_to_siblings = {}
        if include_genetic_distances and species.genus_code and species.genus_code in genus_distances:
            for key, distance in genus_distances[species.genus_code].items():
                if species.lineage_code in key:
                    other_code = key.replace(f"{species.lineage_code}-", "").replace(f"-{species.lineage_code}", "")
                    if other_code != species.lineage_code:
                        genetic_distances_to_siblings[other_code] = distance
        
        # è·å–è¥å…»çº§
        trophic_level = getattr(species, 'trophic_level', 1.0)
        if trophic_level is None or not isinstance(trophic_level, (int, float)):
            trophic_level = 1.0
        
        nodes.append(
            LineageNode(
                lineage_code=species.lineage_code,
                parent_code=species.parent_code,
                latin_name=species.latin_name,
                common_name=species.common_name,
                state=species.status,
                population_share=1.0,
                major_events=[],
                birth_turn=species.created_turn,
                extinction_turn=extinction_turn,
                ecological_role=ecological_role,
                tier=tier,
                trophic_level=float(trophic_level),
                speciation_type="normal",
                current_population=current_pop,
                peak_population=int(peak_pop),
                descendant_count=descendant_map.get(species.lineage_code, 0),
                taxonomic_rank=species.taxonomic_rank,
                genus_code=species.genus_code,
                hybrid_parent_codes=species.hybrid_parent_codes,
                hybrid_fertility=species.hybrid_fertility,
                genetic_distances=genetic_distances_to_siblings,
            )
        )
    
    result = LineageTree(nodes=nodes, total_count=total_count)
    
    # ç”Ÿæˆ ETagï¼ˆåŸºäºå†…å®¹å“ˆå¸Œï¼‰
    content_str = result.model_dump_json()
    etag = f'"{hashlib.md5(content_str.encode()).hexdigest()}"'
    
    # ç¼“å­˜ç»“æœ
    _lineage_cache[cache_key] = (result, etag, current_time)
    
    # è¿”å›å¸¦ ETag çš„å“åº”
    response = JSONResponse(content=result.model_dump())
    response.headers["ETag"] = etag
    response.headers["Cache-Control"] = f"max-age={_lineage_cache_ttl}"
    return response


@router.get("/queue", response_model=ActionQueueStatus)
def get_queue_status() -> ActionQueueStatus:
    preview = []
    for batch in pressure_queue:
        if not batch:
            preview.append("è‡ªç„¶æ¼”åŒ–")
        else:
            kinds = [p.kind for p in batch]
            preview.append("+".join(kinds))
    
    return ActionQueueStatus(
        queued_rounds=action_queue["queued_rounds"], 
        running=action_queue["running"],
        queue_preview=preview
    )


@router.get("/history", response_model=list[TurnReport])
def list_history(limit: int = 10) -> list[TurnReport]:
    logs = history_repository.list_turns(limit=limit)
    return [TurnReport.model_validate(log.record_data) for log in logs]


@router.get("/exports", response_model=list[ExportRecord])
def list_exports() -> list[ExportRecord]:
    records = export_service.list_records()
    return [ExportRecord(**record) for record in records]


@router.get("/map", response_model=MapOverview)
def get_map_overview(
    limit_tiles: int = 0, 
    limit_habitats: int = 0,
    view_mode: str = "terrain",
    species_code: str | None = None,
) -> MapOverview:
    try:
        # ã€v14ã€‘é¢„åˆå§‹åŒ– embedding ç›¸å…³æœåŠ¡
        from ..services.geo.suitability_service import get_suitability_service
        from ..services.species.prey_affinity import get_prey_affinity_service
        get_suitability_service(embedding_service)
        get_prey_affinity_service(embedding_service)
        
        tile_limit = None if limit_tiles <= 0 else limit_tiles
        habitat_limit = None if limit_habitats <= 0 else limit_habitats
        logger.debug(f"[åœ°å›¾æŸ¥è¯¢] é™åˆ¶åœ°å—: {tile_limit or "all"}, æ –æ¯åœ°: {habitat_limit or "all"}, æ¨¡å¼: {view_mode}, ç‰©ç§: {species_code}")
        
        species_id = None
        if species_code:
            species = species_repository.get_by_lineage(species_code)
            if species:
                species_id = species.id
        
        overview = map_manager.get_overview(
            tile_limit=tile_limit, 
            habitat_limit=habitat_limit,
            view_mode=view_mode,  # type: ignore
            species_id=species_id,
        )
        logger.debug(f"[åœ°å›¾æŸ¥è¯¢] è¿”å›åœ°å—æ•°: {len(overview.tiles)}, æ –æ¯åœ°æ•°: {len(overview.habitats)}")
        return overview
    except Exception as e:
        logger.error(f"[åœ°å›¾æŸ¥è¯¢é”™è¯¯] {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"åœ°å›¾æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/config/ui", response_model=UIConfig)
def get_ui_config() -> UIConfig:
    config = environment_repository.load_ui_config(ui_config_path)
    return apply_ui_config(config)


@router.post("/config/ui", response_model=UIConfig)
def update_ui_config(config: UIConfig) -> UIConfig:
    saved = environment_repository.save_ui_config(ui_config_path, config)
    return apply_ui_config(saved)


@router.get("/pressures/templates", response_model=list[PressureTemplate])
def list_pressure_templates() -> list[PressureTemplate]:
    return pressure_templates


@router.post("/queue/add", response_model=ActionQueueStatus)
def add_to_queue(request: QueueRequest) -> ActionQueueStatus:
    for _ in range(request.rounds):
        configs = [PressureConfig(**p.model_dump()) for p in request.pressures]
        pressure_queue.append(configs)
    action_queue["queued_rounds"] += request.rounds
    
    # åŒæ ·ç”Ÿæˆ preview
    preview = []
    for batch in pressure_queue:
        if not batch:
            preview.append("è‡ªç„¶æ¼”åŒ–")
        else:
            kinds = [p.kind for p in batch]
            preview.append("+".join(kinds))
            
    return ActionQueueStatus(
        queued_rounds=action_queue["queued_rounds"],
        running=action_queue["running"],
        queue_preview=preview,
    )


@router.post("/queue/clear", response_model=ActionQueueStatus)
def clear_queue() -> ActionQueueStatus:
    pressure_queue.clear()
    action_queue["queued_rounds"] = 0
    return ActionQueueStatus(
        queued_rounds=0,
        running=action_queue["running"],
        queue_preview=[],
    )


@router.get("/species/list", response_model=SpeciesList)
def list_all_species() -> SpeciesList:
    """è·å–æ‰€æœ‰ç‰©ç§çš„ç®€è¦åˆ—è¡¨"""
    all_species = species_repository.list_species()
    
    items = []
    for species in all_species:
        # æ¨æ–­ç”Ÿæ€è§’è‰²ï¼šä¼˜å…ˆä½¿ç”¨ diet_type å­—æ®µ
        ecological_role = _infer_ecological_role(species)
        
        # ã€ä¿®å¤ã€‘ç¡®ä¿ç§ç¾¤æ•°é‡åœ¨JavaScriptå®‰å…¨æ•´æ•°èŒƒå›´å†…
        raw_population = species.morphology_stats.get("population", 0) or 0
        MAX_SAFE_POPULATION = 9_007_199_254_740_991  # JavaScriptå®‰å…¨æ•´æ•°ä¸Šé™
        population = max(0, min(int(raw_population), MAX_SAFE_POPULATION))
        
        items.append(SpeciesListItem(
            lineage_code=species.lineage_code,
            latin_name=species.latin_name,
            common_name=species.common_name,
            population=population,
            status=species.status,
            ecological_role=ecological_role
        ))
    
    return SpeciesList(species=items)


@router.get("/species/{lineage_code}", response_model=SpeciesDetail)
def get_species_detail(lineage_code: str) -> SpeciesDetail:
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail="Species not found")
    return _serialize_species_detail(species)


@router.get("/saves/list")
def list_saves() -> list[dict]:
    """åˆ—å‡ºæ‰€æœ‰å­˜æ¡£"""
    try:
        saves = save_manager.list_saves()
        logger.debug(f"[å­˜æ¡£API] æŸ¥è¯¢åˆ° {len(saves)} ä¸ªå­˜æ¡£")
        return saves
    except Exception as e:
        logger.error(f"[å­˜æ¡£APIé”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºå­˜æ¡£å¤±è´¥: {str(e)}")


@router.post("/saves/create")
async def create_save(request: CreateSaveRequest) -> dict:
    """åˆ›å»ºæ–°å­˜æ¡£"""
    global current_save_name, autosave_counter
    try:
        logger.info(f"[å­˜æ¡£API] åˆ›å»ºå­˜æ¡£: {request.save_name}, å‰§æœ¬: {request.scenario}")
        
        # ã€å…³é”®ä¿®å¤ã€‘æ ¹æ®å‰§æœ¬è®¾ç½®åˆå§‹å›åˆ
        # ç¹è£ç”Ÿæ€å‰§æœ¬ä»150å›åˆå¼€å§‹ï¼Œå…¶ä»–å‰§æœ¬ä»0å¼€å§‹
        initial_turn = 150 if request.scenario == "ç¹è£ç”Ÿæ€" else 0
        simulation_engine.turn_counter = initial_turn
        logger.debug(f"[å­˜æ¡£API] å›åˆè®¡æ•°å™¨å·²è®¾ç½®ä¸º {initial_turn}")
        
        # ã€é‡ç½®æ¸¸æˆæœåŠ¡çŠ¶æ€ã€‘
        energy_service.reset()
        divine_progression_service.reset()
        achievement_service.reset()
        game_hints_service.clear_cooldown()
        logger.debug(f"[å­˜æ¡£API] æ¸¸æˆæœåŠ¡çŠ¶æ€å·²é‡ç½®")
        
        # è®¾ç½®å½“å‰å­˜æ¡£åç§°ï¼ˆç”¨äºè‡ªåŠ¨ä¿å­˜ï¼‰
        current_save_name = request.save_name
        autosave_counter = 0
        logger.debug(f"[å­˜æ¡£API] å½“å‰å­˜æ¡£åç§°è®¾ç½®ä¸º: {current_save_name}")
        
        # 1. æ¸…ç©ºå½“å‰æ•°æ®åº“ï¼ˆç¡®ä¿æ–°å­˜æ¡£ä»å¹²å‡€çŠ¶æ€å¼€å§‹ï¼‰
        logger.info(f"[å­˜æ¡£API] æ¸…ç©ºå½“å‰æ•°æ®...")
        from ..core.database import session_scope
        from ..models.species import Species
        from ..models.environment import MapTile, MapState, HabitatPopulation
        from ..models.history import TurnLog
        from ..models.genus import Genus
        
        with session_scope() as session:
            # åˆ é™¤æ‰€æœ‰ç‰©ç§
            for sp in session.exec(select(Species)).all():
                session.delete(sp)
            # åˆ é™¤æ‰€æœ‰åœ°å›¾æ•°æ®
            for tile in session.exec(select(MapTile)).all():
                session.delete(tile)
            for state in session.exec(select(MapState)).all():
                session.delete(state)
            for hab in session.exec(select(HabitatPopulation)).all():
                session.delete(hab)
            # åˆ é™¤å†å²è®°å½•
            for log in session.exec(select(TurnLog)).all():
                session.delete(log)
            # åˆ é™¤æ‰€æœ‰å±æ•°æ®
            for genus in session.exec(select(Genus)).all():
                session.delete(genus)
        
        logger.info(f"[å­˜æ¡£API] æ•°æ®æ¸…ç©ºå®Œæˆ")
        
        # 1.5 æ¸…é™¤æœåŠ¡å†…éƒ¨ç¼“å­˜å’Œå…¨å±€çŠ¶æ€ï¼ˆç¡®ä¿æ•°æ®éš”ç¦»ï¼‰
        logger.debug(f"[å­˜æ¡£API] æ¸…é™¤æœåŠ¡ç¼“å­˜å’Œå…¨å±€çŠ¶æ€...")
        migration_advisor.clear_all_caches()
        habitat_manager.clear_all_caches()
        dispersal_engine.clear_caches()  # æ¸…ç©ºæ‰©æ•£å¼•æ“ç¼“å­˜
        pressure_queue.clear()
        watchlist.clear()
        
        # ã€æ–°å¢ã€‘æ¸…ç©ºAIå‹åŠ›å“åº”æœåŠ¡çš„ç¼“å­˜ï¼ˆè¿ç»­å±é™©å›åˆæ•°ç­‰ï¼‰
        # AI å‹åŠ›è·¯å¾„å·²ç§»é™¤
        
        # ã€æ–°å¢ã€‘æ¸…ç©ºåˆ†åŒ–æœåŠ¡çš„ç¼“å­˜ï¼ˆå»¶è¿Ÿè¯·æ±‚ç­‰ï¼‰
        simulation_engine.speciation.clear_all_caches()
        
        # ã€æ–°å¢ã€‘å°½æ—©æ¸…ç©º embedding ç¼“å­˜ï¼ˆåœ¨åˆå§‹åŒ–ç‰©ç§ä¹‹å‰ï¼‰
        embedding_integration.clear_all_caches()
        
        logger.debug(f"[å­˜æ¡£API] æœåŠ¡ç¼“å­˜å’Œå…¨å±€çŠ¶æ€å·²æ¸…é™¤")
        
        # 2. åˆå§‹åŒ–åœ°å›¾
        logger.info(f"[å­˜æ¡£API] åˆå§‹åŒ–åœ°å›¾ï¼Œç§å­: {request.map_seed if request.map_seed else 'éšæœº'}")
        map_manager.ensure_initialized(map_seed=request.map_seed)
        
        # 3. åˆå§‹åŒ–ç‰©ç§
        if request.scenario == "ç©ºç™½å‰§æœ¬" and request.species_prompts:
            logger.info(f"[å­˜æ¡£API] ç©ºç™½å‰§æœ¬ï¼Œç”Ÿæˆ {len(request.species_prompts)} ä¸ªç‰©ç§")
            # åŠ¨æ€åˆ†é… lineage_codeï¼Œé¿å…å†²çª
            base_codes = ["A", "B", "C", "D", "E", "F", "G", "H"]
            existing_species = species_repository.list_species()
            used_codes = {sp.lineage_code[:1] for sp in existing_species}  # å·²ä½¿ç”¨çš„å­—æ¯å‰ç¼€
            
            available_codes = [code for code in base_codes if code not in used_codes]
            if len(available_codes) < len(request.species_prompts):
                raise HTTPException(
                    status_code=400, 
                    detail=f"ç‰©ç§æ•°é‡è¿‡å¤šï¼Œæœ€å¤šæ”¯æŒ {len(available_codes)} ä¸ªåˆå§‹ç‰©ç§"
                )
            
            for i, prompt in enumerate(request.species_prompts):
                lineage_code = f"{available_codes[i]}1"
                species = species_generator.generate_from_prompt(prompt, lineage_code)
                species_repository.upsert(species)
                logger.debug(f"[å­˜æ¡£API] ç”Ÿæˆç‰©ç§: {species.lineage_code} - {species.common_name}")
        elif request.scenario == "ç¹è£ç”Ÿæ€":
            # ç¹è£ç”Ÿæ€å‰§æœ¬ï¼š15ä¸ªç‰©ç§çš„æˆç†Ÿç”Ÿæ€ç³»ç»Ÿ
            logger.info(f"[å­˜æ¡£API] ç¹è£ç”Ÿæ€å‰§æœ¬ï¼ŒåŠ è½½15ä¸ªç‰©ç§...")
            from ..core.seed import seed_thriving_ecosystem
            seed_thriving_ecosystem()
        else:
            # åŸåˆå¤§é™†ï¼šä½¿ç”¨é»˜è®¤ç‰©ç§
            logger.info(f"[å­˜æ¡£API] åŸåˆå¤§é™†ï¼ŒåŠ è½½é»˜è®¤ç‰©ç§...")
            from ..core.seed import seed_defaults
            seed_defaults()
        
        # 3.5 åˆå§‹åŒ–ç‰©ç§æ –æ¯åœ°åˆ†å¸ƒï¼ˆå…³é”®ï¼ï¼‰
        logger.info(f"[å­˜æ¡£API] åˆå§‹åŒ–ç‰©ç§æ –æ¯åœ°åˆ†å¸ƒ...")
        all_species = species_repository.list_species()
        if all_species:
            map_manager.snapshot_habitats(all_species, turn_index=initial_turn, force_recalculate=True)
            logger.info(f"[å­˜æ¡£API] æ –æ¯åœ°åˆ†å¸ƒåˆå§‹åŒ–å®Œæˆï¼Œ{len(all_species)} ä¸ªç‰©ç§å·²åˆ†å¸ƒåˆ°åœ°å›¾")
        else:
            logger.warning(f"[å­˜æ¡£APIè­¦å‘Š] æ²¡æœ‰ç‰©ç§éœ€è¦åˆ†å¸ƒ")
        
        # 3.6 åˆ›å»ºåˆå§‹äººå£å¿«ç…§ï¼ˆä¿®å¤bugï¼šç³»è°±æ ‘éœ€è¦è¿™ä¸ªæ•°æ®ï¼‰
        logger.info(f"[å­˜æ¡£API] åˆ›å»ºåˆå§‹äººå£å¿«ç…§...")
        from ..models.species import PopulationSnapshot
        MAX_SAFE_POPULATION = 9_007_199_254_740_991  # JavaScriptå®‰å…¨æ•´æ•°ä¸Šé™
        if all_species:
            snapshots = []
            for species in all_species:
                # ã€ä¿®å¤ã€‘ç¡®ä¿ç§ç¾¤æ•°é‡åœ¨å®‰å…¨èŒƒå›´å†…
                raw_pop = species.morphology_stats.get("population", 0) or 0
                population = max(0, min(int(raw_pop), MAX_SAFE_POPULATION))
                if population > 0:
                    snapshots.append(PopulationSnapshot(
                        species_id=species.id or 0,
                        turn_index=initial_turn,
                        region_id=0,
                        count=population,
                        death_count=0,
                        survivor_count=population,
                        population_share=1.0 / len(all_species),
                        ecological_pressure={}
                    ))
            if snapshots:
                species_repository.add_population_snapshots(snapshots)
                logger.debug(f"[å­˜æ¡£API] åˆå§‹äººå£å¿«ç…§åˆ›å»ºå®Œæˆï¼Œ{len(snapshots)} æ¡è®°å½•")
        
        # 3.7 åˆ›å»ºåˆå§‹å›åˆæŠ¥å‘Šï¼ˆä¿®å¤bugï¼šå‰ç«¯éœ€è¦æ˜¾ç¤ºç‰©ç§æ•°é‡ï¼‰
        logger.info(f"[å­˜æ¡£API] åˆ›å»ºåˆå§‹å›åˆæŠ¥å‘Š...")
        if all_species:
            from ..schemas.responses import SpeciesSnapshot
            initial_species = []
            # è®¡ç®—æ€»äººå£ç”¨äºè®¡ç®—population_share
            # ã€ä¿®å¤ã€‘ç¡®ä¿ç§ç¾¤æ•°é‡åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆé˜²æ­¢32ä½æ•´æ•°æº¢å‡ºï¼‰
            def safe_population(sp):
                raw = sp.morphology_stats.get("population", 0) or 0
                return max(0, min(int(raw), MAX_SAFE_POPULATION))
            total_population = sum(safe_population(sp) for sp in all_species)
            for species in all_species:
                population = safe_population(species)
                population_share = (population / total_population) if total_population > 0 else 0.0
                
                # æ¨æ–­ç”Ÿæ€è§’è‰²ï¼šä¼˜å…ˆä½¿ç”¨ diet_type å­—æ®µ
                ecological_role = _infer_ecological_role(species)
                
                initial_species.append(SpeciesSnapshot(
                    lineage_code=species.lineage_code,
                    latin_name=species.latin_name,
                    common_name=species.common_name,
                    population=population,
                    population_share=population_share,
                    deaths=0,
                    death_rate=0.0,
                    niche_overlap=0.0,
                    tier="T1.0",
                    notes=[f"åˆå§‹ç‰©ç§ï¼ŒæŠ•æ”¾åˆ°{request.scenario}"],
                    status=species.status,
                    ecological_role=ecological_role,
                    # åˆå§‹çŠ¶æ€çš„åœ°å—åˆ†å¸ƒï¼ˆé»˜è®¤å€¼ï¼‰
                    total_tiles=0,
                    healthy_tiles=0,
                    warning_tiles=0,
                    critical_tiles=0,
                    best_tile_rate=0.0,
                    worst_tile_rate=0.0,
                    has_refuge=True,
                    distribution_status="åˆå§‹",
                ))
            
            # è·å–åœ°å›¾çŠ¶æ€
            map_state = environment_repository.get_state()
            
            # æ ¹æ®å‰§æœ¬ç”Ÿæˆåˆé€‚çš„å™äº‹
            if initial_turn > 0:
                narrative = f"ç¹è£ç”Ÿæ€ï¼ç»è¿‡{initial_turn}ä¸‡å¹´çš„æ¼”åŒ–ï¼Œ{len(all_species)}ä¸ªç‰©ç§å·²å»ºç«‹èµ·å¤æ‚çš„ç”Ÿæ€ç½‘ç»œã€‚æµ·æ´‹ä¸­å¥‡è™¾ç§°éœ¸ï¼Œé™†åœ°ä¸Šèœˆèš£æ¨ªè¡Œï¼Œæ·±æµ·çƒ­æ³‰å­•è‚²ç€å¥‡ç‰¹çš„å…±ç”Ÿå…³ç³»ã€‚"
            else:
                narrative = f"ä¸–ç•Œè¯ç”Ÿï¼{len(all_species)}ä¸ªç‰©ç§åœ¨{request.scenario}å¼€å§‹äº†å®ƒä»¬çš„æ¼”åŒ–ä¹‹æ—…ã€‚"
            
            initial_report = TurnReport(
                turn_index=initial_turn,
                pressures_summary="åˆå§‹çŠ¶æ€ï¼Œæ— ç¯å¢ƒå‹åŠ›" if initial_turn == 0 else "ç”Ÿæ€å¹³è¡¡ï¼Œä¸‡ç‰©ç«ç”Ÿ",
                narrative=narrative,
                species=initial_species,
                branching_events=[],
                background_summary=[],
                reemergence_events=[],
                major_events=[],
                map_changes=[],
                migration_events=[],
                sea_level=map_state.sea_level if map_state else 0.0,
                global_temperature=map_state.global_avg_temperature if map_state else 15.0,
                tectonic_stage=map_state.stage_name if map_state else "ç¨³å®šæœŸ"
            )
            
            history_repository.log_turn(
                TurnLog(
                    turn_index=initial_turn,
                    pressures_summary=initial_report.pressures_summary,
                    narrative=initial_report.narrative,
                    record_data=initial_report.model_dump(mode="json")
                )
            )
            logger.debug(f"[å­˜æ¡£API] åˆå§‹å›åˆæŠ¥å‘Šåˆ›å»ºå®Œæˆ")
        
        # 4. åˆ›å»ºå­˜æ¡£å…ƒæ•°æ®
        metadata = save_manager.create_save(request.save_name, request.scenario)
        
        # 4.5 ã€é‡è¦ã€‘åˆ‡æ¢åˆ°å­˜æ¡£ä¸“å±çš„å‘é‡ç´¢å¼•ç›®å½•
        save_dir = save_manager.get_save_dir(request.save_name)
        if save_dir:
            context_stats = embedding_integration.switch_to_save_context(save_dir)
            logger.debug(f"[å­˜æ¡£API] å·²åˆ‡æ¢åˆ°å­˜æ¡£å‘é‡ç›®å½•: {context_stats}")
        else:
            logger.warning(f"[å­˜æ¡£APIè­¦å‘Š] æœªæ‰¾åˆ°å­˜æ¡£ç›®å½•ï¼Œä½¿ç”¨å…¨å±€å‘é‡ç´¢å¼•")
        
        # 5. ç«‹å³ä¿å­˜æ¸¸æˆçŠ¶æ€åˆ°å­˜æ¡£æ–‡ä»¶
        logger.info(f"[å­˜æ¡£API] ä¿å­˜åˆå§‹æ¸¸æˆçŠ¶æ€åˆ°å­˜æ¡£æ–‡ä»¶...")
        save_manager.save_game(request.save_name, turn_index=initial_turn)
        
        # 6. æ›´æ–°ç‰©ç§æ•°é‡
        species_count = len(species_repository.list_species())
        metadata["species_count"] = species_count
        logger.info(f"[å­˜æ¡£API] å­˜æ¡£åˆ›å»ºå®Œæˆï¼Œç‰©ç§æ•°: {species_count}")
        
        return metadata
    except Exception as e:
        logger.error(f"[å­˜æ¡£APIé”™è¯¯] {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå­˜æ¡£å¤±è´¥: {str(e)}")


@router.post("/saves/save")
async def save_game(request: SaveGameRequest) -> dict:
    """ä¿å­˜å½“å‰æ¸¸æˆçŠ¶æ€"""
    try:
        # ä½¿ç”¨ turn_counterï¼ˆä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„å›åˆï¼‰è€Œéå†å²è®°å½•çš„ turn_index
        # turn_counter è¡¨ç¤º"å·²å®Œæˆçš„å›åˆæ•°"ï¼Œå³ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„å›åˆç´¢å¼•
        turn_index = simulation_engine.turn_counter
        
        # ã€æ–°å¢ã€‘è·å– Embedding é›†æˆæ•°æ®
        taxonomy_data = None
        event_embeddings = None
        try:
            integration_data = embedding_integration.export_for_save()
            taxonomy_data = integration_data.get("taxonomy")
            event_embeddings = integration_data.get("narrative")
        except Exception as e:
            logger.warning(f"[å­˜æ¡£API] è·å–Embeddingé›†æˆæ•°æ®å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
        
        save_dir = save_manager.save_game(
            request.save_name, 
            turn_index,
            taxonomy_data=taxonomy_data,
            event_embeddings=event_embeddings
        )
        return {"success": True, "save_dir": str(save_dir), "turn_index": turn_index}
    except Exception as e:
        logger.error(f"[å­˜æ¡£APIé”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜æ¸¸æˆå¤±è´¥: {str(e)}")


@router.post("/saves/load")
async def load_game(request: LoadGameRequest) -> dict:
    """åŠ è½½æ¸¸æˆå­˜æ¡£"""
    global current_save_name, autosave_counter
    try:
        # æ¸…é™¤æœåŠ¡å†…éƒ¨ç¼“å­˜å’Œå…¨å±€çŠ¶æ€ï¼ˆç¡®ä¿æ•°æ®éš”ç¦»ï¼‰
        logger.info(f"[å­˜æ¡£åŠ è½½] æ¸…é™¤æœåŠ¡ç¼“å­˜å’Œå…¨å±€çŠ¶æ€...")
        migration_advisor.clear_all_caches()
        habitat_manager.clear_all_caches()
        dispersal_engine.clear_caches()  # æ¸…ç©ºæ‰©æ•£å¼•æ“ç¼“å­˜
        pressure_queue.clear()
        watchlist.clear()
        
        # ã€æ–°å¢ã€‘æ¸…ç©ºAIå‹åŠ›å“åº”æœåŠ¡çš„ç¼“å­˜ï¼ˆè¿ç»­å±é™©å›åˆæ•°ç­‰ï¼‰
        # AI å‹åŠ›è·¯å¾„å·²ç§»é™¤
        
        # ã€æ–°å¢ã€‘æ¸…ç©ºåˆ†åŒ–æœåŠ¡çš„ç¼“å­˜ï¼ˆå»¶è¿Ÿè¯·æ±‚ç­‰ï¼‰
        simulation_engine.speciation.clear_all_caches()
        
        logger.debug(f"[å­˜æ¡£åŠ è½½] æœåŠ¡ç¼“å­˜å’Œå…¨å±€çŠ¶æ€å·²æ¸…é™¤")
        
        # ã€é‡è¦ã€‘åˆ‡æ¢åˆ°å­˜æ¡£ä¸“å±çš„å‘é‡ç´¢å¼•ç›®å½•ï¼ˆåŒæ—¶æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼‰
        save_dir = save_manager.get_save_dir(request.save_name)
        if save_dir:
            context_stats = embedding_integration.switch_to_save_context(save_dir)
            logger.debug(f"[å­˜æ¡£åŠ è½½] å·²åˆ‡æ¢åˆ°å­˜æ¡£å‘é‡ç›®å½•: {context_stats}")
        else:
            # å­˜æ¡£ç›®å½•ä¸å­˜åœ¨æ—¶ä»éœ€æ¸…ç©ºç¼“å­˜
            embedding_integration.clear_all_caches()
            logger.warning(f"[å­˜æ¡£åŠ è½½è­¦å‘Š] æœªæ‰¾åˆ°å­˜æ¡£ç›®å½•ï¼Œä½¿ç”¨å…¨å±€å‘é‡ç´¢å¼•")
        
        save_data = save_manager.load_game(request.save_name)
        turn_index = save_data.get("turn_index", 0)
        
        # ã€å…³é”®ä¿®å¤ã€‘æ›´æ–° simulation_engine çš„å›åˆè®¡æ•°å™¨
        simulation_engine.turn_counter = turn_index
        logger.info(f"[å­˜æ¡£åŠ è½½] å·²æ¢å¤å›åˆè®¡æ•°å™¨: {turn_index}")
        
        # ã€æ–°å¢ã€‘æ¢å¤ Embedding é›†æˆæ•°æ®
        try:
            integration_restore_data = {}
            if save_data.get("taxonomy"):
                integration_restore_data["taxonomy"] = save_data["taxonomy"]
            if save_data.get("event_embeddings"):
                integration_restore_data["narrative"] = save_data["event_embeddings"]
            if integration_restore_data:
                embedding_integration.import_from_save(integration_restore_data)
                logger.debug(f"[å­˜æ¡£åŠ è½½] Embeddingé›†æˆæ•°æ®å·²æ¢å¤")
        except Exception as e:
            logger.warning(f"[å­˜æ¡£åŠ è½½] æ¢å¤Embeddingé›†æˆæ•°æ®å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
        
        # è®¾ç½®å½“å‰å­˜æ¡£åç§°ï¼ˆç”¨äºè‡ªåŠ¨ä¿å­˜ï¼‰
        # å¦‚æœåŠ è½½çš„æ˜¯è‡ªåŠ¨ä¿å­˜ï¼Œæå–åŸå§‹å­˜æ¡£å
        if request.save_name.startswith("autosave_"):
            # æ ¼å¼: autosave_{åŸå­˜æ¡£å}_{æ—¶é—´æˆ³}
            parts = request.save_name.split("_")
            if len(parts) >= 3:
                # é‡å»ºåŸå§‹å­˜æ¡£åï¼ˆå¯èƒ½åŒ…å«ä¸‹åˆ’çº¿ï¼‰
                current_save_name = "_".join(parts[1:-2]) if len(parts) > 3 else parts[1]
            else:
                current_save_name = request.save_name
        else:
            current_save_name = request.save_name
        autosave_counter = 0
        logger.info(f"[å­˜æ¡£åŠ è½½] å½“å‰å­˜æ¡£åç§°è®¾ç½®ä¸º: {current_save_name}")
        
        # ã€æ–°å¢ã€‘å­˜æ¡£æ¢å¤æ—¶é‡å»ºé£Ÿç‰©ç½‘ï¼ˆå¯é€‰ï¼‰
        try:
            from ..repositories.environment_repository import environment_repository
            from pathlib import Path
            ui_config = environment_repository.load_ui_config(Path(settings.ui_config_path))
            
            if ui_config.food_web.rebuild_food_web_on_load:
                from ..repositories.species_repository import species_repository
                all_species = species_repository.list_species()
                
                rebuild_count = simulation_engine.food_web_manager.rebuild_food_web(
                    all_species, species_repository,
                    preserve_valid_links=ui_config.food_web.preserve_valid_links_on_rebuild
                )
                
                if rebuild_count > 0:
                    logger.info(f"[å­˜æ¡£åŠ è½½] é£Ÿç‰©ç½‘é‡å»ºå®Œæˆï¼Œæ›´æ–°äº† {rebuild_count} ä¸ªç‰©ç§")
        except Exception as e:
            logger.warning(f"[å­˜æ¡£åŠ è½½] é£Ÿç‰©ç½‘é‡å»ºå¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
        
        return {"success": True, "turn_index": turn_index}
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"[å­˜æ¡£APIé”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"åŠ è½½æ¸¸æˆå¤±è´¥: {str(e)}")


@router.delete("/saves/{save_name}")
def delete_save(save_name: str) -> dict:
    """åˆ é™¤å­˜æ¡£"""
    try:
        success = save_manager.delete_save(save_name)
        if not success:
            raise HTTPException(status_code=404, detail="å­˜æ¡£ä¸å­˜åœ¨")
        return {"success": True}
    except Exception as e:
        logger.error(f"[å­˜æ¡£APIé”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å­˜æ¡£å¤±è´¥: {str(e)}")


@router.post("/species/generate")
def generate_species(request: GenerateSpeciesRequest) -> dict:
    """ä½¿ç”¨AIç”Ÿæˆç‰©ç§
    
    æ¶ˆè€—èƒ½é‡ç‚¹ã€‚
    """
    current_turn = simulation_engine.turn_counter
    
    # ã€èƒ½é‡ç³»ç»Ÿã€‘æ£€æŸ¥èƒ½é‡
    can_afford, cost = energy_service.can_afford("create_species")
    if not can_afford:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼åˆ›é€ ç‰©ç§éœ€è¦ {cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    try:
        # å…ˆæ¶ˆè€—èƒ½é‡
        success, msg = energy_service.spend(
            "create_species",
            current_turn,
            details=f"åˆ›é€ ç‰©ç§: {request.prompt[:30]}..."
        )
        if not success:
            raise HTTPException(status_code=400, detail=msg)
        
        species = species_generator.generate_from_prompt(request.prompt, request.lineage_code)
        species_repository.upsert(species)
        
        # è®°å½•æˆå°±
        achievement_service.record_species_creation(current_turn)
        
        return {
            "success": True,
            "species": {
                "lineage_code": species.lineage_code,
                "latin_name": species.latin_name,
                "common_name": species.common_name,
                "description": species.description,
            },
            "energy_spent": cost,
            "energy_remaining": energy_service.get_state().current,
        }
    except HTTPException:
        raise
    except Exception as e:
        # ç”Ÿæˆå¤±è´¥ï¼Œé€€è¿˜èƒ½é‡
        energy_service.add_energy(cost, "åˆ›é€ ç‰©ç§å¤±è´¥é€€è¿˜")
        logger.error(f"[ç‰©ç§ç”ŸæˆAPIé”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç‰©ç§å¤±è´¥: {str(e)}")


@router.post("/species/generate/advanced")
def generate_species_advanced(request: GenerateSpeciesAdvancedRequest) -> dict:
    """å¢å¼ºç‰ˆç‰©ç§ç”Ÿæˆ - æ”¯æŒå®Œæ•´å‚æ•°
    
    æ”¯æŒé¢„è®¾æ –æ¯åœ°ã€é£Ÿæ€§ã€çŒç‰©ã€çˆ¶ä»£ç‰©ç§ï¼ˆç¥å¯åˆ†åŒ–ï¼‰ç­‰å‚æ•°ã€‚
    æ¶ˆè€—èƒ½é‡ç‚¹ã€‚
    """
    current_turn = simulation_engine.turn_counter
    
    # è‡ªåŠ¨ç”Ÿæˆlineage_codeå¦‚æœæœªæä¾›
    lineage_code = request.lineage_code
    if not lineage_code:
        existing_species = species_repository.get_all()
        used_codes = {s.lineage_code for s in existing_species}
        prefix = "S"
        index = 1
        while f"{prefix}{index}" in used_codes:
            index += 1
        lineage_code = f"{prefix}{index}"
    
    # ã€èƒ½é‡ç³»ç»Ÿã€‘æ£€æŸ¥èƒ½é‡
    can_afford, cost = energy_service.can_afford("create_species")
    if not can_afford:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼åˆ›é€ ç‰©ç§éœ€è¦ {cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    try:
        # å…ˆæ¶ˆè€—èƒ½é‡
        success, msg = energy_service.spend(
            "create_species",
            current_turn,
            details=f"åˆ›é€ ç‰©ç§(å¢å¼ºç‰ˆ): {request.prompt[:30]}..."
        )
        if not success:
            raise HTTPException(status_code=400, detail=msg)
        
        # è·å–ç°æœ‰ç‰©ç§åˆ—è¡¨
        existing_species = species_repository.get_all()
        
        # ä½¿ç”¨å¢å¼ºç‰ˆç”Ÿæˆæ–¹æ³•
        species = species_generator.generate_advanced(
            prompt=request.prompt,
            lineage_code=lineage_code,
            existing_species=existing_species,
            habitat_type=request.habitat_type,
            diet_type=request.diet_type,
            prey_species=request.prey_species,
            parent_code=request.parent_code,
            is_plant=request.is_plant,
            plant_stage=request.plant_stage,
        )
        species_repository.upsert(species)
        
        # è®°å½•æˆå°±
        achievement_service.record_species_creation(current_turn)
        
        return {
            "success": True,
            "species": {
                "lineage_code": species.lineage_code,
                "latin_name": species.latin_name,
                "common_name": species.common_name,
                "description": species.description,
                "habitat_type": species.habitat_type,
                "diet_type": species.diet_type,
                "trophic_level": species.trophic_level,
                "parent_code": species.parent_code,
            },
            "energy_spent": cost,
            "energy_remaining": energy_service.get_state().current,
        }
    except HTTPException:
        raise
    except Exception as e:
        # ç”Ÿæˆå¤±è´¥ï¼Œé€€è¿˜èƒ½é‡
        energy_service.add_energy(cost, "åˆ›é€ ç‰©ç§å¤±è´¥é€€è¿˜")
        logger.error(f"[ç‰©ç§ç”ŸæˆAPI(å¢å¼ºç‰ˆ)é”™è¯¯] {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç‰©ç§å¤±è´¥: {str(e)}")


@router.post("/config/test-api")
def test_api_connection(request: dict) -> dict:
    """æµ‹è¯• API è¿æ¥æ˜¯å¦æœ‰æ•ˆï¼Œæ”¯æŒ OpenAI/Claude/Gemini å¤šç§APIæ ¼å¼"""
    
    api_type = request.get("type", "chat")  # chat æˆ– embedding
    base_url = request.get("base_url", "").rstrip("/")
    api_key = request.get("api_key", "")
    model = request.get("model", "")
    provider_type = request.get("provider_type", "openai")  # openai, anthropic, google
    
    if not base_url or not api_key:
        return {"success": False, "message": "è¯·æä¾› API Base URL å’Œ API Key"}
    
    try:
        if api_type == "embedding":
            # æµ‹è¯• embedding API (ä»…æ”¯æŒ OpenAI å…¼å®¹æ ¼å¼)
            if not model:
                return {
                    "success": False,
                    "message": "è¯·æŒ‡å®šè¦æµ‹è¯•çš„å‘é‡æ¨¡å‹åç§°",
                    "details": "è¯·åœ¨æœåŠ¡å•†è®¾ç½®ä¸­é€‰æ‹©æˆ–è¾“å…¥ä¸€ä¸ªå‘é‡æ¨¡å‹åç§°"
                }
            url = f"{base_url}/embeddings"
            body = {
                "model": model,
                "input": "test"
            }
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            logger.debug(f"[æµ‹è¯• Embedding] URL: {url}")
            logger.debug(f"[æµ‹è¯• Embedding] Model: {model}")
            
            response = httpx.post(url, json=body, headers=headers, timeout=20)
            response.raise_for_status()
            data = response.json()
            
            if "data" in data and len(data["data"]) > 0:
                embedding_dim = len(data["data"][0].get("embedding", []))
                return {
                    "success": True,
                    "message": f"âœ… å‘é‡æ¨¡å‹è¿æ¥æˆåŠŸï¼",
                    "details": f"æ¨¡å‹ï¼š{model or 'default'} | å‘é‡ç»´åº¦ï¼š{embedding_dim}"
                }
            else:
                return {
                    "success": False,
                    "message": "API å“åº”æ ¼å¼ä¸æ­£ç¡®",
                    "details": f"å“åº”ï¼š{str(data)[:100]}"
                }
        
        # ========== Chat API æµ‹è¯• ==========
        
        if provider_type == "anthropic":
            # Claude åŸç”Ÿ API
            url = f"{base_url}/messages"
            body = {
                "model": model,  # å¿…é¡»ç”±å‰ç«¯ä¼ å…¥
                "max_tokens": 10,
                "messages": [{"role": "user", "content": "hi"}]
            }
            headers = {
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json"
            }
            
            logger.debug(f"[æµ‹è¯• Claude] URL: {url} | Model: {model}")
            
            response = httpx.post(url, json=body, headers=headers, timeout=20)
            response.raise_for_status()
            data = response.json()
            
            if "content" in data and len(data.get("content", [])) > 0:
                return {
                    "success": True,
                    "message": f"âœ… Claude API è¿æ¥æˆåŠŸï¼",
                    "details": f"æ¨¡å‹ï¼š{data.get('model', model)} | å“åº”æ—¶é—´ï¼š{response.elapsed.total_seconds():.2f}s"
                }
            else:
                return {
                    "success": False,
                    "message": "API å“åº”æ ¼å¼ä¸æ­£ç¡®",
                    "details": f"å“åº”ï¼š{str(data)[:100]}"
                }
                
        elif provider_type == "google":
            # Gemini åŸç”Ÿ API
            if not model:
                return {
                    "success": False,
                    "message": "è¯·æŒ‡å®šè¦æµ‹è¯•çš„æ¨¡å‹åç§°",
                    "details": "è¯·åœ¨æœåŠ¡å•†è®¾ç½®ä¸­é€‰æ‹©æˆ–è¾“å…¥ä¸€ä¸ª Gemini æ¨¡å‹åç§°"
                }
            url = f"{base_url}/models/{model}:generateContent?key={api_key}"
            body = {
                "contents": [{"role": "user", "parts": [{"text": "hi"}]}]
            }
            headers = {"Content-Type": "application/json"}
            
            logger.debug(f"[æµ‹è¯• Gemini] URL: {url}")
            
            response = httpx.post(url, json=body, headers=headers, timeout=20)
            response.raise_for_status()
            data = response.json()
            
            candidates = data.get("candidates", [])
            if candidates and candidates[0].get("content", {}).get("parts"):
                return {
                    "success": True,
                    "message": f"âœ… Gemini API è¿æ¥æˆåŠŸï¼",
                    "details": f"æ¨¡å‹ï¼š{model} | å“åº”æ—¶é—´ï¼š{response.elapsed.total_seconds():.2f}s"
                }
            else:
                return {
                    "success": False,
                    "message": "API å“åº”æ ¼å¼ä¸æ­£ç¡®",
                    "details": f"å“åº”ï¼š{str(data)[:100]}"
                }
        
        else:
            # OpenAI å…¼å®¹æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
            # URL æ„å»ºä¼˜åŒ–ï¼šè‡ªåŠ¨é€‚é…ä¸åŒçš„ API Base é£æ ¼
            if base_url.endswith("/v1"):
                url = f"{base_url}/chat/completions"
            elif "/v1" in base_url:
                if "chat/completions" not in base_url:
                    url = f"{base_url}/chat/completions" if base_url.endswith("/") else f"{base_url}/chat/completions"
                else:
                    url = base_url
            elif "openai.azure.com" in base_url:
                 url = f"{base_url}/chat/completions"
            elif "chat/completions" in base_url:
                url = base_url
            else:
                url = f"{base_url}/v1/chat/completions"

            # å¦‚æœæœªæŒ‡å®šæ¨¡å‹ï¼Œè¦æ±‚å‰ç«¯ä¼ å…¥
            if not model:
                return {
                    "success": False,
                    "message": "è¯·æŒ‡å®šè¦æµ‹è¯•çš„æ¨¡å‹åç§°",
                    "details": "è¯·åœ¨æœåŠ¡å•†è®¾ç½®ä¸­é€‰æ‹©æˆ–è¾“å…¥ä¸€ä¸ªæ¨¡å‹åç§°"
                }
            
            logger.debug(f"[æµ‹è¯• Chat] URL: {url} | Model: {model}")

            body = {
                "model": model,
                "messages": [{"role": "user", "content": "hi"}],
                "max_tokens": 5
            }
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            response = httpx.post(url, json=body, headers=headers, timeout=20)
            response.raise_for_status()
            data = response.json()
            
            if "choices" in data and len(data["choices"]) > 0:
                return {
                    "success": True,
                    "message": f"âœ… API è¿æ¥æˆåŠŸï¼",
                    "details": f"æ¨¡å‹ï¼š{model or 'default'} | å“åº”æ—¶é—´ï¼š{response.elapsed.total_seconds():.2f}s"
                }
            else:
                return {
                    "success": False,
                    "message": "API å“åº”æ ¼å¼ä¸æ­£ç¡®",
                    "details": f"å“åº”ï¼š{str(data)[:100]}"
                }
                
    except httpx.HTTPStatusError as e:
        error_text = e.response.text
        try:
            error_json = json.loads(error_text)
            # ä¸åŒ API çš„é”™è¯¯æ ¼å¼
            if provider_type == "anthropic":
                error_msg = error_json.get("error", {}).get("message", error_text[:200])
            elif provider_type == "google":
                error_msg = error_json.get("error", {}).get("message", error_text[:200])
            else:
                error_msg = error_json.get("error", {}).get("message", error_text[:200])
        except:
            error_msg = error_text[:200]
        
        # å¦‚æœæ˜¯ 400 é”™è¯¯ï¼Œå¯èƒ½æ˜¯æ¨¡å‹åç§°ä¸å¯¹
        hint = ""
        if e.response.status_code == 400:
            hint = f"\nğŸ’¡ æµ‹è¯•æ¨¡å‹: {model} - è¯·ç¡®è®¤è¯¥æ¨¡å‹åç§°æ­£ç¡®"
        
        return {
            "success": False,
            "message": f"âŒ HTTP é”™è¯¯ {e.response.status_code}",
            "details": f"{error_msg}{hint}"
        }
    except httpx.TimeoutException:
        return {
            "success": False,
            "message": "âŒ è¿æ¥è¶…æ—¶",
            "details": "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– API åœ°å€æ˜¯å¦æ­£ç¡®"
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ è¿æ¥å¤±è´¥",
            "details": str(e)
        }


@router.post("/config/fetch-models")
def fetch_models(request: dict) -> dict:
    """è·å–æœåŠ¡å•†çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    æ”¯æŒ OpenAI å…¼å®¹æ ¼å¼ã€Claude åŸç”Ÿ APIã€Gemini åŸç”Ÿ API
    """
    base_url = request.get("base_url", "").rstrip("/")
    api_key = request.get("api_key", "")
    provider_type = request.get("provider_type", "openai")
    
    if not base_url or not api_key:
        return {"success": False, "message": "è¯·æä¾› API Base URL å’Œ API Key", "models": []}
    
    try:
        models = []
        
        if provider_type == "anthropic":
            # Claude API - ä½¿ç”¨å›ºå®šçš„æ¨¡å‹åˆ—è¡¨ï¼ˆAnthropic æš‚ä¸æä¾› /models ç«¯ç‚¹çš„å…¬å¼€è®¿é—®ï¼‰
            # ä½†å¯ä»¥å°è¯•è°ƒç”¨çœ‹çœ‹
            url = f"{base_url}/models"
            headers = {
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json"
            }
            
            try:
                response = httpx.get(url, headers=headers, timeout=15)
                if response.status_code == 200:
                    data = response.json()
                    # Anthropic è¿”å›æ ¼å¼: {"data": [{"id": "claude-xxx", ...}]}
                    for model in data.get("data", []):
                        model_id = model.get("id", "")
                        if model_id:
                            models.append({
                                "id": model_id,
                                "name": model_id,
                                "description": model.get("display_name", ""),
                                "context_window": model.get("context_window"),
                            })
            except:
                pass
            
            # å¦‚æœ API è·å–å¤±è´¥ï¼Œä½¿ç”¨å·²çŸ¥çš„ Claude æ¨¡å‹åˆ—è¡¨
            if not models:
                models = [
                    {"id": "claude-sonnet-4-20250514", "name": "Claude Sonnet 4", "description": "æœ€æ–°çš„ Claude 4 æ¨¡å‹", "context_window": 200000},
                    {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet", "description": "å¼ºå¤§ä¸”å¿«é€Ÿçš„æ¨¡å‹", "context_window": 200000},
                    {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "description": "å¿«é€Ÿä¸”ç»æµçš„æ¨¡å‹", "context_window": 200000},
                    {"id": "claude-3-opus-20240229", "name": "Claude 3 Opus", "description": "æœ€å¼ºå¤§çš„ Claude 3 æ¨¡å‹", "context_window": 200000},
                    {"id": "claude-3-sonnet-20240229", "name": "Claude 3 Sonnet", "description": "å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦", "context_window": 200000},
                    {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "description": "æœ€å¿«é€Ÿçš„æ¨¡å‹", "context_window": 200000},
                ]
                
        elif provider_type == "google":
            # Gemini API
            url = f"{base_url}/models?key={api_key}"
            headers = {"Content-Type": "application/json"}
            
            logger.debug(f"[è·å–æ¨¡å‹] Gemini URL: {url}")
            
            response = httpx.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            data = response.json()
            
            # Gemini è¿”å›æ ¼å¼: {"models": [{"name": "models/gemini-xxx", "displayName": "...", ...}]}
            for model in data.get("models", []):
                model_name = model.get("name", "")
                # ç§»é™¤ "models/" å‰ç¼€
                model_id = model_name.replace("models/", "") if model_name.startswith("models/") else model_name
                
                # åªä¿ç•™ generateContent æ–¹æ³•å¯ç”¨çš„æ¨¡å‹
                supported_methods = model.get("supportedGenerationMethods", [])
                if "generateContent" not in supported_methods:
                    continue
                    
                if model_id:
                    models.append({
                        "id": model_id,
                        "name": model.get("displayName", model_id),
                        "description": model.get("description", ""),
                        "context_window": model.get("inputTokenLimit"),
                    })
                    
        else:
            # OpenAI å…¼å®¹æ ¼å¼
            # æ„å»º URL
            if base_url.endswith("/v1"):
                url = f"{base_url}/models"
            elif "/v1" in base_url:
                url = f"{base_url}/models"
            else:
                url = f"{base_url}/v1/models"
                
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            logger.debug(f"[è·å–æ¨¡å‹] OpenAI å…¼å®¹ URL: {url}")
            
            response = httpx.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            data = response.json()
            
            # OpenAI è¿”å›æ ¼å¼: {"data": [{"id": "gpt-4", "object": "model", ...}]}
            for model in data.get("data", []):
                model_id = model.get("id", "")
                if model_id:
                    # è¿‡æ»¤æ‰ä¸€äº›éèŠå¤©æ¨¡å‹ï¼ˆå¦‚ embeddingã€whisper ç­‰ï¼‰
                    skip_prefixes = ("text-embedding", "whisper", "tts", "dall-e", "davinci", "babbage", "ada", "curie")
                    if any(model_id.lower().startswith(p) for p in skip_prefixes):
                        continue
                        
                    models.append({
                        "id": model_id,
                        "name": model_id,
                        "description": model.get("owned_by", ""),
                        "context_window": None,
                    })
        
        # æŒ‰åç§°æ’åº
        models.sort(key=lambda m: m.get("name", "").lower())
        
        return {
            "success": True,
            "message": f"è·å–åˆ° {len(models)} ä¸ªæ¨¡å‹",
            "models": models
        }
        
    except httpx.HTTPStatusError as e:
        error_text = e.response.text
        try:
            error_json = json.loads(error_text)
            error_msg = error_json.get("error", {}).get("message", error_text[:200])
        except:
            error_msg = error_text[:200]
        
        return {
            "success": False,
            "message": f"HTTP é”™è¯¯ {e.response.status_code}: {error_msg}",
            "models": []
        }
    except httpx.TimeoutException:
        return {
            "success": False,
            "message": "è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ",
            "models": []
        }
    except Exception as e:
        logger.error(f"[è·å–æ¨¡å‹] é”™è¯¯: {e}")
        return {
            "success": False,
            "message": f"è·å–å¤±è´¥: {str(e)}",
            "models": []
        }


@router.post("/niche/compare", response_model=NicheCompareResult)
def compare_niche(request: NicheCompareRequest) -> NicheCompareResult:
    """å¯¹æ¯”ä¸¤ä¸ªç‰©ç§çš„ç”Ÿæ€ä½ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    ä¸‰ä¸ªæŒ‡æ ‡æœ‰æ˜ç¡®ä¸åŒçš„ç”Ÿæ€å­¦å«ä¹‰ï¼š
    - similarity: ç‰¹å¾æè¿°çš„è¯­ä¹‰ç›¸ä¼¼ç¨‹åº¦
    - overlap: èµ„æºåˆ©ç”¨ã€æ –æ¯åœ°ã€ç”Ÿæ€åŠŸèƒ½çš„å®é™…é‡å 
    - competition_intensity: è€ƒè™‘ç§ç¾¤å‹åŠ›å’Œèµ„æºç¨€ç¼ºçš„çœŸå®ç«äº‰
    """
    import numpy as np
    from ..services.species.niche_compare import compute_niche_metrics
    
    # è·å–ä¸¤ä¸ªç‰©ç§
    species_a = species_repository.get_by_lineage(request.species_a)
    species_b = species_repository.get_by_lineage(request.species_b)
    
    if not species_a:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {request.species_a} ä¸å­˜åœ¨")
    if not species_b:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {request.species_b} ä¸å­˜åœ¨")
    
    logger.debug(f"[ç”Ÿæ€ä½å¯¹æ¯”] å¯¹æ¯”ç‰©ç§: {species_a.common_name} vs {species_b.common_name}")
    
    # è·å–embeddingç›¸ä¼¼åº¦ï¼ˆç”¨äºç›¸ä¼¼åº¦è®¡ç®—ï¼‰
    embedding_similarity = None
    try:
        vectors = embedding_service.embed(
            [species_a.description, species_b.description], 
            require_real=True
        )
        vec_a = np.array(vectors[0], dtype=float)
        vec_b = np.array(vectors[1], dtype=float)
        
        norm_a = np.linalg.norm(vec_a)
        norm_b = np.linalg.norm(vec_b)
        
        if norm_a > 0 and norm_b > 0:
            embedding_similarity = float(np.dot(vec_a, vec_b) / (norm_a * norm_b))
            embedding_similarity = max(0.0, min(1.0, embedding_similarity))
            logger.debug(f"[ç”Ÿæ€ä½å¯¹æ¯”] ä½¿ç”¨embeddingå‘é‡, ç›¸ä¼¼åº¦={embedding_similarity:.3f}")
    except (RuntimeError, Exception) as e:
        logger.debug(f"[ç”Ÿæ€ä½å¯¹æ¯”] EmbeddingæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨å±æ€§è®¡ç®—: {str(e)}")
    
    # ä½¿ç”¨æ–°çš„å‘é‡åŒ–ç”Ÿæ€ä½è®¡ç®—æ¨¡å—
    niche_result = compute_niche_metrics(
        species_a, species_b,
        embedding_similarity=embedding_similarity
    )
    
    similarity = niche_result.similarity
    overlap = niche_result.overlap
    competition_intensity = niche_result.competition
    
    logger.debug(f"[ç”Ÿæ€ä½å¯¹æ¯”] ç»“æœ: ç›¸ä¼¼åº¦={similarity:.1%}, é‡å åº¦={overlap:.1%}, ç«äº‰å¼ºåº¦={competition_intensity:.1%}")
    logger.debug(f"[ç”Ÿæ€ä½å¯¹æ¯”] é‡å åº¦åˆ†è§£: {niche_result.details.get('overlap_breakdown', {})}")
    
    # ä¿ç•™åŸæœ‰å˜é‡ç”¨äºåç»­é€»è¾‘
    pop_a = float(species_a.morphology_stats.get("population", 0) or 0)
    pop_b = float(species_b.morphology_stats.get("population", 0) or 0)
    
    # æå–å…³é”®ç»´åº¦å¯¹æ¯”
    niche_dimensions = {
        "ç§ç¾¤æ•°é‡": {
            "species_a": pop_a,
            "species_b": pop_b
        },
        "ä½“é•¿(cm)": {
            "species_a": float(species_a.morphology_stats.get("body_length_cm", 0)),
            "species_b": float(species_b.morphology_stats.get("body_length_cm", 0))
        },
        "ä½“é‡(g)": {
            "species_a": float(species_a.morphology_stats.get("body_weight_g", 0)),
            "species_b": float(species_b.morphology_stats.get("body_weight_g", 0))
        },
        "å¯¿å‘½(å¤©)": {
            "species_a": float(species_a.morphology_stats.get("lifespan_days", 0)),
            "species_b": float(species_b.morphology_stats.get("lifespan_days", 0))
        },
        "ä»£è°¢ç‡": {
            "species_a": float(species_a.morphology_stats.get("metabolic_rate", 0)),
            "species_b": float(species_b.morphology_stats.get("metabolic_rate", 0))
        },
        "ç¹æ®–é€Ÿåº¦": {
            "species_a": float(species_a.abstract_traits.get("ç¹æ®–é€Ÿåº¦", 0)),
            "species_b": float(species_b.abstract_traits.get("ç¹æ®–é€Ÿåº¦", 0))
        },
        "è¿åŠ¨èƒ½åŠ›": {
            "species_a": float(species_a.abstract_traits.get("è¿åŠ¨èƒ½åŠ›", 0)),
            "species_b": float(species_b.abstract_traits.get("è¿åŠ¨èƒ½åŠ›", 0))
        },
        "ç¤¾ä¼šæ€§": {
            "species_a": float(species_a.abstract_traits.get("ç¤¾ä¼šæ€§", 0)),
            "species_b": float(species_b.abstract_traits.get("ç¤¾ä¼šæ€§", 0))
        }
    }
    
    # æ·»åŠ ç¯å¢ƒé€‚åº”æ€§å¯¹æ¯”
    env_traits = ["è€å¯’æ€§", "è€çƒ­æ€§", "è€æ—±æ€§", "è€ç›æ€§", "å…‰ç…§éœ€æ±‚", "æ°§æ°”éœ€æ±‚"]
    for trait in env_traits:
        if trait in species_a.abstract_traits or trait in species_b.abstract_traits:
            niche_dimensions[trait] = {
                "species_a": float(species_a.abstract_traits.get(trait, 0)),
                "species_b": float(species_b.abstract_traits.get(trait, 0))
            }
    
    return NicheCompareResult(
        species_a=SpeciesDetail(
            lineage_code=species_a.lineage_code,
            latin_name=species_a.latin_name,
            common_name=species_a.common_name,
            description=species_a.description,
            morphology_stats=species_a.morphology_stats,
            abstract_traits=species_a.abstract_traits,
            hidden_traits=species_a.hidden_traits,
            status=species_a.status,
            organs=species_a.organs,
            capabilities=species_a.capabilities,
            genus_code=species_a.genus_code,
            taxonomic_rank=species_a.taxonomic_rank,
            trophic_level=species_a.trophic_level,
            hybrid_parent_codes=species_a.hybrid_parent_codes,
            hybrid_fertility=species_a.hybrid_fertility,
            parent_code=species_a.parent_code,
            created_turn=species_a.created_turn,
            dormant_genes=species_a.dormant_genes,
            stress_exposure=species_a.stress_exposure,
        ),
        species_b=SpeciesDetail(
            lineage_code=species_b.lineage_code,
            latin_name=species_b.latin_name,
            common_name=species_b.common_name,
            description=species_b.description,
            morphology_stats=species_b.morphology_stats,
            abstract_traits=species_b.abstract_traits,
            hidden_traits=species_b.hidden_traits,
            status=species_b.status,
            organs=species_b.organs,
            capabilities=species_b.capabilities,
            genus_code=species_b.genus_code,
            taxonomic_rank=species_b.taxonomic_rank,
            trophic_level=species_b.trophic_level,
            hybrid_parent_codes=species_b.hybrid_parent_codes,
            hybrid_fertility=species_b.hybrid_fertility,
            parent_code=species_b.parent_code,
            created_turn=species_b.created_turn,
            dormant_genes=species_b.dormant_genes,
            stress_exposure=species_b.stress_exposure,
        ),
        similarity=similarity,
        overlap=overlap,
        competition_intensity=competition_intensity,
        niche_dimensions=niche_dimensions
    )


@router.get("/species/{code1}/can_hybridize/{code2}", tags=["species"])
def check_hybridization(code1: str, code2: str) -> dict:
    """æ£€æŸ¥ä¸¤ä¸ªç‰©ç§èƒ½å¦æ‚äº¤"""
    species_a = species_repository.get_by_code(code1)
    species_b = species_repository.get_by_code(code2)
    
    if not species_a or not species_b:
        raise HTTPException(status_code=404, detail="ç‰©ç§ä¸å­˜åœ¨")
    
    genus = genus_repository.get_by_code(species_a.genus_code)
    distance_key = f"{min(code1, code2)}-{max(code1, code2)}"
    genetic_distance = genus.genetic_distances.get(distance_key, 0.5) if genus else 0.5
    
    can_hybrid, fertility = hybridization_service.can_hybridize(species_a, species_b, genetic_distance)
    
    if not can_hybrid:
        if species_a.genus_code != species_b.genus_code:
            reason = "ä¸åŒå±ç‰©ç§æ— æ³•æ‚äº¤"
        elif genetic_distance >= 0.5:
            reason = f"é—ä¼ è·ç¦»è¿‡å¤§({genetic_distance:.2f})ï¼Œæ— æ³•æ‚äº¤"
        else:
            reason = "ä¸æ»¡è¶³æ‚äº¤æ¡ä»¶"
    else:
        reason = f"è¿‘ç¼˜ç‰©ç§ï¼Œé—ä¼ è·ç¦»{genetic_distance:.2f}ï¼Œå¯æ‚äº¤"
    
    return {
        "can_hybridize": can_hybrid,
        "fertility": round(fertility, 3),
        "genetic_distance": round(genetic_distance, 3),
        "reason": reason
    }


@router.get("/genus/{code}/relationships", tags=["species"])
def get_genetic_relationships(code: str) -> dict:
    """è·å–å±å†…é—ä¼ å…³ç³»"""
    genus = genus_repository.get_by_code(code)
    if not genus:
        raise HTTPException(status_code=404, detail="å±ä¸å­˜åœ¨")
    
    all_species = species_repository.list_species()
    genus_species = [sp for sp in all_species if sp.genus_code == code and sp.status == "alive"]
    
    species_codes = [sp.lineage_code for sp in genus_species]
    
    can_hybridize_pairs = []
    for sp_a in genus_species:
        for sp_b in genus_species:
            if sp_a.lineage_code >= sp_b.lineage_code:
                continue
            
            distance_key = f"{sp_a.lineage_code}-{sp_b.lineage_code}"
            distance = genus.genetic_distances.get(distance_key, 0.5)
            
            if distance < 0.5:
                can_hybridize_pairs.append({
                    "pair": [sp_a.lineage_code, sp_b.lineage_code],
                    "distance": round(distance, 3)
                })
    
    return {
        "genus_code": genus.code,
        "genus_name": genus.name_common,
        "species": species_codes,
        "genetic_distances": {k: round(v, 3) for k, v in genus.genetic_distances.items()},
        "can_hybridize_pairs": can_hybridize_pairs
    }


@router.get("/system/logs")
def get_system_logs(lines: int = 200) -> dict:
    """è·å–ç³»ç»Ÿæ—¥å¿—"""
    log_file = Path(settings.log_dir) / "simulation.log"
    if not log_file.exists():
        return {"logs": []}
    
    try:
        # Read last N lines
        # Simple implementation: read all and slice (assuming log file isn't huge for this demo)
        # For production, use seek/tail approach
        with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
            all_lines = f.readlines()
            recent = all_lines[-lines:]
            return {"logs": [line.strip() for line in recent]}
    except Exception as e:
        return {"logs": [], "error": str(e)}


@router.get("/system/ai-diagnostics", tags=["system"])
def get_ai_diagnostics() -> dict:
    """è·å– AI æ¨¡å‹è°ƒç”¨è¯Šæ–­ä¿¡æ¯
    
    è¿”å›å¹¶å‘çŠ¶æ€ã€è¶…æ—¶ç»Ÿè®¡ç­‰ä¿¡æ¯ï¼Œç”¨äºè¯Šæ–­ AI è°ƒç”¨é—®é¢˜ã€‚
    """
    diagnostics = model_router.get_diagnostics()
    
    # æ·»åŠ åˆ¤æ–­å»ºè®®
    advice = []
    if diagnostics["active_requests"] >= diagnostics["concurrency_limit"] * 0.8:
        advice.append("âš ï¸ å¹¶å‘æ¥è¿‘ä¸Šé™ï¼Œå»ºè®®å¢åŠ  concurrency_limit æˆ–å‡å°‘åŒæ—¶è¯·æ±‚æ•°")
    if diagnostics["total_timeouts"] > 0:
        timeout_rate = diagnostics["total_timeouts"] / max(diagnostics["total_requests"], 1)
        if timeout_rate > 0.3:
            advice.append("âš ï¸ è¶…æ—¶ç‡è¿‡é«˜ (>30%)ï¼Œå»ºè®®å¢åŠ  timeout æ—¶é—´æˆ–æ£€æŸ¥ API æœåŠ¡çŠ¶æ€")
        elif timeout_rate > 0.1:
            advice.append("âš¡ å­˜åœ¨ä¸€äº›è¶…æ—¶ (10-30%)ï¼Œå¯èƒ½æ˜¯ API å“åº”æ…¢æˆ–ç½‘ç»œé—®é¢˜")
    if diagnostics["queued_requests"] > 5:
        advice.append("â³ æœ‰è¾ƒå¤šè¯·æ±‚åœ¨æ’é˜Ÿï¼Œå¯èƒ½æ˜¯å¹¶å‘é™åˆ¶è¿‡ä½")
    
    if not advice:
        advice.append("âœ… AI è°ƒç”¨çŠ¶æ€æ­£å¸¸")
    
    return {
        **diagnostics,
        "advice": advice,
    }


@router.post("/system/ai-diagnostics/reset", tags=["system"])
def reset_ai_diagnostics() -> dict:
    """é‡ç½® AI è¯Šæ–­ç»Ÿè®¡"""
    model_router._active_requests = 0
    model_router._queued_requests = 0
    model_router._total_requests = 0
    model_router._total_timeouts = 0
    model_router._request_stats = {}
    return {"success": True, "message": "è¯Šæ–­ç»Ÿè®¡å·²é‡ç½®"}


# ========== ç”Ÿæ€ç³»ç»Ÿå¥åº·æŒ‡æ ‡ API ==========
# æ³¨: /game/state ç«¯ç‚¹å·²ç§»è‡³ analytics.pyï¼Œä½¿ç”¨ä¾èµ–æ³¨å…¥

# åˆå§‹åŒ–ç”Ÿæ€å¥åº·æœåŠ¡
ecosystem_health_service = EcosystemHealthService()


@router.get("/ecosystem/health", response_model=EcosystemHealthResponse, tags=["ecosystem"])
def get_ecosystem_health() -> EcosystemHealthResponse:
    """è·å–ç”Ÿæ€ç³»ç»Ÿå¥åº·æŠ¥å‘Š
    
    è¿”å›åŒ…æ‹¬ï¼š
    - å¤šæ ·æ€§æŒ‡æ•°ï¼ˆShannonã€Simpsonï¼‰
    - è¥å…»çº§åˆ†å¸ƒ
    - ç­ç»é£é™©è¯„ä¼°
    - å…±ç”Ÿç½‘ç»œç»Ÿè®¡
    - æ•´ä½“å¥åº·è¯„åˆ†
    """
    all_species = species_repository.list_species()
    
    # è·å–å·²ç­ç»ç‰©ç§ä»£ç 
    extinct_codes = {sp.lineage_code for sp in all_species if sp.status == "extinct"}
    
    # åˆ†æç”Ÿæ€ç³»ç»Ÿå¥åº·
    report = ecosystem_health_service.analyze(all_species, extinct_codes)
    
    # è½¬æ¢ä¸ºå“åº”æ ¼å¼
    return EcosystemHealthResponse(
        shannon_index=report.shannon_index,
        simpson_index=report.simpson_index,
        species_richness=report.species_richness,
        evenness=report.evenness,
        trophic_distribution=[
            TrophicDistributionItem(
                level=td.level,
                species_count=td.species_count,
                total_population=td.total_population,
                total_biomass=td.total_biomass,
                percentage=td.percentage
            ) for td in report.trophic_distribution
        ],
        trophic_balance_score=report.trophic_balance_score,
        extinction_risks=[
            ExtinctionRiskItem(
                lineage_code=er.lineage_code,
                common_name=er.common_name,
                risk_level=er.risk_level,
                risk_score=er.risk_score,
                reasons=er.reasons
            ) for er in report.extinction_risks
        ],
        critical_count=report.critical_count,
        endangered_count=report.endangered_count,
        symbiotic_connections=report.symbiotic_connections,
        network_connectivity=report.network_connectivity,
        overall_health_score=report.overall_health_score,
        health_grade=report.health_grade,
        health_summary=report.health_summary,
    )


# åˆå§‹åŒ–æ•é£Ÿç½‘æœåŠ¡
predation_service = PredationService()

# åˆå§‹åŒ–é£Ÿç‰©ç½‘ç®¡ç†æœåŠ¡
from ..services.species.food_web_manager import FoodWebManager
food_web_manager = FoodWebManager(predation_service)


@router.get("/ecosystem/food-web", tags=["ecosystem"])
def get_food_web(
    max_nodes: int = Query(500, ge=1, le=1000, description="æœ€å¤§èŠ‚ç‚¹æ•°"),
    max_links: int = Query(2000, ge=1, le=5000, description="æœ€å¤§é“¾æ¥æ•°"),
    offset: int = Query(0, ge=0, description="èŠ‚ç‚¹åç§»é‡"),
    trophic_levels: str | None = Query(None, description="è¥å…»çº§è¿‡æ»¤ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ '1,2,3'"),
    detail_level: str = Query("full", description="è¯¦ç»†ç¨‹åº¦: simple, standard, full"),
    include_preferences: bool = Query(True, description="æ˜¯å¦åŒ…å«çŒç‰©åå¥½"),
    sort_by: str = Query("trophic_level", description="æ’åºå­—æ®µ: trophic_level, population, name"),
    use_cache: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨ç¼“å­˜"),
    legacy_format: bool = Query(True, description="ä½¿ç”¨åŸæœ‰å“åº”æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰"),
):
    """è·å–çœŸå®çš„é£Ÿç‰©ç½‘æ•°æ®ï¼ˆæ”¯æŒåˆ†é¡µ/è£å‰ªï¼‰
    
    è¿”å›åŸºäºç‰©ç§prey_specieså­—æ®µçš„çœŸå®æ•é£Ÿå…³ç³»ï¼Œç”¨äºå‰ç«¯å¯è§†åŒ–ã€‚
    
    ã€æ€§èƒ½ä¼˜åŒ–ã€‘
    - æ”¯æŒåˆ†é¡µï¼šmax_nodes, offset æ§åˆ¶èŠ‚ç‚¹æ•°é‡
    - æ”¯æŒè¿‡æ»¤ï¼štrophic_levels æŒ‰è¥å…»çº§è¿‡æ»¤
    - æ”¯æŒç¼“å­˜ï¼šuse_cache=True æ—¶ä¼˜å…ˆè¯»å–ç¼“å­˜
    - legacy_format=True: è¿”å›åŸæœ‰æ ¼å¼ï¼ˆé»˜è®¤ï¼Œå‘åå…¼å®¹ï¼‰
    """
    # ã€å‘åå…¼å®¹ã€‘é»˜è®¤ä½¿ç”¨åŸæœ‰çš„ build_food_web æ–¹æ³•
    if legacy_format:
        all_species = species_repository.list_species()
        return predation_service.build_food_web(all_species)
    
    # æ–°çš„ç¼“å­˜+åˆ†é¡µæ¨¡å¼
    from ..services.species.food_web_cache import get_food_web_cache, FoodWebQueryOptions
    
    cache_service = get_food_web_cache()
    
    # è§£æè¥å…»çº§è¿‡æ»¤
    levels = None
    if trophic_levels:
        try:
            levels = [int(x.strip()) for x in trophic_levels.split(",")]
        except ValueError:
            levels = None
    
    # æ„å»ºæŸ¥è¯¢é€‰é¡¹
    options = FoodWebQueryOptions(
        max_nodes=max_nodes,
        max_links=max_links,
        offset=offset,
        trophic_levels=levels,
        detail_level=detail_level,
        include_preferences=include_preferences,
        sort_by=sort_by,
    )
    
    # å°è¯•ä½¿ç”¨ç¼“å­˜
    if use_cache and cache_service.is_valid:
        result = cache_service.query(options)
        return {
            "nodes": result.nodes,
            "links": result.links,
            "total_nodes": result.total_nodes,
            "total_links": result.total_links,
            "has_more_nodes": result.has_more_nodes,
            "has_more_links": result.has_more_links,
            "cache_hit": True,
            "cache_age_seconds": round(result.cache_age_seconds, 1),
        }
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œé‡å»ºç¼“å­˜
    all_species = species_repository.list_species()
    cache_service.build_cache(all_species, simulation_engine.turn_counter)
    
    result = cache_service.query(options)
    return {
        "nodes": result.nodes,
        "links": result.links,
        "total_nodes": result.total_nodes,
        "total_links": result.total_links,
        "has_more_nodes": result.has_more_nodes,
        "has_more_links": result.has_more_links,
        "cache_hit": False,
        "cache_age_seconds": 0,
    }


@router.get("/ecosystem/food-web/regional", tags=["ecosystem"])
def get_regional_food_web(
    tile_ids: str = Query(..., description="åœ°å—IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ '1,2,3,4,5'"),
):
    """è·å–åŒºåŸŸé£Ÿç‰©ç½‘æ•°æ®
    
    ã€ç”Ÿç‰©å­¦åŸç†ã€‘
    ä¸åŒåŒºåŸŸçš„é£Ÿç‰©ç½‘ç»“æ„å¯èƒ½ä¸åŒï¼š
    - åŒä¸€ç‰©ç§åœ¨ä¸åŒåŒºåŸŸå¯èƒ½æœ‰ä¸åŒçš„çŒç‰©ï¼ˆå› ä¸ºçŒç‰©åˆ†å¸ƒä¸åŒï¼‰
    - åŒºåŸŸå†…çš„æ•é£Ÿå…³ç³»å–å†³äºå“ªäº›ç‰©ç§å…±å­˜äºè¯¥åŒºåŸŸ
    
    Args:
        tile_ids: è¦æŸ¥è¯¢çš„åœ°å—IDï¼Œé€—å·åˆ†éš”
        
    Returns:
        åŒºåŸŸé£Ÿç‰©ç½‘æ•°æ®ï¼ˆåªåŒ…å«æŒ‡å®šåŒºåŸŸå†…çš„ç‰©ç§å’Œå…³ç³»ï¼‰
    """
    # è§£æåœ°å—ID
    try:
        tile_id_set = {int(x.strip()) for x in tile_ids.split(",") if x.strip()}
    except ValueError:
        raise HTTPException(status_code=400, detail="tile_ids æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºé€—å·åˆ†éš”çš„æ•´æ•°")
    
    if not tile_id_set:
        raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æŒ‡å®šä¸€ä¸ªåœ°å—ID")
    
    # è·å–ç‰©ç§-åœ°å—æ˜ å°„
    from ..services.species.matrix_cache import get_matrix_cache
    matrix_cache = get_matrix_cache()
    
    # ç¡®ä¿ç¼“å­˜æ˜¯æœ€æ–°çš„
    all_species = species_repository.list_species()
    if not matrix_cache.is_valid(len(all_species)):
        matrix_cache.rebuild(all_species)
    
    species_tiles = matrix_cache.species_tiles
    
    # æ„å»ºåŒºåŸŸé£Ÿç‰©ç½‘
    return predation_service.build_regional_food_web(
        all_species=all_species,
        tile_ids=tile_id_set,
        species_tiles=species_tiles,
    )


@router.get("/ecosystem/food-web/summary", tags=["ecosystem"])
def get_food_web_summary():
    """è·å–é£Ÿç‰©ç½‘ç®€ç‰ˆæ‘˜è¦ï¼ˆç”¨äºä»ªè¡¨ç›˜ï¼Œä¼˜å…ˆè¯»ç¼“å­˜ï¼‰
    
    è¿”å›è½»é‡çº§çš„é£Ÿç‰©ç½‘ç»Ÿè®¡ï¼Œé€‚åˆé¢‘ç¹åˆ·æ–°çš„ä»ªè¡¨ç›˜ã€‚
    """
    from ..services.species.food_web_cache import get_food_web_cache
    
    cache_service = get_food_web_cache()
    return cache_service.get_simple_summary()


@router.get("/ecosystem/food-web/cache-stats", tags=["ecosystem"])
def get_food_web_cache_stats():
    """è·å–é£Ÿç‰©ç½‘ç¼“å­˜ç»Ÿè®¡ï¼ˆè°ƒè¯•ç”¨ï¼‰
    
    è¿”å›ç¼“å­˜å‘½ä¸­ç‡ã€å†…å­˜å ç”¨ç­‰æ€§èƒ½æŒ‡æ ‡ã€‚
    """
    from ..services.species.food_web_cache import get_food_web_cache
    from ..services.species.matrix_cache import get_matrix_cache
    
    food_web_cache = get_food_web_cache()
    matrix_cache = get_matrix_cache()
    
    return {
        "food_web_cache": food_web_cache.get_simple_summary(),
        "matrix_cache": matrix_cache.stats,
    }


@router.get("/ecosystem/food-web/analysis", tags=["ecosystem"])
def get_food_web_analysis(
    detail_level: str = Query("full", description="è¯¦ç»†ç¨‹åº¦: simple, full"),
):
    """è·å–é£Ÿç‰©ç½‘å¥åº·çŠ¶å†µåˆ†æ
    
    è¿”å›é£Ÿç‰©ç½‘çš„è¯¦ç»†åˆ†æç»“æœï¼ŒåŒ…æ‹¬ï¼š
    - health_score: é£Ÿç‰©ç½‘å¥åº·åº¦ (0-1)
    - total_species: å­˜æ´»ç‰©ç§æ€»æ•°
    - total_links: æ•é£Ÿå…³ç³»æ€»æ•°
    - orphaned_consumers: æ²¡æœ‰çŒç‰©çš„æ¶ˆè´¹è€…åˆ—è¡¨
    - starving_species: çŒç‰©å…¨éƒ¨ç­ç»çš„ç‰©ç§åˆ—è¡¨
    - keystone_species: å…³é”®ç‰©ç§åˆ—è¡¨ï¼ˆè¢«3+ç‰©ç§ä¾èµ–ï¼‰
    - isolated_species: æ—¢æ— çŒç‰©ä¹Ÿæ— æ•é£Ÿè€…çš„ç‰©ç§
    - avg_prey_per_consumer: æ¯ä¸ªæ¶ˆè´¹è€…çš„å¹³å‡çŒç‰©ç§ç±»æ•°
    - food_web_density: é£Ÿç‰©ç½‘è¿æ¥å¯†åº¦
    - bottleneck_warnings: ç“¶é¢ˆè­¦å‘Šåˆ—è¡¨
    
    ã€æ€§èƒ½ä¼˜åŒ–ã€‘
    - detail_level=simple: åªè¿”å›ç»Ÿè®¡æ•°å­—ï¼Œä¸è¿”å›ç‰©ç§åˆ—è¡¨
    """
    all_species = species_repository.list_species()
    analysis = food_web_manager.analyze_food_web(all_species)
    
    if detail_level == "simple":
        return {
            "health_score": analysis.health_score,
            "total_species": analysis.total_species,
            "total_links": analysis.total_links,
            "orphaned_count": len(analysis.orphaned_consumers),
            "starving_count": len(analysis.starving_species),
            "keystone_count": len(analysis.keystone_species),
            "isolated_count": len(analysis.isolated_species),
            "avg_prey_per_consumer": analysis.avg_prey_per_consumer,
            "food_web_density": analysis.food_web_density,
            "warning_count": len(analysis.bottleneck_warnings),
        }
    
    return {
        "health_score": analysis.health_score,
        "total_species": analysis.total_species,
        "total_links": analysis.total_links,
        "orphaned_consumers": analysis.orphaned_consumers,
        "starving_species": analysis.starving_species,
        "keystone_species": analysis.keystone_species,
        "isolated_species": analysis.isolated_species,
        "avg_prey_per_consumer": analysis.avg_prey_per_consumer,
        "food_web_density": analysis.food_web_density,
        "bottleneck_warnings": analysis.bottleneck_warnings,
    }


@router.post("/ecosystem/food-web/repair", tags=["ecosystem"])
def repair_food_web():
    """ä¿®å¤é£Ÿç‰©ç½‘ç¼ºé™·
    
    è‡ªåŠ¨ä¸ºç¼ºå°‘çŒç‰©çš„æ¶ˆè´¹è€…åˆ†é…çŒç‰©ï¼Œä¿®å¤é£Ÿç‰©é“¾æ–­è£‚é—®é¢˜ã€‚
    
    è¿”å›ï¼š
    - repaired_count: ä¿®å¤çš„ç‰©ç§æ•°é‡
    - changes: å˜æ›´è¯¦æƒ…åˆ—è¡¨
    """
    all_species = species_repository.list_species()
    
    # æ‰§è¡Œä¿®å¤
    analysis = food_web_manager.maintain_food_web(
        all_species, species_repository, turn_index=0
    )
    changes = food_web_manager.get_changes()
    
    return {
        "repaired_count": len(changes),
        "changes": [
            {
                "species_code": c.species_code,
                "species_name": c.species_name,
                "change_type": c.change_type,
                "details": c.details,
                "old_prey": c.old_prey,
                "new_prey": c.new_prey,
            }
            for c in changes
        ],
        "analysis_after": {
            "health_score": analysis.health_score,
            "orphaned_consumers": len(analysis.orphaned_consumers),
            "starving_species": len(analysis.starving_species),
        }
    }


@router.get("/ecosystem/food-web/{lineage_code}", tags=["ecosystem"])
def get_species_food_chain(lineage_code: str):
    """è·å–ç‰¹å®šç‰©ç§çš„é£Ÿç‰©é“¾
    
    è¿”å›è¯¥ç‰©ç§çš„ä¸Šä¸‹æ¸¸é£Ÿç‰©å…³ç³»ï¼š
    - prey_chain: è¯¥ç‰©ç§çš„çŒç‰©åŠçŒç‰©çš„çŒç‰©ï¼ˆå‘ä¸‹è¿½æº¯ï¼‰
    - predator_chain: æ•é£Ÿè¯¥ç‰©ç§çš„æ•é£Ÿè€…åŠå…¶æ•é£Ÿè€…ï¼ˆå‘ä¸Šè¿½æº¯ï¼‰
    - food_dependency: é£Ÿç‰©ä¾èµ–æ»¡è¶³åº¦ (0-1)
    - predation_pressure: è¢«æ•é£Ÿå‹åŠ› (0-1)
    """
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {lineage_code} ä¸å­˜åœ¨")
    
    all_species = species_repository.list_species()
    return predation_service.get_species_food_chain(species, all_species)


@router.get("/ecosystem/food-web/{lineage_code}/neighborhood", tags=["ecosystem"])
def get_species_neighborhood(
    lineage_code: str,
    k_hop: int = Query(2, ge=1, le=5, description="é‚»åŸŸè·³æ•° (1-5)"),
    max_nodes: int = Query(50, ge=1, le=200, description="æœ€å¤§èŠ‚ç‚¹æ•°"),
    detail_level: str = Query("standard", description="è¯¦ç»†ç¨‹åº¦: simple, standard, full"),
):
    """è·å–ç‰¹å®šç‰©ç§çš„ k-hop é‚»åŸŸï¼ˆæ–° APIï¼Œç”¨äºä¼˜åŒ–çš„å±€éƒ¨è§†å›¾ï¼‰
    
    è¿”å›ï¼š
    - neighborhood: k-hop é‚»åŸŸå†…çš„èŠ‚ç‚¹å’Œé“¾æ¥
    - food_chain: å®Œæ•´çš„é£Ÿç‰©é“¾ä¿¡æ¯
    """
    from ..services.species.food_web_cache import get_food_web_cache, FoodWebQueryOptions
    
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {lineage_code} ä¸å­˜åœ¨")
    
    all_species = species_repository.list_species()
    
    # å°è¯•ä½¿ç”¨ç¼“å­˜è·å–é‚»åŸŸ
    cache_service = get_food_web_cache()
    
    # ç¡®ä¿ç¼“å­˜å·²æ„å»º
    if not cache_service.is_valid:
        cache_service.build_cache(all_species, simulation_engine.turn_counter)
    
    options = FoodWebQueryOptions(
        max_nodes=max_nodes,
        max_links=max_nodes * 3,
        center_species=lineage_code,
        k_hop=k_hop,
        detail_level=detail_level,
    )
    result = cache_service.query(options)
    
    # è·å–å®Œæ•´çš„é£Ÿç‰©é“¾ä¿¡æ¯
    food_chain = predation_service.get_species_food_chain(species, all_species)
    
    return {
        "neighborhood": {
            "nodes": result.nodes,
            "links": result.links,
            "total_nodes": result.total_nodes,
            "total_links": result.total_links,
        },
        "food_chain": food_chain,
        "cache_hit": result.cache_hit,
    }


@router.get("/ecosystem/extinction-impact/{lineage_code}", tags=["ecosystem"])
def analyze_extinction_impact(lineage_code: str):
    """åˆ†æç‰©ç§ç­ç»çš„å½±å“
    
    é¢„æµ‹å¦‚æœè¯¥ç‰©ç§ç­ç»ä¼šå¯¹ç”Ÿæ€ç³»ç»Ÿé€ æˆä»€ä¹ˆå½±å“ï¼š
    - directly_affected: ç›´æ¥å—å½±å“çš„æ•é£Ÿè€…ï¼ˆä»¥è¯¥ç‰©ç§ä¸ºé£Ÿï¼‰
    - indirectly_affected: é—´æ¥å—å½±å“çš„ç‰©ç§ï¼ˆäºŒçº§ä»¥ä¸Šï¼‰
    - food_chain_collapse_risk: é£Ÿç‰©é“¾å´©æºƒé£é™© (0-1)
    - affected_biomass_percentage: å—å½±å“ç”Ÿç‰©é‡ç™¾åˆ†æ¯”
    """
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {lineage_code} ä¸å­˜åœ¨")
    
    all_species = species_repository.list_species()
    impact = predation_service.analyze_extinction_impact(species, all_species)
    
    return {
        "extinct_species": impact.extinct_species,
        "directly_affected": impact.directly_affected,
        "indirectly_affected": impact.indirectly_affected,
        "food_chain_collapse_risk": impact.food_chain_collapse_risk,
        "affected_biomass_percentage": impact.affected_biomass_percentage,
    }


# ========== ç©å®¶å¹²é¢„ API ==========

@router.post("/intervention/protect", response_model=InterventionResponse, tags=["intervention"])
def protect_species(request: ProtectSpeciesRequest) -> InterventionResponse:
    """ä¿æŠ¤æŒ‡å®šç‰©ç§
    
    ä¿æŠ¤æ•ˆæœï¼š
    - æ­»äº¡ç‡é™ä½50%
    - æŒç»­æŒ‡å®šå›åˆæ•°
    
    æ¶ˆè€—èƒ½é‡ç‚¹ã€‚
    """
    species = species_repository.get_by_lineage(request.lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {request.lineage_code} ä¸å­˜åœ¨")
    
    if species.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {request.lineage_code} å·²ç­ç»ï¼Œæ— æ³•ä¿æŠ¤")
    
    # ã€èƒ½é‡ç³»ç»Ÿã€‘æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    can_afford, cost = energy_service.can_afford("protect")
    if not can_afford:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼ä¿æŠ¤ç‰©ç§éœ€è¦ {cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    # æ¶ˆè€—èƒ½é‡
    energy_service.spend("protect", current_turn, details=f"ä¿æŠ¤ {species.common_name}")
    
    # è®¾ç½®ä¿æŠ¤çŠ¶æ€
    species.is_protected = True
    species.protection_turns = request.turns
    species_repository.upsert(species)
    
    return InterventionResponse(
        success=True,
        message=f"å·²å¯¹ {species.common_name} ({request.lineage_code}) å®æ–½ä¿æŠ¤ï¼ŒæŒç»­ {request.turns} å›åˆï¼ˆæ¶ˆè€— {cost} èƒ½é‡ï¼‰",
        species_code=request.lineage_code,
        effect_duration=request.turns
    )


@router.post("/intervention/suppress", response_model=InterventionResponse, tags=["intervention"])
def suppress_species(request: SuppressSpeciesRequest) -> InterventionResponse:
    """å‹åˆ¶æŒ‡å®šç‰©ç§
    
    å‹åˆ¶æ•ˆæœï¼š
    - æ­»äº¡ç‡å¢åŠ 30%
    - æŒç»­æŒ‡å®šå›åˆæ•°
    
    æ¶ˆè€—èƒ½é‡ç‚¹ã€‚
    """
    species = species_repository.get_by_lineage(request.lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {request.lineage_code} ä¸å­˜åœ¨")
    
    if species.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {request.lineage_code} å·²ç­ç»ï¼Œæ— éœ€å‹åˆ¶")
    
    # ã€èƒ½é‡ç³»ç»Ÿã€‘æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    can_afford, cost = energy_service.can_afford("suppress")
    if not can_afford:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼å‹åˆ¶ç‰©ç§éœ€è¦ {cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    # æ¶ˆè€—èƒ½é‡
    energy_service.spend("suppress", current_turn, details=f"å‹åˆ¶ {species.common_name}")
    
    # è®¾ç½®å‹åˆ¶çŠ¶æ€
    species.is_suppressed = True
    species.suppression_turns = request.turns
    species_repository.upsert(species)
    
    return InterventionResponse(
        success=True,
        message=f"å·²å¯¹ {species.common_name} ({request.lineage_code}) å®æ–½å‹åˆ¶ï¼ŒæŒç»­ {request.turns} å›åˆï¼ˆæ¶ˆè€— {cost} èƒ½é‡ï¼‰",
        species_code=request.lineage_code,
        effect_duration=request.turns
    )


@router.post("/intervention/cancel/{lineage_code}", response_model=InterventionResponse, tags=["intervention"])
def cancel_intervention(lineage_code: str) -> InterventionResponse:
    """å–æ¶ˆå¯¹æŒ‡å®šç‰©ç§çš„æ‰€æœ‰å¹²é¢„"""
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {lineage_code} ä¸å­˜åœ¨")
    
    # å–æ¶ˆæ‰€æœ‰å¹²é¢„
    species.is_protected = False
    species.protection_turns = 0
    species.is_suppressed = False
    species.suppression_turns = 0
    species_repository.upsert(species)
    
    return InterventionResponse(
        success=True,
        message=f"å·²å–æ¶ˆå¯¹ {species.common_name} ({lineage_code}) çš„æ‰€æœ‰å¹²é¢„",
        species_code=lineage_code,
        effect_duration=0
    )


@router.post("/intervention/introduce", response_model=InterventionResponse, tags=["intervention"])
async def introduce_species(request: IntroduceSpeciesRequest) -> InterventionResponse:
    """å¼•å…¥æ–°ç‰©ç§
    
    é€šè¿‡AIç”Ÿæˆæ–°ç‰©ç§å¹¶å¼•å…¥åˆ°ç”Ÿæ€ç³»ç»Ÿä¸­ã€‚
    """
    try:
        # ç”Ÿæˆå”¯ä¸€çš„lineage_code
        existing_species = species_repository.list_species()
        used_prefixes = {sp.lineage_code[:1] for sp in existing_species}
        
        available_prefixes = [chr(i) for i in range(ord('A'), ord('Z')+1) if chr(i) not in used_prefixes]
        if not available_prefixes:
            # å¦‚æœå­—æ¯ç”¨å®Œï¼Œä½¿ç”¨æ•°å­—åç¼€
            max_num = max((int(sp.lineage_code[1:]) for sp in existing_species if sp.lineage_code[1:].isdigit()), default=0)
            new_code = f"X{max_num + 1}"
        else:
            new_code = f"{available_prefixes[0]}1"
        
        # ç”Ÿæˆç‰©ç§
        new_species = species_generator.generate_from_prompt(request.prompt, new_code)
        
        # è®¾ç½®åˆå§‹ç§ç¾¤
        new_species.morphology_stats["population"] = request.initial_population
        
        # ä¿å­˜ç‰©ç§
        species_repository.upsert(new_species)
        
        # åˆå§‹åŒ–æ –æ¯åœ°ï¼ˆå¦‚æœæŒ‡å®šäº†ç›®æ ‡åŒºåŸŸï¼‰
        if request.target_region:
            # æ‰¾åˆ°ç›®æ ‡åœ°å—
            tiles = environment_repository.list_tiles()
            target_x, target_y = request.target_region
            target_tile = next((t for t in tiles if t.x == target_x and t.y == target_y), None)
            
            if target_tile:
                # åˆ†é…åˆ°ç›®æ ‡åœ°å—ï¼ˆhabitat_manager å·²åœ¨æ¨¡å—çº§åˆ«å¯¼å…¥ï¼‰
                habitat_manager.assign_initial_habitat(new_species, [target_tile], simulation_engine.turn_counter)
        
        return InterventionResponse(
            success=True,
            message=f"æˆåŠŸå¼•å…¥æ–°ç‰©ç§: {new_species.common_name} ({new_code})ï¼Œåˆå§‹ç§ç¾¤ {request.initial_population:,}",
            species_code=new_code,
            effect_duration=None
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¼•å…¥ç‰©ç§å¤±è´¥: {str(e)}")


@router.post("/intervention/symbiosis", response_model=InterventionResponse, tags=["intervention"])
def set_symbiosis(request: SetSymbiosisRequest) -> InterventionResponse:
    """è®¾ç½®ç‰©ç§é—´çš„å…±ç”Ÿå…³ç³»
    
    å¯ä»¥å»ºç«‹äº’åˆ©å…±ç”Ÿã€ååˆ©å…±ç”Ÿæˆ–å¯„ç”Ÿå…³ç³»ã€‚
    """
    species = species_repository.get_by_lineage(request.species_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {request.species_code} ä¸å­˜åœ¨")
    
    # éªŒè¯ä¾èµ–ç‰©ç§å­˜åœ¨
    if request.depends_on:
        all_species = species_repository.list_species()
        all_codes = {sp.lineage_code for sp in all_species}
        invalid_codes = [code for code in request.depends_on if code not in all_codes]
        if invalid_codes:
            raise HTTPException(
                status_code=400, 
                detail=f"ä»¥ä¸‹ç‰©ç§ä»£ç ä¸å­˜åœ¨: {', '.join(invalid_codes)}"
            )
    
    # è®¾ç½®å…±ç”Ÿå…³ç³»
    species.symbiotic_dependencies = request.depends_on
    species.dependency_strength = request.strength
    species.symbiosis_type = request.symbiosis_type
    species_repository.upsert(species)
    
    if request.depends_on:
        return InterventionResponse(
            success=True,
            message=f"å·²è®¾ç½® {species.common_name} ä¸ {', '.join(request.depends_on)} çš„{request.symbiosis_type}å…³ç³»ï¼Œä¾èµ–å¼ºåº¦ {request.strength}",
            species_code=request.species_code,
            effect_duration=None
        )
    else:
        return InterventionResponse(
            success=True,
            message=f"å·²æ¸…é™¤ {species.common_name} çš„å…±ç”Ÿå…³ç³»",
            species_code=request.species_code,
            effect_duration=None
        )


@router.get("/intervention/status", tags=["intervention"])
def get_intervention_status() -> dict:
    """è·å–æ‰€æœ‰å¹²é¢„çŠ¶æ€"""
    all_species = species_repository.list_species()
    
    protected = []
    suppressed = []
    symbiotic = []
    
    for sp in all_species:
        if sp.status != "alive":
            continue
        
        is_protected = getattr(sp, 'is_protected', False) or False
        protection_turns = getattr(sp, 'protection_turns', 0) or 0
        is_suppressed = getattr(sp, 'is_suppressed', False) or False
        suppression_turns = getattr(sp, 'suppression_turns', 0) or 0
        dependencies = getattr(sp, 'symbiotic_dependencies', []) or []
        
        if is_protected and protection_turns > 0:
            protected.append({
                "lineage_code": sp.lineage_code,
                "common_name": sp.common_name,
                "remaining_turns": protection_turns
            })
        
        if is_suppressed and suppression_turns > 0:
            suppressed.append({
                "lineage_code": sp.lineage_code,
                "common_name": sp.common_name,
                "remaining_turns": suppression_turns
            })
        
        if dependencies:
            symbiotic.append({
                "lineage_code": sp.lineage_code,
                "common_name": sp.common_name,
                "depends_on": dependencies,
                "strength": getattr(sp, 'dependency_strength', 0.0) or 0.0,
                "type": getattr(sp, 'symbiosis_type', 'none') or 'none'
            })
    
    return {
        "protected_species": protected,
        "suppressed_species": suppressed,
        "symbiotic_relations": symbiotic,
        "total_protected": len(protected),
        "total_suppressed": len(suppressed),
        "total_symbiotic": len(symbiotic)
    }


# ================== ä»»åŠ¡ä¸­æ–­ API ==================

@router.post("/tasks/abort", tags=["system"])
async def abort_current_tasks() -> dict:
    """é‡ç½® AI è¿æ¥ï¼Œè§£é™¤å¡ä½çŠ¶æ€
    
    å½“ AI è°ƒç”¨å¡ä½æ—¶ï¼Œå¯ä»¥è°ƒç”¨æ­¤ APIï¼š
    - å…³é—­å½“å‰çš„ HTTP å®¢æˆ·ç«¯è¿æ¥
    - ä¸æ¸…ç©ºé˜Ÿåˆ—å’Œè®¡æ•°å™¨ï¼ˆè®©ä»»åŠ¡è‡ªç„¶æ¢å¤ï¼‰
    - å¡ä½çš„è¯·æ±‚ä¼šå› è¿æ¥å…³é—­è€ŒæŠ›å‡ºå¼‚å¸¸ï¼Œç„¶åè‡ªåŠ¨é‡è¯•æˆ–è¿”å›
    
    è¿™ç±»ä¼¼äºåç«¯çš„ shutdownï¼Œå¯ä»¥è®©å¡ä½çš„ä»»åŠ¡ç»§ç»­
    """
    from ..main import get_simulation_engine
    
    try:
        engine = get_simulation_engine()
        router = engine.router
        
        # è·å–å½“å‰è¯Šæ–­ä¿¡æ¯
        diagnostics_before = router.get_diagnostics()
        
        # åªå…³é—­å®¢æˆ·ç«¯è¿æ¥ï¼Œä¸æ¸…ç©ºè®¡æ•°å™¨
        old_client = router._client_session
        router._client_session = None  # å…ˆç½®ç©º
        
        if old_client and not old_client.is_closed:
            try:
                await old_client.aclose()
                logger.info("[ä»»åŠ¡æ¢å¤] å·²å…³é—­æ—§çš„ HTTP å®¢æˆ·ç«¯è¿æ¥")
            except Exception as e:
                logger.warning(f"[ä»»åŠ¡æ¢å¤] å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
        
        logger.warning(f"[ä»»åŠ¡æ¢å¤] è¿æ¥å·²é‡ç½®ï¼Œæ´»è·ƒè¯·æ±‚: {diagnostics_before['active_requests']}ï¼Œæ’é˜Ÿ: {diagnostics_before['queued_requests']}")
        
        return {
            "success": True,
            "message": "è¿æ¥å·²é‡ç½®ï¼Œå¡ä½çš„ä»»åŠ¡å°†è‡ªåŠ¨æ¢å¤",
            "active_requests": diagnostics_before['active_requests'],
            "queued_requests": diagnostics_before['queued_requests']
        }
    except Exception as e:
        logger.error(f"[ä»»åŠ¡æ¢å¤] é‡ç½®å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"é‡ç½®å¤±è´¥: {str(e)}"
        }


@router.post("/tasks/skip-ai-step", tags=["system"])
async def skip_current_ai_step() -> dict:
    """è·³è¿‡å½“å‰AIæ­¥éª¤ï¼Œä½¿ç”¨fallbackè§„åˆ™
    
    å½“AIæ­¥éª¤å¡ä½å¤ªä¹…æ—¶ï¼Œå¯ä»¥è°ƒç”¨æ­¤APIï¼š
    - è®¾ç½®è·³è¿‡æ ‡å¿—
    - å¼ºåˆ¶å…³é—­å½“å‰è¿æ¥
    - è§¦å‘è¶…æ—¶å¼‚å¸¸ï¼Œè®©ä»£ç ä½¿ç”¨fallbacké€»è¾‘
    
    è¿™ä¼šè®©å½“å‰çš„AIæ­¥éª¤ï¼ˆå¦‚æŠ¥å‘Šç”Ÿæˆã€ç‰©ç§åˆ†åŒ–ï¼‰ç«‹å³ä½¿ç”¨è§„åˆ™fallbackå®Œæˆ
    """
    from ..main import get_simulation_engine
    
    try:
        engine = get_simulation_engine()
        router = engine.router
        
        # è®¾ç½®è·³è¿‡æ ‡å¿—ï¼ˆå¦‚æœå¼•æ“æ”¯æŒï¼‰
        if hasattr(engine, '_skip_current_ai_step'):
            engine._skip_current_ai_step = True
        
        # è·å–è¯Šæ–­ä¿¡æ¯
        diagnostics = router.get_diagnostics()
        
        # å¼ºåˆ¶å…³é—­å®¢æˆ·ç«¯è¿æ¥ï¼Œè§¦å‘è¶…æ—¶
        old_client = router._client_session
        router._client_session = None
        
        if old_client and not old_client.is_closed:
            try:
                await old_client.aclose()
                logger.info("[è·³è¿‡AI] å·²å…³é—­HTTPè¿æ¥ï¼Œè§¦å‘fallback")
            except Exception as e:
                logger.warning(f"[è·³è¿‡AI] å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
        
        # å‘é€è·³è¿‡äº‹ä»¶é€šçŸ¥å‰ç«¯
        push_simulation_event("ai_skip", "â­ï¸ å·²è·³è¿‡å½“å‰AIæ­¥éª¤ï¼Œä½¿ç”¨è§„åˆ™fallback", "ç³»ç»Ÿ")
        
        logger.warning(f"[è·³è¿‡AI] ç”¨æˆ·è¯·æ±‚è·³è¿‡ï¼Œæ´»è·ƒè¯·æ±‚: {diagnostics['active_requests']}")
        
        return {
            "success": True,
            "message": "å·²è§¦å‘è·³è¿‡ï¼Œå½“å‰AIæ­¥éª¤å°†ä½¿ç”¨fallbackå®Œæˆ",
            "active_requests": diagnostics['active_requests'],
            "skipped_at": "current_stage"
        }
    except Exception as e:
        logger.error(f"[è·³è¿‡AI] è·³è¿‡å¤±è´¥: {e}")
        return {
            "success": False,
            "message": f"è·³è¿‡å¤±è´¥: {str(e)}"
        }


@router.get("/tasks/diagnostics", tags=["system"])
def get_task_diagnostics() -> dict:
    """è·å–å½“å‰ AI ä»»åŠ¡çš„è¯Šæ–­ä¿¡æ¯
    
    è¿”å›ï¼š
    - å¹¶å‘é™åˆ¶
    - æ´»è·ƒè¯·æ±‚æ•°
    - æ’é˜Ÿè¯·æ±‚æ•°
    - è¶…æ—¶ç»Ÿè®¡
    """
    from ..main import get_simulation_engine
    
    try:
        engine = get_simulation_engine()
        router = engine.router
        return {
            "success": True,
            **router.get_diagnostics()
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


# ================== æˆå°±ç³»ç»Ÿ API ==================

from ..services.analytics.achievements import AchievementService
from ..services.analytics.game_hints import GameHintsService

# åˆå§‹åŒ–æœåŠ¡
achievement_service = AchievementService(settings.data_dir)
game_hints_service = GameHintsService(max_hints=5)


@router.get("/achievements", tags=["achievements"])
def get_achievements() -> dict:
    """è·å–æ‰€æœ‰æˆå°±åŠå…¶è§£é”çŠ¶æ€
    
    è¿”å›ï¼š
    - achievements: æˆå°±åˆ—è¡¨
    - stats: ç»Ÿè®¡ä¿¡æ¯
    """
    return {
        "achievements": achievement_service.get_all_achievements(),
        "stats": achievement_service.get_stats(),
    }


@router.get("/achievements/unlocked", tags=["achievements"])
def get_unlocked_achievements() -> dict:
    """è·å–å·²è§£é”çš„æˆå°±"""
    return {
        "achievements": achievement_service.get_unlocked_achievements(),
    }


@router.get("/achievements/pending", tags=["achievements"])
def get_pending_achievement_unlocks() -> dict:
    """è·å–å¾…é€šçŸ¥çš„æˆå°±è§£é”äº‹ä»¶ï¼ˆè·å–åæ¸…ç©ºï¼‰
    
    ç”¨äºå‰ç«¯æ˜¾ç¤ºæˆå°±è§£é”å¼¹çª—ã€‚
    """
    events = achievement_service.get_pending_unlocks()
    return {
        "events": [
            {
                "achievement": {
                    "id": e.achievement.id,
                    "name": e.achievement.name,
                    "description": e.achievement.description,
                    "icon": e.achievement.icon,
                    "rarity": e.achievement.rarity.value,
                    "category": e.achievement.category.value,
                },
                "turn_index": e.turn_index,
                "timestamp": e.timestamp,
            }
            for e in events
        ]
    }


@router.post("/achievements/exploration/{feature}", tags=["achievements"])
def record_exploration(feature: str) -> dict:
    """è®°å½•ç©å®¶æ¢ç´¢åŠŸèƒ½ï¼ˆç”¨äºè§£é”æ¢ç´¢è€…æˆå°±ï¼‰
    
    Args:
        feature: åŠŸèƒ½åç§° (genealogy, foodweb, niche)
    """
    # è·å–å½“å‰å›åˆ
    current_turn = simulation_engine.turn_counter
    
    event = achievement_service.record_exploration(feature, current_turn)
    if event:
        return {
            "success": True,
            "unlocked": {
                "id": event.achievement.id,
                "name": event.achievement.name,
                "icon": event.achievement.icon,
            }
        }
    return {"success": True, "unlocked": None}


@router.post("/achievements/reset", tags=["achievements"])
def reset_achievements() -> dict:
    """é‡ç½®æ‰€æœ‰æˆå°±è¿›åº¦ï¼ˆæ–°å­˜æ¡£æ—¶è°ƒç”¨ï¼‰"""
    achievement_service.reset()
    return {"success": True, "message": "æˆå°±è¿›åº¦å·²é‡ç½®"}


# ================== æ™ºèƒ½æç¤º API ==================

@router.get("/hints", tags=["hints"])
def get_game_hints() -> dict:
    """è·å–å½“å‰æ¸¸æˆçŠ¶æ€çš„æ™ºèƒ½æç¤º
    
    è¿”å›ï¼š
    - hints: æç¤ºåˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    """
    try:
        all_species = species_repository.list_species()
        current_turn = simulation_engine.turn_counter
    except Exception as e:
        logger.error(f"[æç¤ºAPI] è·å–ç‰©ç§/å›åˆå¤±è´¥: {e}")
        return {"hints": [], "turn": 0}
    
    def _safe_parse_turn_report(record_data) -> TurnReport | None:
        """é˜²å¾¡æ€§è§£æå›åˆæŠ¥å‘Šï¼Œé¿å…è„æ•°æ®å¯¼è‡´ 500ã€‚"""
        if not record_data:
            return None
        try:
            # record_data å¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ– dict
            if isinstance(record_data, str):
                import json
                record_data = json.loads(record_data)
            return TurnReport.model_validate(record_data)
        except Exception as e:
            logger.warning(f"[Hints] è§£æå›åˆæŠ¥å‘Šå¤±è´¥ï¼Œå¿½ç•¥è¯¥è®°å½•: {e}")
            return None
    
    # è·å–æœ€è¿‘çš„æŠ¥å‘Š
    logs = history_repository.list_turns(limit=2)
    recent_report = None
    previous_report = None
    
    if logs:
        recent_report = _safe_parse_turn_report(logs[0].record_data)
        if len(logs) > 1:
            previous_report = _safe_parse_turn_report(logs[1].record_data)
    
    try:
        hints = game_hints_service.generate_hints(
            all_species=all_species,
            current_turn=current_turn,
            recent_report=recent_report,
            previous_report=previous_report,
        )
        return {
            "hints": [h.to_dict() for h in hints],
            "turn": current_turn,
        }
    except Exception as e:
        logger.error(f"[æç¤ºAPI] ç”Ÿæˆæç¤ºå¤±è´¥: {e}", exc_info=True)
        return {"hints": [], "turn": current_turn, "error": "failed_to_generate_hints"}


@router.post("/hints/clear", tags=["hints"])
def clear_hints_cooldown() -> dict:
    """æ¸…é™¤æç¤ºå†·å´ï¼ˆæ–°å­˜æ¡£æ—¶è°ƒç”¨ï¼‰"""
    game_hints_service.clear_cooldown()
    return {"success": True, "message": "æç¤ºå†·å´å·²æ¸…é™¤"}


# åœ¨åˆ›å»ºå­˜æ¡£æ—¶é‡ç½®æˆå°±å’Œæç¤º
def _reset_game_services():
    """é‡ç½®æ¸¸æˆæœåŠ¡çŠ¶æ€ï¼ˆåˆ›å»º/åŠ è½½å­˜æ¡£æ—¶è°ƒç”¨ï¼‰"""
    achievement_service.reset()
    game_hints_service.clear_cooldown()
    energy_service.reset()


# ================== èƒ½é‡ç‚¹ç³»ç»Ÿ API ==================

from ..services.system.divine_energy import DivineEnergyService

# åˆå§‹åŒ–èƒ½é‡æœåŠ¡
energy_service = DivineEnergyService(settings.data_dir)

# ã€å…³é”®ã€‘å°†èƒ½é‡æœåŠ¡æ³¨å…¥å­˜æ¡£ç®¡ç†å™¨ï¼Œç¡®ä¿èƒ½é‡çŠ¶æ€éšå­˜æ¡£ä¿å­˜/åŠ è½½
save_manager.set_energy_service(energy_service)


@router.get("/energy", tags=["energy"])
def get_energy_status() -> dict:
    """è·å–èƒ½é‡çŠ¶æ€
    
    è¿”å›ï¼š
    - enabled: ç³»ç»Ÿæ˜¯å¦å¯ç”¨
    - current: å½“å‰èƒ½é‡
    - maximum: æœ€å¤§èƒ½é‡
    - regen_per_turn: æ¯å›åˆå›å¤
    - percentage: ç™¾åˆ†æ¯”
    """
    return energy_service.get_status()


@router.get("/energy/costs", tags=["energy"])
def get_energy_costs() -> dict:
    """è·å–æ‰€æœ‰æ“ä½œçš„èƒ½é‡æ¶ˆè€—å®šä¹‰"""
    return {
        "costs": energy_service.get_all_costs(),
    }


@router.get("/energy/history", tags=["energy"])
def get_energy_history(limit: int = 20) -> dict:
    """è·å–èƒ½é‡äº¤æ˜“å†å²"""
    return {
        "history": energy_service.get_history(limit),
    }


@router.post("/energy/calculate", tags=["energy"])
def calculate_energy_cost(request: dict) -> dict:
    """è®¡ç®—æ“ä½œçš„èƒ½é‡æ¶ˆè€—
    
    Body:
    - action: æ“ä½œç±»å‹
    - pressures: å‹åŠ›åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºå‹åŠ›æ¶ˆè€—è®¡ç®—ï¼‰
    - intensity: å¼ºåº¦ï¼ˆå¯é€‰ï¼‰
    """
    action = request.get("action", "")
    
    if action == "pressure" and "pressures" in request:
        cost = energy_service.get_pressure_cost(request["pressures"])
    else:
        cost = energy_service.get_cost(action, **request)
    
    can_afford, _ = energy_service.can_afford(action, **request)
    
    return {
        "action": action,
        "cost": cost,
        "can_afford": can_afford,
        "current_energy": energy_service.get_state().current,
    }


@router.post("/energy/toggle", tags=["energy"])
def toggle_energy_system(request: dict) -> dict:
    """å¯ç”¨/ç¦ç”¨èƒ½é‡ç³»ç»Ÿ
    
    Body:
    - enabled: bool
    """
    energy_service.enabled = request.get("enabled", True)
    return {
        "success": True,
        "enabled": energy_service.enabled,
    }


@router.post("/energy/set", tags=["energy"])
def set_energy(request: dict) -> dict:
    """è®¾ç½®èƒ½é‡å‚æ•°ï¼ˆGMæ¨¡å¼ï¼‰
    
    Body:
    - current: å½“å‰èƒ½é‡ï¼ˆå¯é€‰ï¼‰
    - maximum: æœ€å¤§èƒ½é‡ï¼ˆå¯é€‰ï¼‰
    - regen: æ¯å›åˆå›å¤ï¼ˆå¯é€‰ï¼‰
    """
    energy_service.set_energy(
        current=request.get("current"),
        maximum=request.get("maximum"),
        regen=request.get("regen"),
    )
    return energy_service.get_status()


# ================== æ‚äº¤æ§åˆ¶ API ==================

@router.get("/hybridization/candidates", tags=["hybridization"])
def get_hybridization_candidates() -> dict:
    """è·å–å¯æ‚äº¤çš„ç‰©ç§å¯¹
    
    è¿”å›æ‰€æœ‰æ»¡è¶³æ‚äº¤æ¡ä»¶çš„ç‰©ç§ç»„åˆã€‚
    """
    all_species = species_repository.list_species()
    alive_species = [sp for sp in all_species if sp.status == "alive"]
    
    candidates = []
    checked_pairs = set()
    
    for sp1 in alive_species:
        for sp2 in alive_species:
            if sp1.lineage_code >= sp2.lineage_code:
                continue
            
            pair_key = f"{sp1.lineage_code}-{sp2.lineage_code}"
            if pair_key in checked_pairs:
                continue
            checked_pairs.add(pair_key)
            
            can_hybrid, fertility = hybridization_service.can_hybridize(sp1, sp2)
            if can_hybrid:
                candidates.append({
                    "species_a": {
                        "lineage_code": sp1.lineage_code,
                        "common_name": sp1.common_name,
                        "latin_name": sp1.latin_name,
                        "genus_code": sp1.genus_code,
                    },
                    "species_b": {
                        "lineage_code": sp2.lineage_code,
                        "common_name": sp2.common_name,
                        "latin_name": sp2.latin_name,
                        "genus_code": sp2.genus_code,
                    },
                    "fertility": round(fertility, 3),
                    "genus": sp1.genus_code,
                })
    
    return {
        "candidates": candidates,
        "total": len(candidates),
    }


@router.post("/hybridization/execute", tags=["hybridization"])
async def execute_hybridization(request: dict) -> dict:
    """æ‰§è¡Œæ‚äº¤ï¼ˆä½¿ç”¨AIç”Ÿæˆæ‚äº¤ç‰©ç§ï¼‰
    
    Body:
    - species_a: ç‰©ç§Açš„lineage_code
    - species_b: ç‰©ç§Bçš„lineage_code
    
    æ¶ˆè€—èƒ½é‡ç‚¹ã€‚ä½¿ç”¨LLMç”Ÿæˆæ‚äº¤ç‰©ç§çš„åç§°ã€æè¿°å’Œå±æ€§ã€‚
    """
    code_a = request.get("species_a", "")
    code_b = request.get("species_b", "")
    
    if not code_a or not code_b:
        raise HTTPException(status_code=400, detail="è¯·æä¾›ä¸¤ä¸ªç‰©ç§ä»£ç ")
    
    # è·å–ç‰©ç§
    species_a = species_repository.get_by_lineage(code_a)
    species_b = species_repository.get_by_lineage(code_b)
    
    if not species_a:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {code_a} ä¸å­˜åœ¨")
    if not species_b:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {code_b} ä¸å­˜åœ¨")
    
    if species_a.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {code_a} å·²ç­ç»")
    if species_b.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {code_b} å·²ç­ç»")
    
    # æ£€æŸ¥æ‚äº¤å¯è¡Œæ€§
    can_hybrid, fertility = hybridization_service.can_hybridize(species_a, species_b)
    if not can_hybrid:
        raise HTTPException(status_code=400, detail="è¿™ä¸¤ä¸ªç‰©ç§æ— æ³•æ‚äº¤")
    
    # æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    can_afford, cost = energy_service.can_afford("hybridize")
    if not can_afford:
        raise HTTPException(
            status_code=400, 
            detail=f"èƒ½é‡ä¸è¶³ï¼æ‚äº¤éœ€è¦ {cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    # æ¶ˆè€—èƒ½é‡
    success, msg = energy_service.spend(
        "hybridize", 
        current_turn,
        details=f"æ‚äº¤ {species_a.common_name} Ã— {species_b.common_name}"
    )
    if not success:
        raise HTTPException(status_code=400, detail=msg)
    
    # æ”¶é›†ç°æœ‰ç¼–ç ï¼ˆç”¨äºæ‚äº¤ç§ç¼–ç ç”Ÿæˆï¼‰
    all_species = species_repository.list_species()
    existing_codes = {sp.lineage_code for sp in all_species}
    
    # æ‰§è¡Œæ‚äº¤ï¼ˆä½¿ç”¨å¼‚æ­¥AIè°ƒç”¨ï¼‰
    hybrid = await hybridization_service.create_hybrid_async(
        species_a, species_b, current_turn, 
        existing_codes=existing_codes
    )
    if not hybrid:
        # é€€è¿˜èƒ½é‡ï¼ˆæ‚äº¤å¤±è´¥ï¼‰
        energy_service.add_energy(cost, "æ‚äº¤å¤±è´¥é€€è¿˜")
        raise HTTPException(status_code=500, detail="æ‚äº¤å¤±è´¥")
    
    # ä¿å­˜æ‚äº¤ç§
    species_repository.upsert(hybrid)
    
    # è®°å½•æˆå°±
    achievement_service._unlock("hybrid_creator", current_turn)
    
    return {
        "success": True,
        "hybrid": {
            "lineage_code": hybrid.lineage_code,
            "latin_name": hybrid.latin_name,
            "common_name": hybrid.common_name,
            "description": hybrid.description,
            "fertility": hybrid.hybrid_fertility,
            "parent_codes": hybrid.hybrid_parent_codes,
        },
        "energy_spent": cost,
        "energy_remaining": energy_service.get_state().current,
    }


@router.get("/hybridization/preview", tags=["hybridization"])
def preview_hybridization(species_a: str, species_b: str) -> dict:
    """é¢„è§ˆæ‚äº¤ç»“æœ
    
    ä¸æ¶ˆè€—èƒ½é‡ï¼Œåªæ˜¾ç¤ºé¢„æœŸç»“æœã€‚
    """
    sp_a = species_repository.get_by_lineage(species_a)
    sp_b = species_repository.get_by_lineage(species_b)
    
    if not sp_a:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {species_a} ä¸å­˜åœ¨")
    if not sp_b:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {species_b} ä¸å­˜åœ¨")
    
    can_hybrid, fertility = hybridization_service.can_hybridize(sp_a, sp_b)
    
    if not can_hybrid:
        # åˆ†æä¸ºä»€ä¹ˆä¸èƒ½æ‚äº¤
        if sp_a.genus_code != sp_b.genus_code:
            reason = "ä¸åŒå±çš„ç‰©ç§æ— æ³•æ‚äº¤"
        elif sp_a.lineage_code == sp_b.lineage_code:
            reason = "åŒä¸€ç‰©ç§æ— æ³•æ‚äº¤"
        else:
            distance = genetic_distance_calculator.calculate_distance(sp_a, sp_b)
            reason = f"é—ä¼ è·ç¦»è¿‡å¤§ ({distance:.2f} >= 0.5)"
        
        return {
            "can_hybridize": False,
            "reason": reason,
            "fertility": 0,
            "energy_cost": energy_service.get_cost("hybridize"),
        }
    
    # é¢„è§ˆæ‚äº¤ç»“æœ
    hybrid_code = f"{sp_a.lineage_code}Ã—{sp_b.lineage_code}"
    hybrid_name = f"{sp_a.common_name}Ã—{sp_b.common_name}æ‚äº¤ç§"
    
    # é¢„æµ‹ç‰¹å¾
    predicted_trophic = max(sp_a.trophic_level, sp_b.trophic_level)
    combined_capabilities = list(set(sp_a.capabilities + sp_b.capabilities))
    
    return {
        "can_hybridize": True,
        "fertility": round(fertility, 3),
        "energy_cost": energy_service.get_cost("hybridize"),
        "can_afford": energy_service.can_afford("hybridize")[0],
        "preview": {
            "lineage_code": hybrid_code,
            "common_name": hybrid_name,
            "predicted_trophic_level": predicted_trophic,
            "combined_capabilities": combined_capabilities,
            "parent_traits_merged": True,
        },
    }


# ==================== å¼ºè¡Œæ‚äº¤ï¼ˆè·¨å±/å¹»æƒ³æ‚äº¤ï¼‰API ====================

FORCED_HYBRIDIZATION_COST = 50  # å¼ºè¡Œæ‚äº¤æ¶ˆè€—çš„èƒ½é‡ï¼ˆæ™®é€šæ‚äº¤çš„5å€ï¼‰


@router.get("/hybridization/force/preview", tags=["hybridization"])
def preview_forced_hybridization(species_a: str, species_b: str) -> dict:
    """é¢„è§ˆå¼ºè¡Œæ‚äº¤ç»“æœ
    
    å¼ºè¡Œæ‚äº¤å¯ä»¥è·¨è¶Šæ­£å¸¸æ‚äº¤é™åˆ¶ï¼Œå°†ä»»æ„ä¸¤ä¸ªç‰©ç§èåˆæˆåµŒåˆä½“ã€‚
    - æ¶ˆè€—èƒ½é‡ï¼š50ç‚¹ï¼ˆæ™®é€šæ‚äº¤çš„5å€ï¼‰
    - äº§ç‰©ï¼šåµŒåˆä½“ï¼ˆChimeraï¼‰
    - å¯è‚²æ€§ï¼šæä½æˆ–ä¸è‚²
    - é£é™©ï¼šåŸºå› ä¸ç¨³å®š
    """
    sp_a = species_repository.get_by_lineage(species_a)
    sp_b = species_repository.get_by_lineage(species_b)
    
    if not sp_a:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {species_a} ä¸å­˜åœ¨")
    if not sp_b:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {species_b} ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¼ºè¡Œæ‚äº¤
    can_force, reason = hybridization_service.can_force_hybridize(sp_a, sp_b)
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ­£å¸¸æ‚äº¤
    can_normal, normal_fertility = hybridization_service.can_hybridize(sp_a, sp_b)
    
    # é¢„ä¼°åµŒåˆä½“ç‰¹å¾
    trophic_diff = abs(sp_a.trophic_level - sp_b.trophic_level)
    estimated_fertility = max(0.0, 0.15 - trophic_diff * 0.03)
    if sp_a.genus_code != sp_b.genus_code:
        estimated_fertility *= 0.3
    
    # ç¨³å®šæ€§é¢„ä¼°
    if sp_a.genus_code == sp_b.genus_code:
        stability = "unstable"
    elif trophic_diff <= 1.0:
        stability = "unstable"
    else:
        stability = "volatile"
    
    return {
        "can_force_hybridize": can_force,
        "reason": reason,
        "can_normal_hybridize": can_normal,
        "normal_fertility": round(normal_fertility, 3) if can_normal else 0,
        "energy_cost": FORCED_HYBRIDIZATION_COST,
        "can_afford": energy_service.get_state().current >= FORCED_HYBRIDIZATION_COST,
        "current_energy": energy_service.get_state().current,
        "preview": {
            "type": "chimera",
            "estimated_fertility": round(estimated_fertility, 3),
            "stability": stability,
            "parent_a": {
                "code": sp_a.lineage_code,
                "name": sp_a.common_name,
                "trophic": sp_a.trophic_level,
            },
            "parent_b": {
                "code": sp_b.lineage_code,
                "name": sp_b.common_name,
                "trophic": sp_b.trophic_level,
            },
            "warnings": [
                "åµŒåˆä½“é€šå¸¸ä¸è‚²æˆ–æä½å¯è‚²æ€§",
                "åŸºå› ä¸ç¨³å®šå¯èƒ½å¯¼è‡´å¯¿å‘½ç¼©çŸ­",
                "å¯èƒ½å‡ºç°æ„æƒ³ä¸åˆ°çš„èƒ½åŠ›æˆ–ç¼ºé™·",
            ] if can_force else [],
        },
    }


@router.post("/hybridization/force/execute", tags=["hybridization"])
async def execute_forced_hybridization(request: dict) -> dict:
    """æ‰§è¡Œå¼ºè¡Œæ‚äº¤ï¼ˆåˆ›é€ åµŒåˆä½“ï¼‰
    
    Body:
    - species_a: ç‰©ç§Açš„lineage_code
    - species_b: ç‰©ç§Bçš„lineage_code
    
    æ¶ˆè€—50èƒ½é‡ç‚¹ï¼Œå°†ä»»æ„ä¸¤ä¸ªç‰©ç§å¼ºè¡ŒèåˆæˆåµŒåˆä½“ï¼ˆChimeraï¼‰ã€‚
    
    âš ï¸ è­¦å‘Šï¼š
    - åµŒåˆä½“é€šå¸¸ä¸è‚²æˆ–æä½å¯è‚²æ€§
    - åŸºå› ä¸ç¨³å®šå¯èƒ½å¯¼è‡´æ„å¤–å˜å¼‚
    - è¿™æ˜¯è¿èƒŒè‡ªç„¶è§„å¾‹çš„å®éªŒ
    """
    code_a = request.get("species_a", "")
    code_b = request.get("species_b", "")
    
    if not code_a or not code_b:
        raise HTTPException(status_code=400, detail="è¯·æä¾›ä¸¤ä¸ªç‰©ç§ä»£ç ")
    
    # è·å–ç‰©ç§
    species_a = species_repository.get_by_lineage(code_a)
    species_b = species_repository.get_by_lineage(code_b)
    
    if not species_a:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {code_a} ä¸å­˜åœ¨")
    if not species_b:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {code_b} ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¼ºè¡Œæ‚äº¤
    can_force, reason = hybridization_service.can_force_hybridize(species_a, species_b)
    if not can_force:
        raise HTTPException(status_code=400, detail=reason)
    
    # è·å–å½“å‰å›åˆ
    current_turn = simulation_engine.turn_counter
    
    # ä½¿ç”¨ energy_service.spend() æ–¹æ³•æ¶ˆè€—èƒ½é‡
    success, message = energy_service.spend(
        action="forced_hybridize",
        turn=current_turn,
        details=f"å¼ºè¡Œæ‚äº¤ {species_a.common_name} Ã— {species_b.common_name}"
    )
    
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    # æ”¶é›†ç°æœ‰ç¼–ç 
    all_species = species_repository.list_species()
    existing_codes = {sp.lineage_code for sp in all_species}
    
    # æ‰§è¡Œå¼ºè¡Œæ‚äº¤
    chimera = await hybridization_service.force_hybridize_async(
        species_a, species_b, current_turn, existing_codes
    )
    
    if not chimera:
        # é€€è¿˜èƒ½é‡ - ç›´æ¥æ·»åŠ å›å»
        energy_service.add_energy(FORCED_HYBRIDIZATION_COST, "å¼ºè¡Œæ‚äº¤å¤±è´¥ï¼Œèƒ½é‡é€€è¿˜")
        raise HTTPException(status_code=500, detail="å¼ºè¡Œæ‚äº¤å®éªŒå¤±è´¥")
    
    # ä¿å­˜åµŒåˆä½“
    species_repository.upsert(chimera)
    
    # è®°å½•æˆå°±
    achievement_service._unlock("chimera_creator", current_turn)
    achievement_service._unlock("mad_scientist", current_turn)
    
    return {
        "success": True,
        "chimera": {
            "lineage_code": chimera.lineage_code,
            "latin_name": chimera.latin_name,
            "common_name": chimera.common_name,
            "description": chimera.description,
            "fertility": chimera.hybrid_fertility,
            "parent_codes": chimera.hybrid_parent_codes,
            "taxonomic_rank": chimera.taxonomic_rank,
            "stability": chimera.hidden_traits.get("genetic_stability", 0.5),
        },
        "energy_spent": FORCED_HYBRIDIZATION_COST,
        "energy_remaining": energy_service.get_state().current,
        "warnings": [
            f"åµŒåˆä½“å¯è‚²æ€§ä»…ä¸º {chimera.hybrid_fertility:.1%}",
            "åŸºå› ä¸ç¨³å®šå¯èƒ½å¯¼è‡´åä»£å˜å¼‚æˆ–å¯¿å‘½ç¼©çŸ­",
        ],
    }


# ==================== ç¥åŠ›è¿›é˜¶ç³»ç»Ÿ API ====================

from ..services.system.divine_progression import (
    DivinePath,
    DIVINE_SKILLS,
    MIRACLES,
    WagerType,
    WAGER_TYPES,
)
# divine_progression_service å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥

# ã€å…³é”®ã€‘å°†ç¥åŠ›è¿›é˜¶æœåŠ¡æ³¨å…¥å­˜æ¡£ç®¡ç†å™¨
save_manager.set_progression_service(divine_progression_service)


@router.get("/divine/status", tags=["divine"])
def get_divine_status() -> dict:
    """è·å–ç¥åŠ›è¿›é˜¶ç³»ç»Ÿå®Œæ•´çŠ¶æ€
    
    åŒ…æ‹¬ï¼šç¥æ ¼ã€ä¿¡ä»°ã€ç¥è¿¹ã€é¢„è¨€å››å¤§å­ç³»ç»Ÿã€‚
    """
    return divine_progression_service.get_full_status()


@router.get("/divine/paths", tags=["divine"])
def get_available_paths() -> dict:
    """è·å–å¯é€‰æ‹©çš„ç¥æ ¼è·¯çº¿"""
    return {
        "paths": divine_progression_service.get_available_paths(),
        "current_path": divine_progression_service.get_path_info(),
    }


@router.post("/divine/path/choose", tags=["divine"])
def choose_divine_path(request: dict) -> dict:
    """é€‰æ‹©ç¥æ ¼è·¯çº¿
    
    Body:
    - path: ç¥æ ¼è·¯çº¿ (creator/guardian/chaos/ecology)
    
    æ³¨æ„ï¼šä¸»ç¥æ ¼é€‰æ‹©åä¸å¯æ›´æ”¹ï¼Œ4çº§åå¯é€‰å‰¯ç¥æ ¼ã€‚
    """
    path_str = request.get("path", "")
    logger.info(f"[ç¥æ ¼] æ”¶åˆ°é€‰æ‹©è¯·æ±‚: {path_str}")
    
    try:
        path = DivinePath(path_str)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„ç¥æ ¼è·¯çº¿: {path_str}")
    
    if path == DivinePath.NONE:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©ä¸€ä¸ªæœ‰æ•ˆçš„ç¥æ ¼")
    
    success, message = divine_progression_service.choose_path(path)
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    logger.info(f"[ç¥æ ¼] é€‰æ‹©æˆåŠŸ: {path.value}, è§£é”æŠ€èƒ½: {divine_progression_service.get_state().path_progress.unlocked_skills}")
    
    return {
        "success": True,
        "message": message,
        "path_info": divine_progression_service.get_path_info(),
    }


@router.get("/divine/skills", tags=["divine"])
def get_divine_skills() -> dict:
    """è·å–æ‰€æœ‰ç¥åŠ›æŠ€èƒ½ä¿¡æ¯"""
    path_info = divine_progression_service.get_path_info()
    current_path = path_info["path"] if path_info else None
    
    all_skills = []
    for skill_id, skill in DIVINE_SKILLS.items():
        info = divine_progression_service.get_skill_info(skill_id)
        info["is_current_path"] = skill.path.value == current_path
        all_skills.append(info)
    
    return {
        "skills": all_skills,
        "current_path": current_path,
    }


@router.post("/divine/skill/use", tags=["divine"])
async def use_divine_skill(request: dict) -> dict:
    """ä½¿ç”¨ç¥åŠ›æŠ€èƒ½
    
    Body:
    - skill_id: æŠ€èƒ½ID
    - target: ç›®æ ‡ï¼ˆç‰©ç§ä»£ç æˆ–åæ ‡ï¼Œå–å†³äºæŠ€èƒ½ï¼‰
    """
    skill_id = request.get("skill_id", "")
    target = request.get("target")
    
    logger.info(f"[æŠ€èƒ½] å°è¯•ä½¿ç”¨: {skill_id}, ç›®æ ‡: {target}")
    
    if skill_id not in DIVINE_SKILLS:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„æŠ€èƒ½: {skill_id}")
    
    skill = DIVINE_SKILLS[skill_id]
    skill_info = divine_progression_service.get_skill_info(skill_id)
    
    # æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©ç¥æ ¼
    path_info = divine_progression_service.get_path_info()
    if not path_info:
        raise HTTPException(status_code=400, detail="è¯·å…ˆé€‰æ‹©ä¸€ä¸ªç¥æ ¼è·¯çº¿")
    
    if not skill_info["unlocked"]:
        raise HTTPException(status_code=400, detail=f"æŠ€èƒ½ã€Œ{skill.name}ã€å°šæœªè§£é”ï¼ˆéœ€è¦ç­‰çº§ {skill.unlock_level}ï¼‰")
    
    # æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    can_afford, cost = energy_service.can_afford("pressure", intensity=skill.cost // 3)
    actual_cost = skill.cost
    
    if energy_service.get_state().current < actual_cost:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼{skill.name}éœ€è¦ {actual_cost} èƒ½é‡"
        )
    
    # æ¶ˆè€—èƒ½é‡
    success, msg = energy_service.spend_fixed(actual_cost, current_turn, details=f"æŠ€èƒ½: {skill.name}")
    if not success:
        raise HTTPException(status_code=400, detail=msg)
    
    logger.info(f"[æŠ€èƒ½] æ¶ˆè€—èƒ½é‡æˆåŠŸ: {actual_cost}, æŠ€èƒ½: {skill.name}")
    
    # å¢åŠ ç»éªŒ
    divine_progression_service.add_experience(actual_cost)
    
    # è®°å½•æŠ€èƒ½ä½¿ç”¨
    state = divine_progression_service.get_state()
    state.path_progress.skills_used[skill_id] = state.path_progress.skills_used.get(skill_id, 0) + 1
    state.total_skills_used += 1
    
    # æ‰§è¡ŒæŠ€èƒ½æ•ˆæœï¼ˆæ ¹æ®æŠ€èƒ½ç±»å‹ï¼‰
    result = {"effect": "executed", "details": f"æŠ€èƒ½ã€Œ{skill.name}ã€å·²é‡Šæ”¾"}
    
    # ç‰¹å®šæŠ€èƒ½çš„é¢å¤–æ•ˆæœ
    if skill_id == "ancestor_blessing" and target:
        species = species_repository.get_by_lineage(target)
        if species:
            species.can_open_lineage = True
            species_repository.upsert(species)
            result["details"] = f"å·²èµäºˆã€Œ{species.common_name}ã€å§‹ç¥–æ ‡è®°"
    
    elif skill_id == "life_shelter" and target:
        species = species_repository.get_by_lineage(target)
        if species:
            species.is_protected = True
            species.protection_turns = 999  # æ°¸ä¹…ä¿æŠ¤ï¼ˆä¸€æ¬¡æ€§ï¼‰
            species_repository.upsert(species)
            result["details"] = f"ã€Œ{species.common_name}ã€è·å¾—ç”Ÿå‘½åº‡æŠ¤"
    
    elif skill_id == "mass_extinction":
        all_species = species_repository.list_species()
        culled = 0
        
        def calculate_fitness(sp):
            """è®¡ç®—ç‰©ç§é€‚åº”åº¦ï¼ˆ0-1èŒƒå›´ï¼‰"""
            traits = sp.abstract_traits or {}
            adaptability = traits.get("é€‚åº”æ€§", 5) / 10.0
            morph = sp.morphology_stats or {}
            morph_avg = sum(morph.values()) / max(1, len(morph)) if morph else 0.5
            return (adaptability + morph_avg) / 2
        
        for sp in all_species:
            if sp.status == "alive":
                fitness = calculate_fitness(sp)
                if fitness < 0.25:
                    sp.status = "extinct"
                    sp.extinction_turn = current_turn
                    sp.extinction_cause = "divine_judgement"
                    species_repository.upsert(sp)
                    culled += 1
        result["details"] = f"å¤§ç­ç»æ¸…é™¤äº† {culled} ä¸ªä½é€‚åº”åŠ›ç‰©ç§"
    
    elif skill_id == "life_spark":
        # ç”Ÿå‘½ç«ç§ï¼šä½¿ç”¨AIåˆ›é€ ä¸€ä¸ªåŸºç¡€ç”Ÿäº§è€…ç‰©ç§
        try:
            # è‡ªåŠ¨ç”Ÿæˆlineage_code
            existing_species = species_repository.get_all()
            used_codes = {s.lineage_code for s in existing_species}
            prefix = "P"  # Plant prefix
            index = 1
            while f"{prefix}{index}" in used_codes:
                index += 1
            new_code = f"{prefix}{index}"
            
            # ä½¿ç”¨AIç”Ÿæˆç‰©ç§
            new_species = species_generator.generate_advanced(
                prompt="ä¸€ç§èƒ½å¤Ÿåœ¨å½“å‰ç¯å¢ƒä¸­è‡ªç»™è‡ªè¶³çš„åŸºç¡€å…‰åˆç”Ÿç‰©ï¼Œä½œä¸ºç”Ÿæ€ç³»ç»Ÿçš„åˆçº§ç”Ÿäº§è€…",
                lineage_code=new_code,
                existing_species=existing_species,
                is_plant=True,
                diet_type="autotroph",
            )
            species_repository.upsert(new_species)
            result["details"] = f"ç”Ÿå‘½ç«ç§è¯ç”Ÿäº†ã€Œ{new_species.common_name}ã€({new_code})"
            result["new_species"] = {
                "lineage_code": new_species.lineage_code,
                "common_name": new_species.common_name,
                "latin_name": new_species.latin_name,
            }
        except Exception as e:
            logger.error(f"[ç”Ÿå‘½ç«ç§] åˆ›é€ ç‰©ç§å¤±è´¥: {e}")
            result["details"] = f"ç”Ÿå‘½ç«ç§åˆ›é€ å¤±è´¥: {str(e)}"
            result["error"] = True
    
    elif skill_id == "revival_light":
        # å¤è‹ä¹‹å…‰ï¼šå¤æ´»æœ€è¿‘ç­ç»çš„ç‰©ç§
        all_species = species_repository.list_species()
        extinct_species = [
            sp for sp in all_species 
            if sp.status == "extinct" and sp.extinction_turn is not None
        ]
        
        if not extinct_species:
            result["details"] = "æ²¡æœ‰å¯å¤æ´»çš„å·²ç­ç»ç‰©ç§"
            result["error"] = True
        else:
            # æ‰¾åˆ°æœ€è¿‘ç­ç»çš„ç‰©ç§
            extinct_species.sort(key=lambda x: x.extinction_turn or 0, reverse=True)
            target = extinct_species[0]
            
            # è·å–ç­ç»å‰çš„ç§ç¾¤å¿«ç…§
            from ..models.species import PopulationSnapshot
            from ..core.database import session_scope
            
            last_population = 100000  # é»˜è®¤å€¼
            try:
                with session_scope() as session:
                    # æŸ¥æ‰¾è¯¥ç‰©ç§ç­ç»å‰æœ€åä¸€ä¸ªç§ç¾¤å¿«ç…§
                    snapshots = session.exec(
                        select(PopulationSnapshot)
                        .where(PopulationSnapshot.species_id == target.id)
                        .order_by(PopulationSnapshot.turn_index.desc())
                    ).all()
                    if snapshots:
                        # å–æœ€åä¸€ä¸ªå¿«ç…§çš„ç§ç¾¤æ€»æ•°
                        total_pop = sum(s.count for s in snapshots if s.turn_index == snapshots[0].turn_index)
                        if total_pop > 0:
                            last_population = total_pop
            except Exception as e:
                logger.warning(f"[å¤è‹ä¹‹å…‰] è·å–ç§ç¾¤å¿«ç…§å¤±è´¥: {e}")
            
            # æ¢å¤ç‰©ç§
            target.status = "alive"
            target.extinction_turn = None
            target.extinction_cause = None
            # è®¾ç½®åˆå§‹ç§ç¾¤ä¸ºç­ç»å‰çš„50%ï¼ˆå­˜å‚¨åœ¨ morphology_stats ä¸­ï¼‰
            restored_population = max(1000, int(last_population * 0.5))
            if not target.morphology_stats:
                target.morphology_stats = {}
            target.morphology_stats["population"] = restored_population
            # è®°å½•å†å²
            if not target.history_highlights:
                target.history_highlights = []
            target.history_highlights.append(f"å›åˆ{current_turn}: è¢«å¤è‹ä¹‹å…‰å¤æ´»")
            species_repository.upsert(target)
            
            result["details"] = f"å¤è‹ä¹‹å…‰å¤æ´»äº†ã€Œ{target.common_name}ã€ï¼Œç§ç¾¤æ¢å¤è‡³ {restored_population:,}"
            result["revived_species"] = {
                "lineage_code": target.lineage_code,
                "common_name": target.common_name,
                "restored_population": restored_population,
            }
    
    elif skill_id == "divine_speciation":
        # ç¥å¯åˆ†åŒ–ï¼šå¼ºåˆ¶ç‰©ç§ç«‹å³äº§ç”Ÿåˆ†åŒ–
        if not target:
            result["details"] = "è¯·æŒ‡å®šç›®æ ‡ç‰©ç§"
            result["error"] = True
        else:
            species = species_repository.get_by_lineage(target)
            if not species:
                result["details"] = f"ç‰©ç§ {target} ä¸å­˜åœ¨"
                result["error"] = True
            elif species.status != "alive":
                result["details"] = f"ç‰©ç§ {target} å·²ç­ç»ï¼Œæ— æ³•åˆ†åŒ–"
                result["error"] = True
            else:
                try:
                    # ç”Ÿæˆåˆ†åŒ–åä»£
                    existing_species = species_repository.get_all()
                    used_codes = {s.lineage_code for s in existing_species}
                    
                    # ç”Ÿæˆå­ä»£ç¼–ç 
                    base = species.lineage_code
                    suffix = 1
                    while f"{base}.{suffix}" in used_codes:
                        suffix += 1
                    child_code = f"{base}.{suffix}"
                    
                    child = species_generator.generate_advanced(
                        prompt=f"ä»ã€Œ{species.common_name}ã€åˆ†åŒ–å‡ºçš„é€‚åº”æ€§å˜ç§ï¼Œä¿ç•™éƒ¨åˆ†ç¥–å…ˆç‰¹å¾ä½†æœ‰æ˜æ˜¾å·®å¼‚",
                        lineage_code=child_code,
                        existing_species=existing_species,
                        parent_code=species.lineage_code,
                        habitat_type=species.habitat_type,
                    )
                    species_repository.upsert(child)
                    result["details"] = f"ã€Œ{species.common_name}ã€åˆ†åŒ–å‡ºæ–°ç‰©ç§ã€Œ{child.common_name}ã€"
                    result["new_species"] = {
                        "lineage_code": child.lineage_code,
                        "common_name": child.common_name,
                        "parent_code": species.lineage_code,
                    }
                except Exception as e:
                    logger.error(f"[ç¥å¯åˆ†åŒ–] å¤±è´¥: {e}")
                    result["details"] = f"åˆ†åŒ–å¤±è´¥: {str(e)}"
                    result["error"] = True
    
    elif skill_id == "chaos_mutation":
        # æ··æ²Œçªå˜ï¼šéšæœºå¤§å¹…æ”¹å˜ç‰©ç§ç‰¹å¾
        if not target:
            result["details"] = "è¯·æŒ‡å®šç›®æ ‡ç‰©ç§"
            result["error"] = True
        else:
            species = species_repository.get_by_lineage(target)
            if not species:
                result["details"] = f"ç‰©ç§ {target} ä¸å­˜åœ¨"
                result["error"] = True
            elif species.status != "alive":
                result["details"] = f"ç‰©ç§ {target} å·²ç­ç»"
                result["error"] = True
            else:
                import random
                # éšæœºä¿®æ”¹å½¢æ€ç‰¹å¾
                mutations = []
                for trait, value in species.morphology_stats.items():
                    if random.random() < 0.5:  # 50%æ¦‚ç‡æ”¹å˜æ¯ä¸ªç‰¹å¾
                        change = random.uniform(-0.3, 0.3)
                        new_value = max(0.1, min(1.0, value + change))
                        species.morphology_stats[trait] = round(new_value, 3)
                        mutations.append(f"{trait}: {value:.2f}â†’{new_value:.2f}")
                
                # å¯èƒ½æ”¹å˜é£Ÿæ€§
                if random.random() < 0.2:
                    new_diet = random.choice(["herbivore", "carnivore", "omnivore", "detritivore"])
                    if new_diet != species.diet_type:
                        mutations.append(f"é£Ÿæ€§: {species.diet_type}â†’{new_diet}")
                        species.diet_type = new_diet
                
                species_repository.upsert(species)
                result["details"] = f"æ··æ²Œçªå˜æ”¹å˜äº†ã€Œ{species.common_name}ã€çš„ {len(mutations)} ä¸ªç‰¹å¾"
                result["mutations"] = mutations[:5]  # åªè¿”å›å‰5ä¸ª
    
    return {
        "success": True,
        "skill": skill.name,
        "cost": actual_cost,
        "result": result,
        "energy_remaining": energy_service.get_state().current,
    }


# ========== ä¿¡ä»°ç³»ç»Ÿ API ==========

@router.get("/divine/faith", tags=["divine"])
def get_faith_status() -> dict:
    """è·å–ä¿¡ä»°ç³»ç»ŸçŠ¶æ€"""
    return divine_progression_service.get_faith_summary()


@router.post("/divine/faith/add", tags=["divine"])
def add_follower(request: dict) -> dict:
    """æ·»åŠ ä¿¡å¾’
    
    Body:
    - lineage_code: ç‰©ç§ä»£ç 
    """
    lineage_code = request.get("lineage_code", "")
    logger.info(f"[ä¿¡ä»°] å°è¯•æ·»åŠ ä¿¡å¾’: {lineage_code}")
    
    if not lineage_code:
        raise HTTPException(status_code=400, detail="è¯·æä¾›ç‰©ç§ä»£ç ")
    
    species = species_repository.get_by_lineage(lineage_code)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {lineage_code} ä¸å­˜åœ¨")
    
    if species.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {lineage_code} å·²ç­ç»")
    
    # ä» morphology_stats è·å–ç§ç¾¤
    morph = species.morphology_stats or {}
    population = morph.get("population", 100000)
    trophic = species.trophic_level or 1
    
    success = divine_progression_service.add_follower(
        lineage_code, species.common_name, population, trophic
    )
    
    if not success:
        raise HTTPException(status_code=400, detail="è¯¥ç‰©ç§å·²æ˜¯ä¿¡å¾’")
    
    logger.info(f"[ä¿¡ä»°] æ·»åŠ ä¿¡å¾’æˆåŠŸ: {species.common_name}")
    return {
        "success": True,
        "message": f"ã€Œ{species.common_name}ã€å·²æˆä¸ºä¿¡å¾’",
        "faith_summary": divine_progression_service.get_faith_summary(),
    }


@router.post("/divine/faith/bless", tags=["divine"])
def bless_follower(request: dict) -> dict:
    """æ˜¾åœ£ - èµç¦ä¿¡å¾’
    
    Body:
    - lineage_code: ä¿¡å¾’ç‰©ç§ä»£ç 
    
    æ¶ˆè€—20èƒ½é‡ï¼Œä½¿ä¿¡å¾’è·å¾—ç¥çœ·æ ‡è®°ã€‚
    """
    lineage_code = request.get("lineage_code", "")
    
    # æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    cost = 20
    if energy_service.get_state().current < cost:
        raise HTTPException(status_code=400, detail=f"èƒ½é‡ä¸è¶³ï¼æ˜¾åœ£éœ€è¦ {cost} èƒ½é‡")
    
    success, message = divine_progression_service.bless_follower(lineage_code)
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    # æ¶ˆè€—èƒ½é‡
    success, msg = energy_service.spend_fixed(cost, current_turn, details=f"æ˜¾åœ£: {lineage_code}")
    if not success:
        raise HTTPException(status_code=400, detail=msg)
    
    # åº”ç”¨æ•ˆæœåˆ°ç‰©ç§ï¼šæå‡æŠ½è±¡ç‰¹å¾
    species = species_repository.get_by_lineage(lineage_code)
    if species and species.abstract_traits:
        for trait in species.abstract_traits:
            species.abstract_traits[trait] = min(10.0, species.abstract_traits[trait] * 1.1)
        if not species.history_highlights:
            species.history_highlights = []
        species.history_highlights.append(f"è·å¾—ç¥çœ·ç¥ç¦ï¼Œé€‚åº”èƒ½åŠ›æå‡")
        species_repository.upsert(species)
    
    return {
        "success": True,
        "message": message,
        "energy_spent": cost,
        "faith_summary": divine_progression_service.get_faith_summary(),
    }


@router.post("/divine/faith/sanctify", tags=["divine"])
def sanctify_follower(request: dict) -> dict:
    """åœ£åŒ– - å°†ä¿¡å¾’æå‡ä¸ºåœ£ç‰©ç§
    
    Body:
    - lineage_code: ä¿¡å¾’ç‰©ç§ä»£ç 
    
    æ¶ˆè€—40èƒ½é‡ï¼Œä½¿ä¿¡å¾’æˆä¸ºåœ£ç‰©ç§ï¼Œæ°¸ä¹…å…ç–«å‹åˆ¶ã€‚
    """
    lineage_code = request.get("lineage_code", "")
    
    # æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    cost = 40
    if energy_service.get_state().current < cost:
        raise HTTPException(status_code=400, detail=f"èƒ½é‡ä¸è¶³ï¼åœ£åŒ–éœ€è¦ {cost} èƒ½é‡")
    
    success, message = divine_progression_service.sanctify_follower(lineage_code)
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    # æ¶ˆè€—èƒ½é‡
    success, msg = energy_service.spend_fixed(cost, current_turn, details=f"åœ£åŒ–: {lineage_code}")
    if not success:
        raise HTTPException(status_code=400, detail=msg)
    
    # åº”ç”¨æ•ˆæœåˆ°ç‰©ç§
    species = species_repository.get_by_lineage(lineage_code)
    if species:
        species.is_protected = True
        species.protection_turns = 999
        species_repository.upsert(species)
    
    return {
        "success": True,
        "message": message,
        "energy_spent": cost,
        "faith_summary": divine_progression_service.get_faith_summary(),
    }


# ========== ç¥è¿¹ç³»ç»Ÿ API ==========

@router.get("/divine/miracles", tags=["divine"])
def get_miracles() -> dict:
    """è·å–æ‰€æœ‰ç¥è¿¹ä¿¡æ¯"""
    return {
        "miracles": divine_progression_service.get_all_miracles(),
        "charging": divine_progression_service.get_state().miracle_state.charging,
    }


@router.post("/divine/miracle/charge", tags=["divine"])
def start_miracle_charge(request: dict) -> dict:
    """å¼€å§‹è“„åŠ›ç¥è¿¹
    
    Body:
    - miracle_id: ç¥è¿¹ID
    
    ç¥è¿¹éœ€è¦è“„åŠ›å¤šå›åˆï¼Œè“„åŠ›æœŸé—´èƒ½é‡è¢«é”å®šã€‚
    """
    miracle_id = request.get("miracle_id", "")
    
    if miracle_id not in MIRACLES:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„ç¥è¿¹: {miracle_id}")
    
    miracle = MIRACLES[miracle_id]
    
    # æ£€æŸ¥èƒ½é‡
    if energy_service.get_state().current < miracle.cost:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼ã€Œ{miracle.name}ã€éœ€è¦ {miracle.cost} èƒ½é‡"
        )
    
    success, message, cost = divine_progression_service.start_miracle_charge(miracle_id)
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    # é”å®šèƒ½é‡ï¼ˆå®é™…æ‰£é™¤ï¼‰
    current_turn = simulation_engine.turn_counter
    energy_service.spend("pressure", current_turn, details=f"ç¥è¿¹è“„åŠ›: {miracle.name}", intensity=cost // 3)
    
    return {
        "success": True,
        "message": message,
        "miracle": divine_progression_service.get_miracle_info(miracle_id),
        "energy_locked": cost,
    }


@router.post("/divine/miracle/cancel", tags=["divine"])
def cancel_miracle_charge() -> dict:
    """å–æ¶ˆè“„åŠ›ç¥è¿¹
    
    å–æ¶ˆè“„åŠ›è¿”è¿˜80%èƒ½é‡ã€‚
    """
    success, refund = divine_progression_service.cancel_miracle_charge()
    if not success:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æ­£åœ¨è“„åŠ›çš„ç¥è¿¹")
    
    # è¿”è¿˜èƒ½é‡
    energy_service.add_energy(refund, "å–æ¶ˆç¥è¿¹è“„åŠ›")
    
    return {
        "success": True,
        "message": f"å·²å–æ¶ˆè“„åŠ›ï¼Œè¿”è¿˜ {refund} èƒ½é‡",
        "energy_refunded": refund,
        "current_energy": energy_service.get_state().current,
    }


@router.post("/divine/miracle/execute", tags=["divine"])
async def execute_miracle(request: dict) -> dict:
    """æ‰‹åŠ¨è§¦å‘ç¥è¿¹
    
    Body:
    - miracle_id: ç¥è¿¹ID
    - target: ç›®æ ‡ï¼ˆæŸäº›ç¥è¿¹éœ€è¦ï¼‰
    """
    miracle_id = request.get("miracle_id", "")
    target = request.get("target")
    
    logger.info(f"[ç¥è¿¹] å°è¯•é‡Šæ”¾: {miracle_id}")
    
    if miracle_id not in MIRACLES:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„ç¥è¿¹: {miracle_id}")
    
    miracle = MIRACLES[miracle_id]
    miracle_info = divine_progression_service.get_miracle_info(miracle_id)
    
    # æ£€æŸ¥ä¸€æ¬¡æ€§ç¥è¿¹æ˜¯å¦å·²ä½¿ç”¨
    if miracle.one_time and miracle_id in divine_progression_service.get_state().miracle_state.used_one_time:
        raise HTTPException(status_code=400, detail=f"ã€Œ{miracle.name}ã€æ˜¯ä¸€æ¬¡æ€§ç¥è¿¹ï¼Œå·²ä½¿ç”¨è¿‡")
    
    # æ£€æŸ¥å†·å´
    if miracle_info["current_cooldown"] > 0:
        raise HTTPException(
            status_code=400,
            detail=f"ç¥è¿¹å†·å´ä¸­ï¼Œå‰©ä½™ {miracle_info['current_cooldown']} å›åˆ"
        )
    
    # æ£€æŸ¥èƒ½é‡
    current_turn = simulation_engine.turn_counter
    if energy_service.get_state().current < miracle.cost:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼ã€Œ{miracle.name}ã€éœ€è¦ {miracle.cost} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    # æ¶ˆè€—èƒ½é‡
    success, msg = energy_service.spend_fixed(miracle.cost, current_turn, details=f"ç¥è¿¹: {miracle.name}")
    if not success:
        raise HTTPException(status_code=400, detail=msg)
    
    logger.info(f"[ç¥è¿¹] æ¶ˆè€—èƒ½é‡æˆåŠŸ: {miracle.cost}, ç¥è¿¹: {miracle.name}")
    
    # è®¾ç½®å†·å´
    state = divine_progression_service.get_state()
    state.miracle_state.cooldowns[miracle_id] = miracle.cooldown
    state.miracle_state.miracles_cast += 1
    
    if miracle.one_time:
        state.miracle_state.used_one_time.append(miracle_id)
    
    # æ‰§è¡Œç¥è¿¹æ•ˆæœ
    result = {"effect": "executed", "details": f"ç¥è¿¹ã€Œ{miracle.name}ã€å·²é‡Šæ”¾"}
    
    if miracle_id == "tree_of_life":
        # éšæœºé€‰æ‹©3ä¸ªç‰©ç§äº§ç”Ÿåˆ†åŒ–
        all_species = species_repository.list_species()
        alive = [sp for sp in all_species if sp.status == "alive"]
        import random
        selected = random.sample(alive, min(3, len(alive)))
        result["details"] = f"ç”Ÿå‘½ä¹‹æ ‘è§¦å‘ï¼Œ{len(selected)} ä¸ªç‰©ç§å³å°†åˆ†åŒ–"
        result["affected_species"] = [sp.lineage_code for sp in selected]
    
    elif miracle_id == "judgement_day":
        # æ¸…é™¤ä½é€‚åº”åŠ›ç‰©ç§ï¼ˆåŸºäº abstract_traits çš„é€‚åº”æ€§è¯„ä¼°ï¼‰
        all_species = species_repository.list_species()
        culled = 0
        survivors = []
        
        def calculate_fitness(sp):
            """è®¡ç®—ç‰©ç§é€‚åº”åº¦ï¼ˆ0-1èŒƒå›´ï¼‰"""
            traits = sp.abstract_traits or {}
            adaptability = traits.get("é€‚åº”æ€§", 5) / 10.0
            morph = sp.morphology_stats or {}
            morph_avg = sum(morph.values()) / max(1, len(morph)) if morph else 0.5
            return (adaptability + morph_avg) / 2
        
        for sp in all_species:
            if sp.status == "alive":
                fitness = calculate_fitness(sp)
                if fitness < 0.25:
                    sp.status = "extinct"
                    sp.extinction_turn = current_turn
                    sp.extinction_cause = "divine_judgement"
                    species_repository.upsert(sp)
                    culled += 1
                else:
                    # å­˜æ´»è€…è·å¾—åŠ æˆï¼šæå‡æŠ½è±¡ç‰¹å¾
                    if sp.abstract_traits:
                        for trait in sp.abstract_traits:
                            sp.abstract_traits[trait] = min(10.0, sp.abstract_traits[trait] * 1.05)
                    survivors.append(sp.lineage_code)
                    species_repository.upsert(sp)
        result["details"] = f"æœ«æ—¥å®¡åˆ¤æ¸…é™¤äº† {culled} ä¸ªç‰©ç§ï¼Œ{len(survivors)} ä¸ªç‰©ç§è·å¾—ç¥æ©"
    
    elif miracle_id == "great_prosperity":
        # å¤§ç¹è£ï¼šæå‡æ‰€æœ‰ç‰©ç§çš„æŠ½è±¡ç‰¹å¾ï¼ˆ0-10èŒƒå›´ï¼‰
        all_species = species_repository.list_species()
        boosted = 0
        for sp in all_species:
            if sp.status == "alive":
                # æå‡æŠ½è±¡ç‰¹å¾ï¼ˆé€‚åº”æ€§ã€ç¹æ®–é€Ÿåº¦ç­‰ï¼Œ0-10èŒƒå›´ï¼‰
                if sp.abstract_traits:
                    for trait in sp.abstract_traits:
                        sp.abstract_traits[trait] = min(10.0, sp.abstract_traits[trait] * 1.1)
                # æ ‡è®°ä¸ºå—åˆ°å¤§ç¹è£ç¥ç¦
                if not sp.history_highlights:
                    sp.history_highlights = []
                sp.history_highlights.append(f"å›åˆ{current_turn}: è·å¾—å¤§ç¹è£ç¥ç¦ï¼Œé€‚åº”èƒ½åŠ›æå‡")
                species_repository.upsert(sp)
                boosted += 1
        result["details"] = f"å¤§ç¹è£é™ä¸´ï¼Œ{boosted} ä¸ªç‰©ç§è·å¾—ç¥ç¦ï¼Œé€‚åº”èƒ½åŠ›æå‡10%"
    
    elif miracle_id == "divine_sanctuary":
        # ç¥åœ£é¿éš¾æ‰€ï¼šä¿æŠ¤æ‰€æœ‰å­˜æ´»ç‰©ç§10å›åˆ
        all_species = species_repository.list_species()
        protected = 0
        for sp in all_species:
            if sp.status == "alive":
                sp.is_protected = True
                sp.protection_turns = max(sp.protection_turns or 0, 10)
                species_repository.upsert(sp)
                protected += 1
        result["details"] = f"ç¥åœ£é¿éš¾æ‰€åº‡æŠ¤äº† {protected} ä¸ªç‰©ç§ï¼ŒæŒç»­10å›åˆ"
    
    elif miracle_id == "genesis_flood":
        # åˆ›ä¸–æ´ªæ°´ï¼šæµ·å²¸ç‰©ç§å—å†²å‡»ï¼Œé™ä½æŠ½è±¡ç‰¹å¾
        all_species = species_repository.list_species()
        affected = 0
        for sp in all_species:
            if sp.status == "alive" and sp.habitat_type in ("coastal", "marine", "freshwater"):
                # æµ·æ´‹/æ°´ç”Ÿç‰©ç§å—å½±å“ï¼šé™ä½æŠ½è±¡ç‰¹å¾ï¼ˆé€‚åº”æ€§ç­‰ï¼‰
                if sp.abstract_traits:
                    for trait in sp.abstract_traits:
                        sp.abstract_traits[trait] = max(1.0, sp.abstract_traits[trait] * 0.9)
                # è®°å½•å†å²
                if not sp.history_highlights:
                    sp.history_highlights = []
                sp.history_highlights.append(f"å›åˆ{current_turn}: é­å—åˆ›ä¸–æ´ªæ°´å†²å‡»")
                affected += 1
                species_repository.upsert(sp)
        result["details"] = f"åˆ›ä¸–æ´ªæ°´é‡å¡‘æµ·å²¸ï¼Œ{affected} ä¸ªæ°´ç”Ÿç‰©ç§å—åˆ°å†²å‡»"
    
    elif miracle_id == "miracle_evolution":
        # å¥‡è¿¹è¿›åŒ–ï¼šAIç”Ÿæˆè¶…å¸¸è§„ç‰©ç§
        if not target:
            result["details"] = "å¥‡è¿¹è¿›åŒ–éœ€è¦æŒ‡å®šç›®æ ‡ç‰©ç§"
            result["error"] = True
        else:
            species = species_repository.get_by_lineage(target)
            if not species:
                result["details"] = f"ç›®æ ‡ç‰©ç§ {target} ä¸å­˜åœ¨"
                result["error"] = True
            else:
                try:
                    existing_species = species_repository.get_all()
                    used_codes = {s.lineage_code for s in existing_species}
                    suffix = 1
                    while f"{species.lineage_code}.M{suffix}" in used_codes:
                        suffix += 1
                    miracle_code = f"{species.lineage_code}.M{suffix}"
                    
                    miracle_species = species_generator.generate_advanced(
                        prompt=f"ä»ã€Œ{species.common_name}ã€äº§ç”Ÿçš„å¥‡è¿¹è¿›åŒ–ä½“ï¼Œæ‹¥æœ‰è¶…è¶Šå¸¸ç†çš„èƒ½åŠ›å’Œç‹¬ç‰¹å½¢æ€",
                        lineage_code=miracle_code,
                        existing_species=existing_species,
                        parent_code=species.lineage_code,
                    )
                    species_repository.upsert(miracle_species)
                    result["details"] = f"å¥‡è¿¹è¿›åŒ–è¯ç”Ÿäº†ã€Œ{miracle_species.common_name}ã€ï¼"
                    result["new_species"] = {
                        "lineage_code": miracle_species.lineage_code,
                        "common_name": miracle_species.common_name,
                    }
                except Exception as e:
                    logger.error(f"[å¥‡è¿¹è¿›åŒ–] å¤±è´¥: {e}")
                    result["details"] = f"å¥‡è¿¹è¿›åŒ–å¤±è´¥: {str(e)}"
                    result["error"] = True
    
    logger.info(f"[ç¥è¿¹] é‡Šæ”¾æˆåŠŸ: {miracle.name}, ç»“æœ: {result['details']}")
    
    return {
        "success": True,
        "miracle": miracle.name,
        "cost": miracle.cost,
        "result": result,
        "cooldown": miracle.cooldown,
        "energy_remaining": energy_service.get_state().current,
    }


# ========== é¢„è¨€èµŒæ³¨ç³»ç»Ÿ API ==========

@router.get("/divine/wagers", tags=["divine"])
def get_wagers() -> dict:
    """è·å–é¢„è¨€èµŒæ³¨ç³»ç»ŸçŠ¶æ€"""
    return divine_progression_service.get_wager_summary()


@router.post("/divine/wager/place", tags=["divine"])
def place_wager(request: dict) -> dict:
    """ä¸‹æ³¨é¢„è¨€
    
    Body:
    - wager_type: é¢„è¨€ç±»å‹ (dominance/extinction/expansion/evolution/duel)
    - target_species: ç›®æ ‡ç‰©ç§ä»£ç 
    - bet_amount: ä¸‹æ³¨é‡‘é¢
    - secondary_species: ç¬¬äºŒç‰©ç§ï¼ˆå¯¹å†³é¢„è¨€éœ€è¦ï¼‰
    - predicted_outcome: é¢„æµ‹ç»“æœï¼ˆå¯¹å†³é¢„è¨€éœ€è¦ï¼Œå¡«å†™é¢„æµ‹è·èƒœè€…ï¼‰
    """
    logger.info(f"[é¢„è¨€] æ”¶åˆ°ä¸‹æ³¨è¯·æ±‚: {request}")
    wager_type_str = request.get("wager_type", "")
    target_species = request.get("target_species", "")
    bet_amount = request.get("bet_amount", 0)
    secondary_species = request.get("secondary_species")
    predicted_outcome = request.get("predicted_outcome", "")
    
    try:
        wager_type = WagerType(wager_type_str)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„é¢„è¨€ç±»å‹: {wager_type_str}")
    
    # éªŒè¯ç‰©ç§å­˜åœ¨
    species = species_repository.get_by_lineage(target_species)
    if not species:
        raise HTTPException(status_code=404, detail=f"ç‰©ç§ {target_species} ä¸å­˜åœ¨")
    
    if species.status != "alive":
        raise HTTPException(status_code=400, detail=f"ç‰©ç§ {target_species} å·²ç­ç»")
    
    # å¯¹å†³é¢„è¨€éœ€è¦ç¬¬äºŒç‰©ç§
    if wager_type == WagerType.DUEL:
        if not secondary_species:
            raise HTTPException(status_code=400, detail="å¯¹å†³é¢„è¨€éœ€è¦æŒ‡å®šç¬¬äºŒç‰©ç§")
        sp2 = species_repository.get_by_lineage(secondary_species)
        if not sp2:
            raise HTTPException(status_code=404, detail=f"ç‰©ç§ {secondary_species} ä¸å­˜åœ¨")
        if sp2.status != "alive":
            raise HTTPException(status_code=400, detail=f"ç‰©ç§ {secondary_species} å·²ç­ç»")
    
    # æ£€æŸ¥èƒ½é‡
    if energy_service.get_state().current < bet_amount:
        raise HTTPException(
            status_code=400,
            detail=f"èƒ½é‡ä¸è¶³ï¼ä¸‹æ³¨ {bet_amount} èƒ½é‡ï¼Œå½“å‰åªæœ‰ {energy_service.get_state().current}"
        )
    
    # è®°å½•åˆå§‹çŠ¶æ€ï¼ˆä» morphology_stats è·å–ç§ç¾¤ï¼Œè®¡ç®—é€‚åº”åº¦ï¼‰
    morph = species.morphology_stats or {}
    traits = species.abstract_traits or {}
    calculated_fitness = (traits.get("é€‚åº”æ€§", 5) / 10.0 + sum(morph.values()) / max(1, len(morph))) / 2 if morph else 0.5
    
    initial_state = {
        "population": morph.get("population", 10000),
        "fitness": calculated_fitness,
        "regions": len(species.regions) if hasattr(species, 'regions') and species.regions else 1,
    }
    
    current_turn = simulation_engine.turn_counter
    
    success, message, wager_id = divine_progression_service.place_wager(
        wager_type=wager_type,
        target_species=target_species,
        bet_amount=bet_amount,
        current_turn=current_turn,
        secondary_species=secondary_species,
        predicted_outcome=predicted_outcome,
        initial_state=initial_state,
    )
    
    if not success:
        raise HTTPException(status_code=400, detail=message)
    
    # æ¶ˆè€—èƒ½é‡
    success2, msg2 = energy_service.spend_fixed(bet_amount, current_turn, details=f"é¢„è¨€ä¸‹æ³¨: {WAGER_TYPES[wager_type].name}")
    if not success2:
        raise HTTPException(status_code=400, detail=msg2)
    
    logger.info(f"[é¢„è¨€] ä¸‹æ³¨æˆåŠŸ: {bet_amount} èƒ½é‡, ç›®æ ‡: {target_species}")
    
    return {
        "success": True,
        "message": message,
        "wager_id": wager_id,
        "wager_type": WAGER_TYPES[wager_type].name,
        "potential_return": int(bet_amount * WAGER_TYPES[wager_type].multiplier),
        "energy_bet": bet_amount,
        "energy_remaining": energy_service.get_state().current,
    }


@router.post("/divine/wager/check", tags=["divine"])
def check_wager(request: dict) -> dict:
    """æ£€æŸ¥é¢„è¨€ç»“æœ
    
    Body:
    - wager_id: é¢„è¨€ID
    
    æ‰‹åŠ¨è§¦å‘é¢„è¨€ç»“ç®—ï¼ˆé€šå¸¸åœ¨å›åˆå¤„ç†æ—¶è‡ªåŠ¨æ£€æŸ¥ï¼‰ã€‚
    """
    wager_id = request.get("wager_id", "")
    
    state = divine_progression_service.get_state()
    if wager_id not in state.wager_state.active_wagers:
        raise HTTPException(status_code=404, detail=f"é¢„è¨€ {wager_id} ä¸å­˜åœ¨æˆ–å·²ç»“ç®—")
    
    wager = state.wager_state.active_wagers[wager_id]
    current_turn = simulation_engine.turn_counter
    
    # æ£€æŸ¥æ˜¯å¦åˆ°æœŸ
    if current_turn < wager.end_turn:
        remaining = wager.end_turn - current_turn
        return {
            "status": "in_progress",
            "message": f"é¢„è¨€è¿›è¡Œä¸­ï¼Œå‰©ä½™ {remaining} å›åˆ",
            "wager": wager.to_dict(),
        }
    
    # åˆ¤æ–­ç»“æœ
    species = species_repository.get_by_lineage(wager.target_species)
    success = False
    reason = ""
    
    wager_type = wager.wager_type
    
    if wager_type == WagerType.EXTINCTION:
        # ç­ç»é¢„è¨€
        success = species is None or species.status != "alive"
        reason = "ç‰©ç§å·²ç­ç»" if success else "ç‰©ç§ä»å­˜æ´»"
    
    elif wager_type == WagerType.DOMINANCE:
        # éœ¸ä¸»é¢„è¨€ - æ£€æŸ¥æ˜¯å¦æ˜¯åŒç”Ÿæ€ä½æœ€å¤§ç§ç¾¤
        if species and species.status == "alive":
            all_species = species_repository.list_species()
            same_niche = [sp for sp in all_species 
                         if sp.status == "alive" 
                         and sp.trophic_level == species.trophic_level]
            # ä» morphology_stats è·å–ç§ç¾¤
            def get_pop(sp):
                return (sp.morphology_stats or {}).get("population", 0)
            max_pop = max(get_pop(sp) for sp in same_niche) if same_niche else 0
            success = get_pop(species) >= max_pop
            reason = "å·²æˆä¸ºéœ¸ä¸»" if success else "æœªèƒ½æˆä¸ºéœ¸ä¸»"
        else:
            reason = "ç‰©ç§å·²ç­ç»"
    
    elif wager_type == WagerType.EXPANSION:
        # æ‰©å¼ é¢„è¨€
        if species and species.status == "alive":
            initial_regions = wager.initial_state.get("regions", 1)
            current_regions = len(species.regions) if species.regions else 1
            new_regions = current_regions - initial_regions
            success = new_regions >= 3
            reason = f"æ‰©å±•äº† {new_regions} ä¸ªåŒºåŸŸ" if success else f"åªæ‰©å±•äº† {new_regions} ä¸ªåŒºåŸŸ"
        else:
            reason = "ç‰©ç§å·²ç­ç»"
    
    elif wager_type == WagerType.EVOLUTION:
        # æ¼”åŒ–é¢„è¨€ - æ£€æŸ¥æ˜¯å¦æœ‰åä»£
        all_species = species_repository.list_species()
        descendants = [sp for sp in all_species 
                       if sp.parent_code == wager.target_species 
                       and sp.born_turn and sp.born_turn > wager.start_turn]
        success = len(descendants) > 0
        reason = f"äº§ç”Ÿäº† {len(descendants)} ä¸ªåä»£" if success else "æœªäº§ç”Ÿåä»£"
    
    elif wager_type == WagerType.DUEL:
        # å¯¹å†³é¢„è¨€
        sp1 = species
        sp2 = species_repository.get_by_lineage(wager.secondary_species) if wager.secondary_species else None
        
        sp1_alive = sp1 and sp1.status == "alive"
        sp2_alive = sp2 and sp2.status == "alive"
        
        def get_pop(sp):
            return (sp.morphology_stats or {}).get("population", 0) if sp else 0
        
        if sp1_alive and not sp2_alive:
            winner = wager.target_species
        elif sp2_alive and not sp1_alive:
            winner = wager.secondary_species
        elif sp1_alive and sp2_alive:
            # éƒ½å­˜æ´»ï¼Œæ¯”è¾ƒç§ç¾¤
            if get_pop(sp1) > get_pop(sp2):
                winner = wager.target_species
            else:
                winner = wager.secondary_species
        else:
            winner = None
        
        success = winner == wager.predicted_outcome
        reason = f"èƒœè€…: {winner}" if winner else "åŒæ–¹éƒ½ç­ç»"
    
    # ç»“ç®—
    reward = divine_progression_service.resolve_wager(wager_id, success)
    
    if reward > 0:
        energy_service.add_energy(reward, f"é¢„è¨€æˆåŠŸ: {WAGER_TYPES[wager_type].name}")
    
    return {
        "status": "resolved",
        "success": success,
        "reason": reason,
        "reward": reward,
        "current_energy": energy_service.get_state().current,
        "wager_summary": divine_progression_service.get_wager_summary(),
    }