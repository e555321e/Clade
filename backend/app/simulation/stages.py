"""
Simulation Stages - æµæ°´çº¿é˜¶æ®µå®šä¹‰

è¯¥æ¨¡å—å®šä¹‰äº†æ¨¡æ‹Ÿå›åˆä¸­çš„å„ä¸ªé˜¶æ®µã€‚æ¯ä¸ªé˜¶æ®µå®ç° Stage åè®®ï¼Œ
å¯ä»¥è¢«æµæ°´çº¿æ‰§è¡Œå™¨æŒ‰é¡ºåºè°ƒç”¨ã€‚

è®¾è®¡åŸåˆ™ï¼š
1. æ¯ä¸ªé˜¶æ®µåªè´Ÿè´£ä¸€ä¸ªç›¸å¯¹ç‹¬ç«‹çš„åŠŸèƒ½
2. é˜¶æ®µä¹‹é—´é€šè¿‡ SimulationContext äº¤æ¢æ•°æ®
3. é˜¶æ®µå¯ä»¥ä¾èµ– SimulationEngine ä¸­çš„æœåŠ¡å’Œä»“å‚¨
4. é˜¶æ®µæ‰§è¡Œå¯èƒ½æ˜¯åŒæ­¥æˆ–å¼‚æ­¥çš„
5. æ¯ä¸ªé˜¶æ®µå£°æ˜è‡ªå·±çš„ä¾èµ–å’Œè¾“å‡ºï¼Œä¾¿äºéªŒè¯æ‰§è¡Œé¡ºåº
"""

from __future__ import annotations

import asyncio
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import TYPE_CHECKING, Any, Callable, Protocol, runtime_checkable, Set, List

import numpy as np

if TYPE_CHECKING:
    from .context import SimulationContext
    from .engine import SimulationEngine

# å¯¼å…¥æœåŠ¡ï¼ˆç”¨äºæ›¿ä»£ engine æ–¹æ³•è°ƒç”¨ï¼‰
from ..services.species.trophic_interaction import get_trophic_service
from ..services.species.intervention import InterventionService
from ..services.species.extinction_checker import ExtinctionChecker
from ..services.species.reemergence import ReemergenceService
from ..services.analytics.turn_report import TurnReportService
from ..services.analytics.population_snapshot import PopulationSnapshotService
from ..tensor.speciation_monitor import SpeciationMonitor

logger = logging.getLogger(__name__)


# ============================================================================
# Stage ä¾èµ–å£°æ˜
# ============================================================================

@dataclass
class StageDependency:
    """é˜¶æ®µä¾èµ–å£°æ˜
    
    Attributes:
        requires_stages: å¿…é¡»å…ˆæ‰§è¡Œçš„é˜¶æ®µåç§°é›†åˆ
        requires_fields: å¿…é¡»å·²å¡«å……çš„ Context å­—æ®µé›†åˆ
        writes_fields: æœ¬é˜¶æ®µä¼šå†™å…¥çš„ Context å­—æ®µé›†åˆ
        optional_stages: å¯é€‰çš„å‰ç½®é˜¶æ®µï¼ˆå¦‚æœå­˜åœ¨åˆ™ä¾èµ–ï¼‰
    """
    requires_stages: Set[str] = field(default_factory=set)
    requires_fields: Set[str] = field(default_factory=set)
    writes_fields: Set[str] = field(default_factory=set)
    optional_stages: Set[str] = field(default_factory=set)
    
    def __post_init__(self):
        # è½¬æ¢ä¸º set ä»¥é˜²ä¼ å…¥ list
        self.requires_stages = set(self.requires_stages)
        self.requires_fields = set(self.requires_fields)
        self.writes_fields = set(self.writes_fields)
        self.optional_stages = set(self.optional_stages)


class DependencyError(Exception):
    """ä¾èµ–éªŒè¯é”™è¯¯"""
    pass


@dataclass
class DependencyValidationResult:
    """ä¾èµ–éªŒè¯ç»“æœ"""
    valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    dependency_graph: str = ""  # æ–‡æœ¬å½¢å¼çš„ä¾èµ–å›¾


class StageDependencyValidator:
    """é˜¶æ®µä¾èµ–éªŒè¯å™¨"""
    
    # å¼•å¯¼å­—æ®µï¼šSimulationContext åˆ›å»ºæ—¶å°±å·²ç»å­˜åœ¨çš„å­—æ®µ
    # è¿™äº›å­—æ®µä¸éœ€è¦ç”±ä»»ä½• Stage æä¾›
    BOOTSTRAP_FIELDS: Set[str] = {
        # å›åˆåŸºç¡€ä¿¡æ¯ï¼ˆæ„é€ æ—¶ä¼ å…¥ï¼‰
        "turn_index",
        "command",
        "event_callback",
        # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨/å­—å…¸/é»˜è®¤å€¼çš„å­—æ®µ
        "pressures",
        "modifiers",
        "major_events",
        "pressure_context",
        "map_changes",
        "temp_delta",
        "sea_delta",
        "all_species",
        "species_batch",
        "extinct_codes",
        "all_habitats",
        "all_tiles",
        "niche_metrics",
        "trophic_interactions",
        "preliminary_mortality",
        "critical_results",
        "focus_results",
        "background_results",
        "combined_results",
        "migration_events",
        "migration_count",
        "new_populations",
        "reproduction_results",
        "ai_status_evals",
        "activation_events",
        # æ’ä»¶æ•°æ®å…±äº«
        "plugin_data",
        "embedding_turn_data",
        "gene_flow_count",
        "drift_count",
        "auto_hybrids",
        "adaptation_events",
        "branching_events",
        "background_summary",
        "mass_extinction",
        "reemergence_events",
        "species_snapshots",
        "embedding_turn_data",
    }
    
    def __init__(self, stages: List["Stage"]):
        self.stages = stages
        self.stage_map = {s.name: s for s in stages}
        self.order_map = {s.name: s.order for s in stages}
    
    def validate(self) -> DependencyValidationResult:
        """éªŒè¯æ‰€æœ‰é˜¶æ®µçš„ä¾èµ–å…³ç³»"""
        errors = []
        warnings = []
        executed_stages: Set[str] = set()
        # ä»å¼•å¯¼å­—æ®µå¼€å§‹ï¼Œè¿™äº›å­—æ®µç”± SimulationContext åˆå§‹åŒ–æä¾›
        available_fields: Set[str] = set(self.BOOTSTRAP_FIELDS)
        
        # æŒ‰é¡ºåºæ£€æŸ¥æ¯ä¸ªé˜¶æ®µ
        for stage in sorted(self.stages, key=lambda s: s.order):
            dep = stage.get_dependency()
            
            # æ£€æŸ¥é˜¶æ®µä¾èµ–
            for req_stage in dep.requires_stages:
                if req_stage not in executed_stages:
                    if req_stage in self.stage_map:
                        errors.append(
                            f"âŒ [{stage.name}] ä¾èµ– [{req_stage}] ä½†å®ƒå°šæœªæ‰§è¡Œ "
                            f"(order: {stage.order} vs {self.order_map.get(req_stage, '?')})"
                        )
                    else:
                        errors.append(
                            f"âŒ [{stage.name}] ä¾èµ–æœªæ³¨å†Œçš„é˜¶æ®µ [{req_stage}]"
                        )
            
            # æ£€æŸ¥å¯é€‰ä¾èµ–ï¼ˆåªåœ¨å­˜åœ¨æ—¶æ£€æŸ¥é¡ºåºï¼‰
            for opt_stage in dep.optional_stages:
                if opt_stage in self.stage_map and opt_stage not in executed_stages:
                    if self.order_map.get(opt_stage, 0) > stage.order:
                        warnings.append(
                            f"âš ï¸ [{stage.name}] å¯é€‰ä¾èµ– [{opt_stage}] çš„é¡ºåºåœ¨å…¶ä¹‹å"
                        )
            
            # æ£€æŸ¥å­—æ®µä¾èµ–
            for req_field in dep.requires_fields:
                if req_field not in available_fields:
                    # æ£€æŸ¥æ˜¯å¦ç”±ä¹‹å‰çš„é˜¶æ®µæä¾›
                    provider = self._find_field_provider(req_field, executed_stages)
                    if provider:
                        available_fields.add(req_field)
                    else:
                        errors.append(
                            f"âŒ [{stage.name}] éœ€è¦å­—æ®µ [{req_field}] ä½†æ²¡æœ‰å‰ç½®é˜¶æ®µæä¾›å®ƒ"
                        )
            
            # è®°å½•æœ¬é˜¶æ®µçš„è¾“å‡º
            available_fields.update(dep.writes_fields)
            executed_stages.add(stage.name)
        
        # ç”Ÿæˆä¾èµ–å›¾
        dependency_graph = self._generate_dependency_graph()
        
        return DependencyValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            dependency_graph=dependency_graph,
        )
    
    def _find_field_provider(self, field_name: str, executed_stages: Set[str]) -> str | None:
        """æŸ¥æ‰¾æä¾›æŒ‡å®šå­—æ®µçš„é˜¶æ®µ"""
        for stage_name in executed_stages:
            stage = self.stage_map.get(stage_name)
            if stage:
                dep = stage.get_dependency()
                if field_name in dep.writes_fields:
                    return stage_name
        return None
    
    def _generate_dependency_graph(self) -> str:
        """ç”Ÿæˆæ–‡æœ¬å½¢å¼çš„ä¾èµ–å›¾"""
        lines = ["Stage ä¾èµ–å…³ç³»å›¾:", "=" * 50]
        
        for stage in sorted(self.stages, key=lambda s: s.order):
            dep = stage.get_dependency()
            lines.append(f"\n[{stage.order:3d}] {stage.name}")
            
            if dep.requires_stages:
                lines.append(f"      â† ä¾èµ–é˜¶æ®µ: {', '.join(sorted(dep.requires_stages))}")
            if dep.requires_fields:
                lines.append(f"      â† éœ€è¦å­—æ®µ: {', '.join(sorted(dep.requires_fields))}")
            if dep.writes_fields:
                lines.append(f"      â†’ è¾“å‡ºå­—æ®µ: {', '.join(sorted(dep.writes_fields))}")
        
        lines.append("\n" + "=" * 50)
        return "\n".join(lines)


class StageOrder(Enum):
    """é˜¶æ®µæ‰§è¡Œé¡ºåºæšä¸¾"""
    INIT = 0
    PARSE_PRESSURES = 10
    TENSOR_STATE_INIT = 49  # å¼ é‡çŠ¶æ€æ„å»º
    MAP_EVOLUTION = 20
    TECTONIC_MOVEMENT = 25
    FETCH_SPECIES = 30
    RESOURCE_CALC = 32  # èµ„æºè®¡ç®—ï¼ˆNPP/æ‰¿è½½åŠ›ï¼‰
    FOOD_WEB = 35
    TIERING_AND_NICHE = 40
    PRELIMINARY_MORTALITY = 50
    PREY_DISTRIBUTION = 55
    MIGRATION = 60
    DISPERSAL = 65
    HUNGER_MIGRATION = 66
    POST_MIGRATION_NICHE = 70
    FINAL_MORTALITY = 80
    SPECIATION_DATA_TRANSFER = 86
    POPULATION_UPDATE = 90
    GENE_DIVERSITY = 93
    GENE_ACTIVATION = 95
    GENE_FLOW = 100
    GENETIC_DRIFT = 105
    AUTO_HYBRIDIZATION = 110
    SUBSPECIES_PROMOTION = 115
    SPECIATION = 125
    BACKGROUND_MANAGEMENT = 130
    BUILD_REPORT = 140
    SAVE_MAP_SNAPSHOT = 150
    VEGETATION_COVER = 155
    SAVE_POPULATION_SNAPSHOT = 160
    EMBEDDING_INTEGRATION = 164  # Embedding é›†æˆé˜¶æ®µ
    EMBEDDING_HOOKS = 165        # å…¼å®¹åˆ«å
    EMBEDDING_PLUGINS = 166
    SAVE_HISTORY = 170
    EXPORT_DATA = 175
    FINALIZE = 180
    DATABASE_MAINTENANCE = 185  # æ•°æ®åº“è‡ªåŠ¨ç»´æŠ¤


@runtime_checkable
class Stage(Protocol):
    """é˜¶æ®µåè®® - æ‰€æœ‰é˜¶æ®µå¿…é¡»å®ç°æ­¤æ¥å£"""
    
    @property
    def name(self) -> str:
        """é˜¶æ®µåç§°ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰"""
        ...
    
    @property
    def order(self) -> int:
        """é˜¶æ®µé¡ºåºï¼ˆæ•°å€¼è¶Šå°è¶Šå…ˆæ‰§è¡Œï¼‰"""
        ...
    
    @property
    def is_async(self) -> bool:
        """æ˜¯å¦ä¸ºå¼‚æ­¥é˜¶æ®µ"""
        ...
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        """æ‰§è¡Œé˜¶æ®µé€»è¾‘
        
        Args:
            ctx: å›åˆä¸Šä¸‹æ–‡
            engine: æ¨¡æ‹Ÿå¼•æ“ï¼ˆç”¨äºè®¿é—®æœåŠ¡å’Œä»“å‚¨ï¼‰
        """
        ...


@dataclass
class StageResult:
    """é˜¶æ®µæ‰§è¡Œç»“æœ"""
    stage_name: str
    success: bool
    error: Exception | None = None
    duration_ms: float = 0.0


class BaseStage(ABC):
    """é˜¶æ®µåŸºç±»ï¼Œæä¾›é€šç”¨åŠŸèƒ½
    
    å­ç±»åº”è¯¥é‡å†™ `get_dependency()` æ–¹æ³•æ¥å£°æ˜ä¾èµ–å…³ç³»ã€‚
    """
    
    def __init__(self, order: int, name: str, is_async: bool = False):
        self._order = order
        self._name = name
        self._is_async = is_async
    
    @property
    def name(self) -> str:
        return self._name
    
    @property
    def order(self) -> int:
        return self._order
    
    @property
    def is_async(self) -> bool:
        return self._is_async
    
    def get_dependency(self) -> StageDependency:
        """è·å–æœ¬é˜¶æ®µçš„ä¾èµ–å£°æ˜
        
        å­ç±»åº”é‡å†™æ­¤æ–¹æ³•æ¥å£°æ˜ä¾èµ–å…³ç³»ã€‚
        """
        return StageDependency()
    
    @abstractmethod
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        """å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•"""
        pass


# ============================================================================
# å…·ä½“é˜¶æ®µå®ç°
# ============================================================================

class InitStage(BaseStage):
    """å›åˆåˆå§‹åŒ–é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.INIT.value, "å›åˆåˆå§‹åŒ–")
        self._plugin_manager = None
        self._plugin_init_attempted = False
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å‰ç½®ä¾èµ–
            requires_fields={"turn_index", "command"},  # éœ€è¦åŸºæœ¬ä¿¡æ¯
            writes_fields=set(),  # åªåšæ¸…ç†ï¼Œä¸å†™å…¥å­—æ®µ
        )
    
    def _get_plugin_manager(self, engine: 'SimulationEngine'):
        """å»¶è¿Ÿè·å–æ’ä»¶ç®¡ç†å™¨"""
        if self._plugin_init_attempted:
            return self._plugin_manager
        
        self._plugin_init_attempted = True
        
        embedding_service = getattr(engine, 'embedding_service', None)
        if not embedding_service:
            return None
        
        try:
            from ..services.embedding_plugins import (
                EmbeddingPluginManager,
                load_all_plugins
            )
            
            load_all_plugins()
            self._plugin_manager = EmbeddingPluginManager(embedding_service)
            self._plugin_manager.load_plugins()
            return self._plugin_manager
        except Exception as e:
            logger.debug(f"[InitStage] æ— æ³•åŠ è½½ embedding æ’ä»¶: {e}")
            return None
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        """æ¸…ç†å„æœåŠ¡ç¼“å­˜"""
        engine.speciation.clear_tile_cache()
        engine.migration_advisor.clear_tile_mortality_cache()
        engine.tile_mortality.clear_accumulated_data()
        
        # è§¦å‘æ’ä»¶ on_turn_start
        if engine._use_embedding_integration:
            manager = self._get_plugin_manager(engine)
            if manager:
                try:
                    manager.on_turn_start(ctx)
                    logger.debug(f"[InitStage] æ’ä»¶ on_turn_start å·²è§¦å‘")
                except Exception as e:
                    logger.warning(f"[InitStage] æ’ä»¶ on_turn_start å¤±è´¥: {e}")


class ParsePressuresStage(BaseStage):
    """è§£æç¯å¢ƒå‹åŠ›é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.PARSE_PRESSURES.value, "è§£æç¯å¢ƒå‹åŠ›")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages={"å›åˆåˆå§‹åŒ–"},
            requires_fields={"command", "turn_index"},
            writes_fields={"pressures", "modifiers", "major_events"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        logger.info("è§£æå‹åŠ›...")
        ctx.emit_event("stage", "ğŸŒ¡ï¸ è§£æç¯å¢ƒå‹åŠ›", "ç¯å¢ƒ")
        
        ctx.pressures = engine.environment.parse_pressures(ctx.command.pressures)
        ctx.modifiers = engine.environment.apply_pressures(ctx.pressures)
        ctx.major_events = engine.escalation_service.register(
            ctx.command.pressures, ctx.turn_index
        )


class MapEvolutionStage(BaseStage):
    """åœ°å›¾æ¼”åŒ–é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.MAP_EVOLUTION.value, "åœ°å›¾æ¼”åŒ–")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages={"è§£æç¯å¢ƒå‹åŠ›"},
            requires_fields={"modifiers", "major_events", "turn_index"},
            writes_fields={"current_map_state", "map_changes", "temp_delta", "sea_delta"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        logger.info("åœ°å›¾æ¼”åŒ–...")
        ctx.emit_event("stage", "ğŸ—ºï¸ åœ°å›¾æ¼”åŒ–ä¸æµ·å¹³é¢å˜åŒ–", "åœ°è´¨")
        
        ctx.current_map_state = environment_repository.get_state()
        if not ctx.current_map_state:
            logger.info("åˆå§‹åŒ–åœ°å›¾çŠ¶æ€...")
            ctx.emit_event("info", "åˆå§‹åŒ–åœ°å›¾çŠ¶æ€", "åœ°è´¨")
            ctx.current_map_state = environment_repository.save_state(
                {"stage_name": "ç¨³å®šæœŸ", "stage_progress": 0, "stage_duration": 0}
            )
        
        ctx.map_changes = engine.map_evolution.advance(
            ctx.major_events, ctx.turn_index, ctx.modifiers, ctx.current_map_state
        ) or []
        
        # è®¡ç®—æ¸©åº¦å’Œæµ·å¹³é¢å˜åŒ–
        if ctx.modifiers:
            temp_change, sea_level_change = engine.map_evolution.calculate_climate_changes(
                ctx.modifiers, ctx.current_map_state
            )
            ctx.temp_delta = temp_change
            ctx.sea_delta = sea_level_change
            
            if abs(temp_change) > 0.01 or abs(sea_level_change) > 0.01:
                new_temp = ctx.current_map_state.global_avg_temperature + temp_change
                new_sea_level = ctx.current_map_state.sea_level + sea_level_change
                
                logger.info(f"æ¸©åº¦: {ctx.current_map_state.global_avg_temperature:.1f}Â°C â†’ {new_temp:.1f}Â°C")
                logger.info(f"æµ·å¹³é¢: {ctx.current_map_state.sea_level:.1f}m â†’ {new_sea_level:.1f}m")
                
                ctx.current_map_state.global_avg_temperature = new_temp
                ctx.current_map_state.sea_level = new_sea_level
                # æ³¨æ„ï¼šturn_index ä¼šåœ¨ FinalizeStage ä¸­ç»Ÿä¸€æ›´æ–°ä¸ºä¸‹ä¸€ä¸ªå›åˆæ•°
                # è¿™é‡Œæš‚æ—¶ä¿å­˜å½“å‰å›åˆæ•°ï¼Œä»…ç”¨äºä¸­é—´çŠ¶æ€
                ctx.current_map_state.turn_index = ctx.turn_index
                environment_repository.save_state(ctx.current_map_state)
                
                if abs(sea_level_change) > 0.5:
                    engine.map_manager.reclassify_terrain_by_sea_level(new_sea_level)
        
        if not engine._use_tectonic_system:
            logger.info("[åœ°å½¢æ¼”åŒ–] æ¿å—ç³»ç»Ÿæœªå¯ç”¨ï¼Œä»…ä½¿ç”¨ MapEvolution ç»“æœ")
            ctx.emit_event("info", "â­ï¸ æ¿å—ç³»ç»Ÿæœªå¯ç”¨ï¼Œé‡‡ç”¨ MapEvolution ç»“æœ", "åœ°è´¨")


class TectonicMovementStage(BaseStage):
    """æ¿å—æ„é€ è¿åŠ¨é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.TECTONIC_MOVEMENT.value, "æ¿å—æ„é€ è¿åŠ¨")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages={"åœ°å›¾æ¼”åŒ–"},
            requires_fields={"modifiers", "current_map_state"},
            writes_fields={"tectonic_result"},
            optional_stages=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        if not engine._use_tectonic_system or not engine.tectonic:
            return
        
        from ..repositories.environment_repository import environment_repository
        from ..repositories.species_repository import species_repository
        from ..services.species.habitat_manager import habitat_manager
        from ..services.species.dispersal_engine import dispersal_engine
        
        try:
            ctx.emit_event("stage", "ğŸŒ æ¿å—æ„é€ è¿åŠ¨", "åœ°è´¨")
            
            # è·å–ç‰©ç§å’Œæ –æ¯åœ°æ•°æ®
            all_species_for_tectonic = species_repository.list_species()
            alive_species = [sp for sp in all_species_for_tectonic if sp.status == "alive"]
            
            # è·å–æ –æ¯åœ°æ•°æ®
            habitat_data = []
            for sp in alive_species:
                for h in getattr(sp, "habitats", []):
                    habitat_data.append({
                        "tile_id": getattr(h, "tile_id", 0),
                        "species_id": sp.id,
                        "population": getattr(h, "population", 0),
                    })
            
            map_tiles = environment_repository.list_tiles()
            
            ctx.tectonic_result = engine.tectonic.step(
                species_list=alive_species,
                habitat_data=habitat_data,
                map_tiles=map_tiles,
                pressure_modifiers=ctx.modifiers,
            )
            
            wilson = ctx.tectonic_result.wilson_phase
            logger.info(f"[æ¿å—ç³»ç»Ÿ] å¨å°”é€Šå‘¨æœŸ: {wilson['phase']} ({wilson['progress']:.0%})")
            
            for summary in ctx.tectonic_result.get_major_events_summary():
                ctx.emit_event("info", f"ğŸŒ‹ {summary}", "åœ°è´¨")
            
            # åº”ç”¨åœ°å½¢å˜åŒ–
            if ctx.tectonic_result.terrain_changes and map_tiles:
                coord_map = {(t.x, t.y): t for t in map_tiles}
                updated_tiles = []
                
                for change in ctx.tectonic_result.terrain_changes:
                    tile = coord_map.get((change["x"], change["y"]))
                    if tile:
                        tile.elevation = change["new_elevation"]
                        if hasattr(tile, "temperature") and "new_temperature" in change:
                            tile.temperature = change["new_temperature"]
                        updated_tiles.append(tile)
                
                if updated_tiles:
                    environment_repository.upsert_tiles(updated_tiles)
                    avg_change = sum(abs(c["delta"]) for c in ctx.tectonic_result.terrain_changes) / len(ctx.tectonic_result.terrain_changes)
                    logger.info(f"[æ¿å—ç³»ç»Ÿ] åº”ç”¨äº† {len(updated_tiles)} å¤„åœ°å½¢å˜åŒ– (å¹³å‡ {avg_change:.2f}m)")
                    
                    engine.map_manager.reclassify_terrain_by_sea_level(ctx.current_map_state.sea_level)
                    logger.info("[æ¿å—ç³»ç»Ÿ] æ°´ä½“é‡æ–°åˆ†ç±»å®Œæˆï¼ˆæ¹–æ³Šæ£€æµ‹ï¼‰")
                    
                    relocation_result = habitat_manager.handle_terrain_type_changes(
                        alive_species, updated_tiles, ctx.turn_index,
                        dispersal_engine=dispersal_engine
                    )
                    if relocation_result["forced_relocations"] > 0:
                        ctx.emit_event(
                            "migration",
                            f"ğŸŒŠ æµ·é™†å˜åŒ–å¯¼è‡´ {relocation_result['forced_relocations']} æ¬¡ç‰©ç§è¿å¾™",
                            "ç”Ÿæ€"
                        )
                    if relocation_result.get("hunger_migrations", 0) > 0:
                        ctx.emit_event(
                            "migration",
                            f"ğŸ– {relocation_result['hunger_migrations']} ä¸ªæ¶ˆè´¹è€…è¿½è¸ªçŒç‰©è¿å¾™",
                            "ç”Ÿæ€"
                        )
            
            # åˆå¹¶å‹åŠ›åé¦ˆ
            for key, value in ctx.tectonic_result.pressure_feedback.items():
                ctx.modifiers[key] = ctx.modifiers.get(key, 0) + value
            
            # ã€æ–°å¢ã€‘è§¦å‘èµ„æºç³»ç»Ÿäº‹ä»¶è„‰å†²
            self._apply_resource_event_pulses(ctx, ctx.tectonic_result, map_tiles, engine)
        
        except Exception as e:
            logger.warning(f"[æ¿å—ç³»ç»Ÿ] è¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _apply_resource_event_pulses(
        self,
        ctx: "SimulationContext",
        tectonic_result,
        map_tiles: list,
        engine: "SimulationEngine" = None,
    ):
        """å°†æ¿å—/åœ°è´¨äº‹ä»¶è½¬æ¢ä¸ºèµ„æºè„‰å†²"""
        try:
            # ä½¿ç”¨ engine æ³¨å…¥çš„ resource_managerï¼Œé¿å…å…¨å±€å•ä¾‹
            resource_mgr = engine.resource_manager if engine else None
            if resource_mgr is None:
                logger.warning("[åœ°è´¨é˜¶æ®µ] èµ„æºç®¡ç†å™¨æœªæ³¨å…¥ï¼Œè·³è¿‡èµ„æºè„‰å†²")
                return
            
            # åˆå§‹åŒ–åœ°å—èµ„æºçŠ¶æ€ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
            if map_tiles:
                resource_mgr.initialize_tiles(map_tiles)
            
            # å¤„ç†ç«å±±äº‹ä»¶
            if hasattr(tectonic_result, 'volcanic_events'):
                for event in tectonic_result.volcanic_events:
                    affected_tiles = event.get('affected_tiles', [])
                    for tile_id in affected_tiles:
                        resource_mgr.apply_event_pulse(tile_id, "volcanic_ash", duration_turns=5)
                    
                    if affected_tiles:
                        ctx.emit_event(
                            "info",
                            f"ğŸŒ‹ ç«å±±ç°å½±å“ {len(affected_tiles)} ä¸ªåœ°å—çš„èµ„æº",
                            "ç”Ÿæ€"
                        )
            
            # å¤„ç†æ´ªæ°´äº‹ä»¶ï¼ˆä» modifiers æ£€æµ‹ï¼‰
            flood_intensity = ctx.modifiers.get("flood", 0)
            if flood_intensity > 0.3:
                # å½±å“ä½æµ·æ‹”åœ°å—
                for tile in map_tiles or []:
                    if hasattr(tile, 'elevation') and tile.elevation < 50:
                        resource_mgr.apply_event_pulse(tile.id, "flood", duration_turns=3)
            
            # å¤„ç†å¹²æ—±äº‹ä»¶
            drought_intensity = ctx.modifiers.get("drought", 0)
            if drought_intensity > 0.3:
                # å½±å“å¹²æ—±æ•æ„Ÿåœ°å—
                for tile in map_tiles or []:
                    if hasattr(tile, 'humidity') and tile.humidity < 0.3:
                        resource_mgr.apply_event_pulse(tile.id, "drought", duration_turns=4)
            
            # æ›´æ–°èµ„æºåŠ¨æ€ï¼ˆè®¡ç®—æ¶ˆè€—ï¼‰
            # æ¶ˆè€—æ•°æ®å°†åœ¨åç»­é˜¶æ®µè®¡ç®—åæ›´æ–°
            
        except Exception as e:
            logger.warning(f"[èµ„æºäº‹ä»¶è„‰å†²] å¤„ç†å¤±è´¥: {e}")


class FetchSpeciesStage(BaseStage):
    """è·å–ç‰©ç§åˆ—è¡¨é˜¶æ®µ
    
    ã€æ€§èƒ½ä¼˜åŒ– v2ã€‘
    1. åˆ†æ®µè®¡æ—¶æ—¥å¿—ï¼Œä¾¿äºå®šä½ç“¶é¢ˆ
    2. ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œå‡å°‘ DB æŸ¥è¯¢
    3. æé«˜æ°”å€™è°ƒæ•´é˜ˆå€¼ï¼Œå‡å°‘è§¦å‘é¢‘ç‡
    """
    
    def __init__(self):
        super().__init__(StageOrder.FETCH_SPECIES.value, "è·å–ç‰©ç§åˆ—è¡¨")
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        import time
        from ..repositories.species_repository import species_repository
        from ..services.species.habitat_manager import habitat_manager
        from ..services.system.species_cache import get_species_cache
        
        stage_start = time.perf_counter()
        timings: dict[str, float] = {}
        
        logger.info("è·å–ç‰©ç§åˆ—è¡¨...")
        ctx.emit_event("stage", "ğŸ§¬ è·å–ç‰©ç§åˆ—è¡¨", "ç‰©ç§")
        
        # ã€å…³é”®ä¿®å¤ã€‘å§‹ç»ˆä»æ•°æ®åº“åŠ è½½æœ€æ–°ç‰©ç§åˆ—è¡¨
        # åŸå› ï¼šåˆ†åŒ–å‘ç”Ÿåœ¨å›åˆæœ«å°¾ï¼ˆSpeciationStageï¼‰ï¼Œæ–°ç‰©ç§ä¿å­˜åˆ°æ•°æ®åº“å
        # ä¸‹ä¸€å›åˆå¼€å§‹æ—¶å¿…é¡»ä»æ•°æ®åº“é‡æ–°åŠ è½½ï¼Œå¦åˆ™ species_batch ä¸åŒ…å«æ–°ç‰©ç§
        t0 = time.perf_counter()
        species_cache = get_species_cache()
        ctx.all_species = species_repository.list_species()
        species_cache.update(ctx.all_species, ctx.turn_index)
        timings["db_fetch"] = time.perf_counter() - t0
        
        ctx.species_batch = [sp for sp in ctx.all_species if sp.status == "alive"]
        ctx.extinct_codes = {sp.lineage_code for sp in ctx.all_species if sp.status == "extinct"}
        
        logger.info(f"å½“å‰ç‰©ç§æ•°é‡: {len(ctx.species_batch)} (æ€»å…±{len(ctx.all_species)}ä¸ªï¼Œå…¶ä¸­{len(ctx.extinct_codes)}ä¸ªå·²ç­ç»)")
        ctx.emit_event("info", f"å½“å‰å­˜æ´»ç‰©ç§: {len(ctx.species_batch)} ä¸ª", "ç‰©ç§")
        
        # Embedding é›†æˆ
        if engine._use_embedding_integration and ctx.species_batch:
            t0 = time.perf_counter()
            try:
                engine.embedding_integration.on_turn_start(ctx.turn_index, ctx.species_batch)
                engine.embedding_integration.on_pressure_applied(
                    ctx.turn_index, ctx.command.pressures, ctx.modifiers
                )
            except Exception as e:
                logger.warning(f"[Embeddingé›†æˆ] å›åˆå¼€å§‹é’©å­å¤±è´¥: {e}")
            timings["embedding_integration"] = time.perf_counter() - t0
        
        # æ°”å€™è°ƒæ•´ã€ä¼˜åŒ–ã€‘æé«˜é˜ˆå€¼ï¼Œå‡å°‘è§¦å‘é¢‘ç‡
        # åŸé˜ˆå€¼ï¼šæ¸©åº¦ 0.1, æµ·å¹³é¢ 0.5 -> æ–°é˜ˆå€¼ï¼šæ¸©åº¦ 0.5, æµ·å¹³é¢ 2.0
        if ctx.species_batch and (abs(ctx.temp_delta) > 0.5 or abs(ctx.sea_delta) > 2.0):
            t0 = time.perf_counter()
            habitat_manager.adjust_habitats_for_climate(
                ctx.species_batch,
                ctx.temp_delta,
                ctx.sea_delta,
                ctx.turn_index,
            )
            timings["habitat_adjust"] = time.perf_counter() - t0
        
        # æ›´æ–°å¹²é¢„çŠ¶æ€ï¼ˆä½¿ç”¨ InterventionServiceï¼‰
        t0 = time.perf_counter()
        from ..repositories.species_repository import species_repository
        intervention_service = InterventionService(
            species_repository=species_repository,
            event_callback=ctx.emit_event,
        )
        intervention_service.update_intervention_status(ctx.species_batch)
        timings["intervention"] = time.perf_counter() - t0
        
        # è¾“å‡ºæ€§èƒ½æ—¥å¿—
        total_time = time.perf_counter() - stage_start
        timing_str = ", ".join(f"{k}={v*1000:.0f}ms" for k, v in timings.items())
        logger.info(f"[FetchSpeciesStage] æ€»è€—æ—¶ {total_time*1000:.0f}ms ({timing_str})")


class ResourceCalcStage(BaseStage):
    """èµ„æºè®¡ç®—é˜¶æ®µ
    
    ä½¿ç”¨ ResourceManager è®¡ç®—å„åœ°å—çš„ NPP å’Œæ‰¿è½½åŠ›ï¼Œ
    ç”Ÿæˆ resource_snapshot ä¾›åç»­é˜¶æ®µï¼ˆæ­»äº¡ç‡ã€ç¹æ®–ã€è¿å¾™ï¼‰ä½¿ç”¨ã€‚
    """
    
    def __init__(self):
        super().__init__(StageOrder.RESOURCE_CALC.value, "èµ„æºè®¡ç®—")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages={"è·å–ç‰©ç§åˆ—è¡¨"},  # éœ€è¦ç‰©ç§åˆ—è¡¨å’Œåœ°å—ä¿¡æ¯
            requires_fields={"species_batch", "all_tiles", "turn_index"},
            writes_fields={"resource_snapshot"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        """æ‰§è¡Œèµ„æºè®¡ç®—
        
        1. ä»å¼•æ“è·å– ResourceManagerï¼ˆé€šè¿‡å®¹å™¨æ³¨å…¥ï¼‰
        2. è®¡ç®—å„åœ°å—çš„æ¶ˆè€—é‡ï¼ˆåŸºäºç‰©ç§åˆ†å¸ƒï¼‰
        3. æ›´æ–°èµ„æºåŠ¨æ€
        4. ç”Ÿæˆèµ„æºå¿«ç…§ä¾›åç»­é˜¶æ®µä½¿ç”¨
        """
        logger.info("è®¡ç®—èµ„æºåˆ†å¸ƒ...")
        ctx.emit_event("stage", "ğŸŒ¿ è®¡ç®—èµ„æºåˆ†å¸ƒ", "ç”Ÿæ€")
        
        try:
            # ä»å¼•æ“è·å– ResourceManagerï¼ˆä¸å†ä½¿ç”¨å…¨å±€å®¹å™¨ï¼‰
            resource_manager = engine.resource_manager
            if resource_manager is None:
                logger.warning("ResourceManager ä¸å¯ç”¨ï¼Œè·³è¿‡èµ„æºé˜¶æ®µ")
                return
            
            # ã€æ–°å¢v12ã€‘æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®ï¼ˆç”¨äºåŠ¨æ€åŒåŒ–æ•ˆç‡ï¼‰
            eco_realism_data = ctx.plugin_data.get("ecological_realism", {})
            if eco_realism_data:
                resource_manager._ecological_realism_data = eco_realism_data
                logger.debug("[èµ„æºè®¡ç®—] å·²æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®ï¼ˆåŠ¨æ€åŒåŒ–æ•ˆç‡ï¼‰")
            
            # è®¡ç®—å„åœ°å—çš„ç‰©ç§æ¶ˆè€—
            consumption_by_tile = self._calculate_consumption(ctx)
            
            # æ›´æ–°èµ„æºåŠ¨æ€
            if ctx.all_tiles:
                resource_manager.update_resource_dynamics(
                    ctx.all_tiles,
                    consumption_by_tile,
                    ctx.turn_index,
                )
            
            # ç”Ÿæˆå¹¶å­˜å‚¨èµ„æºå¿«ç…§
            ctx.resource_snapshot = resource_manager.get_snapshot(ctx.turn_index)
            
            # è¾“å‡ºæ±‡æ€»ä¿¡æ¯
            if ctx.resource_snapshot:
                overgrazing = ctx.resource_snapshot.overgrazing_tiles
                total_npp = ctx.resource_snapshot.total_npp
                ctx.emit_event(
                    "info",
                    f"ğŸŒ± æ€»NPP: {total_npp:.0f} kg | è¿‡é‡‡åœ°å—: {overgrazing}",
                    "ç”Ÿæ€"
                )
                logger.info(
                    f"èµ„æºè®¡ç®—å®Œæˆ: total_npp={total_npp:.0f}, "
                    f"avg_npp={ctx.resource_snapshot.avg_npp:.2f}, "
                    f"overgrazing_tiles={overgrazing}"
                )
        except Exception as e:
            logger.warning(f"èµ„æºè®¡ç®—é˜¶æ®µå‡ºé”™: {e}")
            ctx.emit_event("warning", f"èµ„æºè®¡ç®—å‡ºé”™: {e}", "ç”Ÿæ€")
    
    def _calculate_consumption(self, ctx: SimulationContext) -> dict[int, float]:
        """è®¡ç®—å„åœ°å—çš„èµ„æºæ¶ˆè€—é‡
        
        åŸºäºç‰©ç§åˆ†å¸ƒå’Œä»£è°¢éœ€æ±‚ä¼°ç®—æ¶ˆè€—ã€‚
        """
        consumption: dict[int, float] = {}
        
        # éå†å­˜æ´»ç‰©ç§
        for species in ctx.species_batch:
            if species.status != "alive":
                continue
            
            # è·å–ä½“é‡ï¼ˆç”¨äºä»£è°¢è®¡ç®—ï¼‰
            body_weight = getattr(species, 'body_weight_kg', 1.0)
            if body_weight is None:
                body_weight = 1.0
            
            # è·å–æ –æ¯åœ°åˆ†å¸ƒ
            habitats = getattr(species, 'habitats', []) or []
            
            if not habitats:
                continue
            
            # ä¼°ç®—ä»£è°¢éœ€æ±‚ï¼ˆå¼‚é€Ÿç”Ÿé•¿ï¼šéœ€æ±‚ âˆ ä½“é‡^0.75ï¼‰
            individual_demand = 0.01 * (body_weight ** 0.75)  # ç®€åŒ–çš„ä»£è°¢æ¨¡å‹
            
            # æŒ‰æ –æ¯åœ°åˆ†é…æ¶ˆè€—ï¼ˆä» morphology_stats è·å–ï¼‰
            population = species.morphology_stats.get("population", 0)
            tiles_count = len(habitats)
            pop_per_tile = population / tiles_count if tiles_count > 0 else 0
            
            for hab in habitats:
                tile_id = getattr(hab, 'tile_id', None)
                if tile_id is not None:
                    tile_consumption = individual_demand * pop_per_tile
                    consumption[tile_id] = consumption.get(tile_id, 0.0) + tile_consumption
        
        return consumption


class FoodWebStage(BaseStage):
    """é£Ÿç‰©ç½‘ç»´æŠ¤é˜¶æ®µ
    
    ã€v2å¢å¼ºã€‘
    1. çŒç‰©å¤šæ ·æ€§é˜ˆå€¼æ£€æŸ¥å’Œè‡ªåŠ¨è¡¥å……
    2. æ–°ç‰©ç§ï¼ˆT1/T2ï¼‰è‡ªåŠ¨é›†æˆ
    3. åŒºåŸŸæƒé‡æ„ŸçŸ¥ï¼ˆé¥¥é¥¿åŒºåŸŸã€å­¤ç«‹åŒºåŸŸï¼‰
    4. ç”Ÿæˆ trophic_interactions åé¦ˆä¿¡å·
    """
    
    def __init__(self):
        super().__init__(StageOrder.FOOD_WEB.value, "é£Ÿç‰©ç½‘ç»´æŠ¤")
        self._previous_species_codes: set[str] | None = None
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.info("ç»´æŠ¤é£Ÿç‰©ç½‘...")
        ctx.emit_event("stage", "ğŸ•¸ï¸ ç»´æŠ¤é£Ÿç‰©ç½‘", "ç”Ÿæ€")
        
        try:
            # æ„å»ºåœ°å—-ç‰©ç§æ˜ å°„ï¼ˆç”¨äºåŒºåŸŸæƒé‡ï¼‰
            tile_species_map, species_tiles = self._build_tile_species_map(ctx.all_species)
            
            # è·å–ä¸Šå›åˆçš„ç‰©ç§ä»£ç ï¼ˆç”¨äºæ£€æµ‹æ–°ç‰©ç§ï¼‰
            current_codes = {s.lineage_code for s in ctx.all_species if s.status == "alive"}
            previous_codes = self._previous_species_codes
            self._previous_species_codes = current_codes.copy()
            
            # æ‰§è¡Œé£Ÿç‰©ç½‘ç»´æŠ¤ï¼ˆv2å¢å¼ºç‰ˆï¼‰
            ctx.food_web_analysis = engine.food_web_manager.maintain_food_web(
                ctx.all_species, species_repository, ctx.turn_index,
                tile_species_map=tile_species_map,
                species_tiles=species_tiles,
                previous_species_codes=previous_codes,
            )
            food_web_changes = engine.food_web_manager.get_changes()
            
            if food_web_changes:
                ctx.emit_event(
                    "info",
                    f"ğŸ½ï¸ æ›´æ–°äº† {len(food_web_changes)} ä¸ªç‰©ç§çš„é£Ÿç‰©å…³ç³»",
                    "ç”Ÿæ€"
                )
                ctx.all_species = species_repository.list_species()
                ctx.species_batch = [sp for sp in ctx.all_species if sp.status == "alive"]
            
            # ã€æ–°å¢ã€‘ç”Ÿæˆ trophic_interactions åé¦ˆä¿¡å·
            trophic_signals = engine.food_web_manager.generate_trophic_signals(
                ctx.food_web_analysis, ctx.all_species
            )
            
            # åˆå¹¶åˆ° trophic_interactionsï¼ˆä¾›åç»­é˜¶æ®µä½¿ç”¨ï¼‰
            if not hasattr(ctx, 'trophic_interactions') or ctx.trophic_interactions is None:
                ctx.trophic_interactions = {}
            ctx.trophic_interactions.update(trophic_signals)
            
            # æŠ¥å‘Šæ–°ç”Ÿäº§è€…
            if ctx.food_web_analysis.new_producers:
                ctx.emit_event(
                    "info",
                    f"ğŸŒ± å‘ç° {len(ctx.food_web_analysis.new_producers)} ä¸ªæ–° T1/T2 ç‰©ç§",
                    "ç”Ÿæ€"
                )
            
            # æŠ¥å‘ŠçŒç‰©ä¸è¶³çš„ç‰©ç§
            if ctx.food_web_analysis.prey_shortage_species:
                ctx.emit_event(
                    "warning",
                    f"âš ï¸ {len(ctx.food_web_analysis.prey_shortage_species)} ä¸ªç‰©ç§çŒç‰©å¤šæ ·æ€§ä¸è¶³",
                    "ç”Ÿæ€"
                )
            
            if ctx.food_web_analysis.bottleneck_warnings:
                for warning in ctx.food_web_analysis.bottleneck_warnings[:3]:
                    ctx.emit_event("warning", warning, "ç”Ÿæ€")
            
            logger.info(
                f"[é£Ÿç‰©ç½‘] å¥åº·åº¦: {ctx.food_web_analysis.health_score:.0%}, "
                f"é“¾æ¥æ•°: {ctx.food_web_analysis.total_links}, "
                f"å­¤ç«‹æ¶ˆè´¹è€…: {len(ctx.food_web_analysis.orphaned_consumers)}, "
                f"trophic_signals: {len(trophic_signals)}"
            )
        except Exception as e:
            logger.warning(f"[é£Ÿç‰©ç½‘ç»´æŠ¤] å¤±è´¥: {e}")
    
    def _build_tile_species_map(
        self, 
        all_species: list
    ) -> tuple[dict[int, set[str]], dict[str, set[int]]]:
        """æ„å»ºåœ°å—-ç‰©ç§åŒå‘æ˜ å°„"""
        tile_species_map: dict[int, set[str]] = {}
        species_tiles: dict[str, set[int]] = {}
        
        for sp in all_species:
            if sp.status != "alive":
                continue
            tiles = set(sp.morphology_stats.get("tile_ids", []))
            if tiles:
                species_tiles[sp.lineage_code] = tiles
                for tid in tiles:
                    if tid not in tile_species_map:
                        tile_species_map[tid] = set()
                    tile_species_map[tid].add(sp.lineage_code)
        
        return tile_species_map, species_tiles


class TieringAndNicheStage(BaseStage):
    """ç‰©ç§åˆ†å±‚ä¸ç”Ÿæ€ä½åˆ†æé˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.TIERING_AND_NICHE.value, "ç‰©ç§åˆ†å±‚ä¸ç”Ÿæ€ä½")
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        logger.info("ç‰©ç§åˆ†å±‚...")
        ctx.emit_event("stage", "ğŸ“Š ç‰©ç§åˆ†å±‚ä¸ç”Ÿæ€ä½åˆ†æ", "ç”Ÿæ€")
        
        ctx.tiered = engine.tiering.classify(ctx.species_batch, engine.watchlist)
        logger.info(f"Critical: {len(ctx.tiered.critical)}, Focus: {len(ctx.tiered.focus)}, Background: {len(ctx.tiered.background)}")
        ctx.emit_event("info", f"Critical: {len(ctx.tiered.critical)}, Focus: {len(ctx.tiered.focus)}, Background: {len(ctx.tiered.background)}", "ç”Ÿæ€")
        
        logger.info("ç”Ÿæ€ä½åˆ†æï¼ˆè¿å¾™å‰ï¼‰...")
        ctx.all_habitats = environment_repository.latest_habitats()
        ctx.all_tiles = environment_repository.list_tiles()
        ctx.niche_metrics = engine.niche_analyzer.analyze(ctx.species_batch, habitat_data=ctx.all_habitats)


class PreliminaryMortalityStage(BaseStage):
    """åˆæ­¥æ­»äº¡ç‡è¯„ä¼°é˜¶æ®µï¼ˆè¿å¾™å‰ï¼‰"""
    
    def __init__(self):
        super().__init__(StageOrder.PRELIMINARY_MORTALITY.value, "åˆæ­¥æ­»äº¡ç‡è¯„ä¼°")
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        logger.info("ã€é˜¶æ®µ1ã€‘è®¡ç®—è¥å…»çº§äº’åŠ¨...")
        ctx.emit_event("stage", "âš”ï¸ ã€é˜¶æ®µ1ã€‘è®¡ç®—è¥å…»çº§äº’åŠ¨ä¸æ­»äº¡ç‡", "ç”Ÿæ€")
        
        # ä½¿ç”¨ TrophicInteractionService è®¡ç®—è¥å…»çº§äº’åŠ¨
        trophic_service = get_trophic_service()
        ctx.trophic_interactions = trophic_service.calculate(ctx.species_batch)
        
        # ã€æ–°å¢ã€‘æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®åˆ° trophic_interactions
        # è¿™æ ·æ­»äº¡ç‡è®¡ç®—å¯ä»¥è®¿é—®è¯­ä¹‰é©±åŠ¨çš„ç”Ÿæ€å­¦ä¿®æ­£
        eco_realism_data = ctx.plugin_data.get("ecological_realism", {})
        if eco_realism_data:
            ctx.trophic_interactions["_ecological_realism_data"] = eco_realism_data
            logger.debug("[æ­»äº¡ç‡] å·²æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®")
        
        logger.info("ã€é˜¶æ®µ1ã€‘è®¡ç®—åˆæ­¥æ­»äº¡ç‡ï¼ˆè¿å¾™å‰ï¼‰...")
        
        if engine._use_tile_based_mortality and ctx.all_tiles:
            logger.info("[åœ°å—æ­»äº¡ç‡] æ„å»ºåœ°å—-ç‰©ç§çŸ©é˜µ...")
            ctx.emit_event("info", "ğŸ—ºï¸ ä½¿ç”¨æŒ‰åœ°å—è®¡ç®—æ­»äº¡ç‡", "ç”Ÿæ€")
            
            # ã€æ–°å¢v12ã€‘æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®åˆ°æ­»äº¡ç‡å¼•æ“
            # ç”¨äºç©ºé—´æ•é£Ÿæ•ˆç‡ã€å‚ç›´ç”Ÿæ€ä½ç«äº‰ç­‰ä¿®æ­£
            engine.tile_mortality._ecological_realism_data = eco_realism_data if eco_realism_data else None
            
            engine.tile_mortality.build_matrices(ctx.species_batch, ctx.all_tiles, ctx.all_habitats)
            
            preliminary_critical = engine.tile_mortality.evaluate(
                ctx.tiered.critical, ctx.modifiers, ctx.niche_metrics, tier="critical",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
            preliminary_focus = engine.tile_mortality.evaluate(
                ctx.tiered.focus, ctx.modifiers, ctx.niche_metrics, tier="focus",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
            preliminary_background = engine.tile_mortality.evaluate(
                ctx.tiered.background, ctx.modifiers, ctx.niche_metrics, tier="background",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
        else:
            preliminary_critical = engine.mortality.evaluate(
                ctx.tiered.critical, ctx.modifiers, ctx.niche_metrics, tier="critical",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
            preliminary_focus = engine.mortality.evaluate(
                ctx.tiered.focus, ctx.modifiers, ctx.niche_metrics, tier="focus",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
            preliminary_background = engine.mortality.evaluate(
                ctx.tiered.background, ctx.modifiers, ctx.niche_metrics, tier="background",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
        
        ctx.preliminary_mortality = preliminary_critical + preliminary_focus + preliminary_background
        logger.info("ã€é˜¶æ®µ1ã€‘åˆæ­¥æ­»äº¡ç‡è®¡ç®—å®Œæˆï¼Œç”¨äºè¿å¾™å†³ç­–")
        
        # ä¼ é€’åœ°å—æ­»äº¡ç‡æ•°æ®ç»™è¿å¾™æœåŠ¡
        if engine._use_tile_based_mortality and ctx.all_tiles:
            engine.migration_advisor.clear_tile_mortality_cache()
            tile_mortality_data = engine.tile_mortality.get_all_species_tile_mortality()
            for lineage_code, tile_rates in tile_mortality_data.items():
                engine.migration_advisor.set_tile_mortality_data(lineage_code, tile_rates)
            logger.debug(f"[æ•°æ®ä¼ é€’] å‘è¿å¾™æœåŠ¡ä¼ é€’äº† {len(tile_mortality_data)} ä¸ªç‰©ç§çš„åœ°å—æ­»äº¡ç‡æ•°æ®")


## ã€å·²åˆ é™¤ã€‘MigrationStage - å·²è¢« TensorEcologyStage æ›¿ä»£


class FinalMortalityStage(BaseStage):
    """æœ€ç»ˆæ­»äº¡ç‡è¯„ä¼°é˜¶æ®µï¼ˆè¿å¾™åï¼‰"""
    
    def __init__(self):
        super().__init__(StageOrder.FINAL_MORTALITY.value, "æœ€ç»ˆæ­»äº¡ç‡è¯„ä¼°")
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        # é‡æ–°åˆ†æç”Ÿæ€ä½ï¼ˆå¦‚æœ‰è¿å¾™ï¼‰
        if ctx.migration_count > 0:
            logger.info("ã€é˜¶æ®µ3ã€‘é‡æ–°åˆ†æç”Ÿæ€ä½ï¼ˆè¿å¾™åï¼‰...")
            ctx.emit_event("stage", "ğŸ“Š ã€é˜¶æ®µ3ã€‘é‡æ–°åˆ†æç”Ÿæ€ä½", "ç”Ÿæ€")
            ctx.all_habitats = environment_repository.latest_habitats()
            ctx.niche_metrics = engine.niche_analyzer.analyze(ctx.species_batch, habitat_data=ctx.all_habitats)
            logger.info("ã€é˜¶æ®µ3ã€‘ç”Ÿæ€ä½é‡æ–°åˆ†æå®Œæˆ")
        
        # é‡æ–°è®¡ç®—æ­»äº¡ç‡
        logger.info("ã€é˜¶æ®µ3ã€‘é‡æ–°è®¡ç®—æ­»äº¡ç‡ï¼ˆè¿å¾™åï¼‰...")
        ctx.emit_event("stage", "ğŸ’€ ã€é˜¶æ®µ3ã€‘é‡æ–°è®¡ç®—æ­»äº¡ç‡", "ç”Ÿæ€")
        
        if engine._use_tile_based_mortality and ctx.all_tiles:
            if ctx.migration_count > 0:
                ctx.all_habitats = environment_repository.latest_habitats()
                engine.tile_mortality.build_matrices(ctx.species_batch, ctx.all_tiles, ctx.all_habitats)
            
            ctx.critical_results = engine.tile_mortality.evaluate(
                ctx.tiered.critical, ctx.modifiers, ctx.niche_metrics, tier="critical",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
            ctx.focus_results = engine.tile_mortality.evaluate(
                ctx.tiered.focus, ctx.modifiers, ctx.niche_metrics, tier="focus",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
            ctx.background_results = engine.tile_mortality.evaluate(
                ctx.tiered.background, ctx.modifiers, ctx.niche_metrics, tier="background",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes,
                turn_index=ctx.turn_index
            )
        else:
            ctx.critical_results = engine.mortality.evaluate(
                ctx.tiered.critical, ctx.modifiers, ctx.niche_metrics, tier="critical",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
            ctx.focus_results = engine.mortality.evaluate(
                ctx.tiered.focus, ctx.modifiers, ctx.niche_metrics, tier="focus",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
            ctx.background_results = engine.mortality.evaluate(
                ctx.tiered.background, ctx.modifiers, ctx.niche_metrics, tier="background",
                trophic_interactions=ctx.trophic_interactions, extinct_codes=ctx.extinct_codes
            )
        
        ctx.combined_results = ctx.critical_results + ctx.focus_results + ctx.background_results
        
        # æ—¥å¿—ï¼šå¯¹æ¯”è¿å¾™å‰åå˜åŒ–
        if ctx.migration_count > 0:
            for final_result in ctx.combined_results:
                prelim_result = next(
                    (r for r in ctx.preliminary_mortality if r.species.lineage_code == final_result.species.lineage_code),
                    None
                )
                if prelim_result and abs(final_result.death_rate - prelim_result.death_rate) > 0.05:
                    logger.info(
                        f"[æ­»äº¡ç‡å˜åŒ–] {final_result.species.common_name}: "
                        f"{prelim_result.death_rate:.1%} â†’ {final_result.death_rate:.1%}"
                    )
        
        logger.info("ã€é˜¶æ®µ3ã€‘æœ€ç»ˆæ­»äº¡ç‡è®¡ç®—å®Œæˆ")


class PopulationUpdateStage(BaseStage):
    """ç§ç¾¤æ›´æ–°é˜¶æ®µ
    
    ä½¿ç”¨ ModifierApplicator ç»Ÿä¸€åº”ç”¨ AI ä¿®æ­£ï¼š
    - mortality: æ­»äº¡ç‡ä¿®æ­£
    - reproduction_r: ç¹æ®–ç‡ä¿®æ­£ (r)
    - carrying_capacity: æ‰¿è½½åŠ›ä¿®æ­£ (K)
    """
    
    def __init__(self):
        super().__init__(StageOrder.POPULATION_UPDATE.value, "ç§ç¾¤æ›´æ–°")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},  # å¼ é‡è®¡ç®—å¯é€‰
            requires_fields={"species_batch"},
            writes_fields={"new_populations", "reproduction_results"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        from ..services.species.habitat_manager import habitat_manager
        
        logger.info("è®¡ç®—ç§ç¾¤å˜åŒ–ï¼ˆæ­»äº¡+ç¹æ®–å¹¶è¡Œï¼‰...")
        ctx.emit_event("stage", "ğŸ’€ğŸ£ è®¡ç®—ç§ç¾¤å˜åŒ–", "ç‰©ç§")
        
        # æ›´æ–°ç¯å¢ƒåŠ¨æ€ä¿®æ­£ç³»æ•°
        temp_change = ctx.modifiers.get("temperature", 0.0) if ctx.modifiers else 0.0
        sea_level_change = 0.0
        if ctx.current_map_state:
            prev_sea = getattr(ctx.current_map_state, '_prev_sea_level', ctx.current_map_state.sea_level)
            sea_level_change = ctx.current_map_state.sea_level - prev_sea
            ctx.current_map_state._prev_sea_level = ctx.current_map_state.sea_level
        engine.reproduction_service.update_environmental_modifier(temp_change, sea_level_change)
        
        # ã€v8æ–°å¢ã€‘æ›´æ–°èµ„æºç¹è£åŠ æˆï¼ˆæ­£é¢å‹åŠ›æé«˜ç¹æ®–ç‡ï¼‰
        if ctx.modifiers:
            engine.reproduction_service.update_resource_boost(ctx.modifiers)
        
        # ã€æ–°å¢v12ã€‘æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®åˆ°ç¹æ®–æœåŠ¡
        # ç”¨äºåº”ç”¨ Allee æ•ˆåº”ã€ç¯å¢ƒæ³¢åŠ¨ã€å…±ç”Ÿç­‰è¯­ä¹‰é©±åŠ¨çš„ç¹æ®–ç‡ä¿®æ­£
        eco_realism_data = ctx.plugin_data.get("ecological_realism", {})
        if eco_realism_data:
            engine.reproduction_service._ecological_realism_data = eco_realism_data
            logger.debug("[ç§ç¾¤æ›´æ–°] å·²æ³¨å…¥ç”Ÿæ€æ‹ŸçœŸæ•°æ®åˆ°ç¹æ®–æœåŠ¡")
        else:
            engine.reproduction_service._ecological_realism_data = None
        
        # è®¡ç®—æ­»äº¡ç‡æ˜ å°„ï¼Œç”¨äºæ„å»ºå­˜æ´»ç‡
        death_rates = {}
        if not ctx.combined_results:
            logger.warning("[ç§ç¾¤æ›´æ–°] combined_results ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ç¹æ®–")
        else:
            logger.info(f"[ç§ç¾¤æ›´æ–°] å¤„ç† {len(ctx.combined_results)} ä¸ªç‰©ç§çš„ç¹æ®–")
        
        for item in ctx.combined_results:
            code = item.species.lineage_code
            # ç¡®ä¿æ­»äº¡ç‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
            death_rates[code] = max(0.0, min(1.0, item.death_rate))
        
        # ã€æ–°å¢ã€‘äº²ç¼˜å·®å¼‚åŒ–ç«äº‰ä¿®æ­£ï¼šåŒå±ç«äº‰ä¼˜èƒœåŠ£æ±°ï¼ˆTaichi GPUåŠ é€Ÿï¼‰
        try:
            from ..tensor.competition import calculate_competition_tensor
            from ..core.container import get_container
            
            config_service = get_container().config_service
            ecology_config = config_service.get_ecology_balance()
            
            if ecology_config.enable_kin_competition and ctx.species_batch:
                # è·å–ç”Ÿæ€ä½é‡å æ•°æ®
                niche_overlaps = {
                    code: metrics.overlap
                    for code, metrics in ctx.niche_metrics.items()
                } if ctx.niche_metrics else None
                
                # ã€GPUåŠ é€Ÿã€‘ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ç‰©ç§çš„ç«äº‰ç»“æœ
                competition_result = calculate_competition_tensor(
                    ctx.species_batch,
                    ecology_config,
                    niche_overlaps=niche_overlaps,
                )
                
                # åº”ç”¨ç«äº‰ä¿®æ­£åˆ°æ­»äº¡ç‡ï¼ˆå‘é‡åŒ–ï¼‰
                modified_count = 0
                for i, code in enumerate(competition_result.species_codes):
                    mortality_mod = competition_result.mortality_modifiers[i]
                    fitness = competition_result.fitness_scores[i]
                    
                    if code in death_rates and abs(mortality_mod) > 0.001:
                        original = death_rates[code]
                        # mortality_modifier æ­£æ•°=ä¼˜åŠ¿ï¼ˆå‡å°‘æ­»äº¡ç‡ï¼‰ï¼Œè´Ÿæ•°=åŠ£åŠ¿ï¼ˆå¢åŠ æ­»äº¡ç‡ï¼‰
                        modified = max(0.01, min(0.95, original - mortality_mod))
                        death_rates[code] = modified
                        modified_count += 1
                        
                        if abs(original - modified) > 0.03:
                            status = "ğŸ‘‘" if mortality_mod > 0.05 else "ğŸ’€" if mortality_mod < -0.05 else "ğŸ¤"
                            logger.info(
                                f"[GPUç«äº‰] {status} {code}: "
                                f"æ­»äº¡ç‡ {original:.1%} â†’ {modified:.1%} "
                                f"(é€‚åº”åº¦={fitness:.2f}, ä¿®æ­£={mortality_mod:+.3f})"
                            )
                
                if modified_count > 0:
                    logger.info(f"[GPUç«äº‰] å·²è°ƒæ•´ {modified_count} ä¸ªç‰©ç§çš„æ­»äº¡ç‡")
        except Exception as e:
            logger.warning(f"[GPUç«äº‰] è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡: {e}", exc_info=True)
        
        # ä½¿ç”¨çœŸå®å­˜æ´»ç‡ï¼ˆ1 - death_rateï¼‰
        survival_rates = {
            code: max(0.01, 1.0 - death_rate)  # ä¿è¯æœ€ä½ 1% å­˜æ´»ç‡é¿å…é™¤é›¶
            for code, death_rate in death_rates.items()
        }
        
        # è®°å½•é«˜æ­»äº¡ç‡ç‰©ç§ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        high_mortality_species = [(code, dr) for code, dr in death_rates.items() if dr > 0.5]
        if high_mortality_species:
            logger.debug(f"[ç§ç¾¤æ›´æ–°] é«˜æ­»äº¡ç‡ç‰©ç§: {high_mortality_species[:5]}...")
        
        niche_data = {
            code: (metrics.overlap, metrics.saturation)
            for code, metrics in ctx.niche_metrics.items()
        }
        
        # ä¸´æ—¶è®¾ç½®ç§ç¾¤ä¸ºåˆå§‹å€¼
        for item in ctx.combined_results:
            item.species.morphology_stats["population"] = item.initial_population
        
        ctx.reproduction_results = engine.reproduction_service.apply_reproduction(
            ctx.species_batch, niche_data, survival_rates,
            habitat_manager=habitat_manager,
            turn_index=ctx.turn_index
        )
        
        # è®¡ç®—æœ€ç»ˆç§ç¾¤
        from ..services.species.population_calculator import PopulationCalculator
        
        for item in ctx.combined_results:
            code = item.species.lineage_code
            initial = item.initial_population
            death_rate = death_rates.get(code, item.death_rate)
            
            repro_pop = ctx.reproduction_results.get(code, initial)
            repro_gain = max(0, repro_pop - initial)
            
            survivors = int(initial * (1.0 - death_rate))
            survivor_ratio = survivors / initial if initial > 0 else 0
            
            offspring_survival = 0.8 + 0.2 * (1.0 - death_rate)
            effective_gain = int(repro_gain * survivor_ratio * offspring_survival)
            
            # åŠ¨æ€è®¡ç®—æ‰¿è½½åŠ›
            stored_k = item.species.morphology_stats.get("carrying_capacity")
            if stored_k and stored_k > 0:
                carrying_capacity = stored_k
            else:
                # åŸºäºä½“å‹åŠ¨æ€è®¡ç®—æ‰¿è½½åŠ›
                body_length = item.species.morphology_stats.get("body_length_cm", 1.0)
                body_weight = item.species.morphology_stats.get("body_weight_g")
                _, carrying_capacity = PopulationCalculator.calculate_reasonable_population(
                    body_length, body_weight
                )
            
            final_pop = survivors + effective_gain
            
            # åº”ç”¨ K é™åˆ¶ï¼šå¦‚æœè¶…è¿‡æ‰¿è½½åŠ›ï¼Œå¤šä½™ä¸ªä½“æ­»äº¡
            if final_pop > carrying_capacity:
                excess = final_pop - carrying_capacity
                final_pop = int(carrying_capacity)
                if excess > 100:
                    logger.debug(f"[æ‰¿è½½åŠ›é™åˆ¶] {item.species.common_name}: è¶…å‡º K={carrying_capacity:,.0f}ï¼Œå‡å°‘ {excess:,}")
            
            ctx.new_populations[code] = max(0, final_pop)
            
            item.births = effective_gain
            item.final_population = final_pop
            item.survivors = survivors
            item.adjusted_death_rate = death_rate
            item.adjusted_k = carrying_capacity
            
            # è®°å½•æ˜¾è‘—çš„ç§ç¾¤å˜åŒ–
            if abs(final_pop - initial) > initial * 0.1 or effective_gain > 0:
                logger.debug(
                    f"[ç§ç¾¤å˜åŒ–] {item.species.common_name}: "
                    f"{initial:,} â†’ {final_pop:,} "
                    f"(æ­»äº¡{death_rate:.1%}, å­˜æ´»{survivors:,}, ç¹æ®–+{effective_gain:,})"
                )
        
        # æ€»ç»“æ—¥å¿—
        total_births = sum(item.births for item in ctx.combined_results)
        total_deaths = sum(item.deaths for item in ctx.combined_results)
        logger.info(f"[ç§ç¾¤æ›´æ–°] å®Œæˆ: æ€»å‡ºç”Ÿ={total_births:,}, æ€»æ­»äº¡={total_deaths:,}")
        
        # ===== å¼ é‡å½±å­çŠ¶æ€å›å†™ï¼ˆä½¿ç”¨ Taichi/Numpy æ··åˆï¼‰=====
        t_state = getattr(ctx, "tensor_state", None)
        if t_state and hasattr(t_state, "pop") and hasattr(t_state, "species_map"):
            try:
                from ..tensor import get_compute
                compute = get_compute()
                
                species_map = t_state.species_map
                # ä»¥å½“å‰å¼ é‡æ€»æ•°ä¸ºåŸºå‡†ï¼ŒæŒ‰æ–°çš„ final_population é‡åˆ†é…
                final_totals = t_state.pop.sum(axis=(1, 2), dtype=np.float32)
                for item in ctx.combined_results:
                    idx = species_map.get(item.species.lineage_code)
                    if idx is not None and idx < final_totals.shape[0]:
                        final_totals[idx] = float(item.final_population)
                
                # ä½¿ç”¨ HybridCompute çš„ Taichi å†…æ ¸ï¼ˆå¯ç”¨æ—¶ï¼‰è¿›è¡Œé‡åˆ†é… + è£å‰ª
                t_state.pop = compute.redistribute_population(t_state.pop, final_totals)
                t_state.pop = compute.clip_population(t_state.pop, min_val=0)
                ctx.tensor_state = t_state
                logger.debug(f"[ç§ç¾¤æ›´æ–°] å·²å°†æ–°ç§ç¾¤å†™å›å¼ é‡å½±å­çŠ¶æ€ (åç«¯={compute.backend})")
            except Exception as e:
                logger.warning(f"[ç§ç¾¤æ›´æ–°] å¼ é‡å½±å­å›å†™å¤±è´¥: {e}")
        
        # åº”ç”¨æœ€ç»ˆç§ç¾¤
        for species in ctx.species_batch:
            if species.lineage_code in ctx.new_populations:
                species.morphology_stats["population"] = ctx.new_populations[species.lineage_code]
                species_repository.upsert(species)
        
        # æ›´æ–°ç­ç»çŠ¶æ€ï¼ˆä½¿ç”¨ ExtinctionCheckerï¼Œä¼ å…¥é…ç½®ï¼‰
        spec_config = getattr(engine.speciation, '_config', None)
        extinction_checker = ExtinctionChecker(
            species_repository=species_repository,
            turn_counter=ctx.turn_index,
            event_callback=ctx.emit_event,
            config=spec_config,  # ä¼ å…¥é…ç½®ä»¥ä½¿ç”¨ç­ç»é˜ˆå€¼
        )
        extinction_checker.check_and_apply(ctx.combined_results, ctx.new_populations)
        
        logger.info("ç§ç¾¤å˜åŒ–è®¡ç®—å®Œæˆ")
        ctx.emit_event("info", "ç§ç¾¤å˜åŒ–è®¡ç®—å®Œæˆ", "ç‰©ç§")
        
        # æ›´æ–°æ…¢æ€§è¡°é€€è¿½è¸ª
        for result in ctx.combined_results:
            old_pop = result.initial_population
            new_pop = ctx.new_populations.get(result.species.lineage_code, result.survivors)
            growth_rate = new_pop / old_pop if old_pop > 0 else 1.0
            engine.migration_advisor.update_decline_streak(
                result.species.lineage_code,
                result.death_rate,
                growth_rate
            )
        
        # ã€æ–°å¢ã€‘æ›´æ–°èµ„æºç³»ç»ŸåŠ¨æ€
        self._update_resource_dynamics(ctx, engine)
    
    def _update_resource_dynamics(self, ctx: "SimulationContext", engine: "SimulationEngine"):
        """æ›´æ–°èµ„æºç³»ç»ŸåŠ¨æ€ï¼ˆè®¡ç®—æ¶ˆè€—å¹¶è§¦å‘å†ç”Ÿï¼‰"""
        try:
            from ..repositories.environment_repository import environment_repository
            
            # ä½¿ç”¨ engine æ³¨å…¥çš„ resource_managerï¼Œé¿å…å…¨å±€å•ä¾‹
            resource_mgr = engine.resource_manager if engine else None
            if resource_mgr is None:
                logger.warning("[èµ„æºåŠ¨æ€] èµ„æºç®¡ç†å™¨æœªæ³¨å…¥ï¼Œè·³è¿‡èµ„æºæ›´æ–°")
                return
            
            # è·å–æ‰€æœ‰åœ°å—
            all_tiles = environment_repository.list_tiles()
            if not all_tiles:
                return
            
            # è®¡ç®—å„åœ°å—çš„èµ„æºæ¶ˆè€—
            consumption_by_tile: dict[int, float] = {}
            
            for result in ctx.combined_results:
                sp = result.species
                if sp.trophic_level >= 2.0:
                    continue  # åªè®¡ç®—ç”Ÿäº§è€…çš„æ¶ˆè€—ï¼ˆç”±æ¶ˆè´¹è€…æ–½åŠ ï¼‰
                
                # è·å–ç‰©ç§åˆ†å¸ƒ
                habitats = getattr(sp, 'habitats', [])
                body_weight_kg = sp.morphology_stats.get("body_weight_g", 1.0) / 1000.0
                
                for hab in habitats:
                    tile_id = getattr(hab, 'tile_id', 0)
                    pop = getattr(hab, 'population', 0)
                    
                    if tile_id > 0 and pop > 0:
                        # ç®€å•ä¼°ç®—æ¶ˆè€—ï¼ˆç”Ÿäº§è€…çš„ç”Ÿç‰©é‡ = æ¶ˆè´¹è€…çš„é£Ÿç‰©ï¼‰
                        consumption = pop * body_weight_kg * 0.1  # æ¯å›åˆæ¶ˆè€— 10%
                        consumption_by_tile[tile_id] = consumption_by_tile.get(tile_id, 0) + consumption
            
            # æ·»åŠ æ¶ˆè´¹è€…çš„çŒç‰©æ¶ˆè€—
            for result in ctx.combined_results:
                sp = result.species
                if sp.trophic_level < 2.0:
                    continue
                
                habitats = getattr(sp, 'habitats', [])
                body_weight_kg = sp.morphology_stats.get("body_weight_g", 1.0) / 1000.0
                metabolic_rate = sp.morphology_stats.get("metabolic_rate", 3.0)
                
                for hab in habitats:
                    tile_id = getattr(hab, 'tile_id', 0)
                    pop = getattr(hab, 'population', 0)
                    
                    if tile_id > 0 and pop > 0:
                        # æ¶ˆè´¹è€…çš„èƒ½é‡éœ€æ±‚
                        consumption = pop * body_weight_kg * (metabolic_rate / 10.0)
                        consumption_by_tile[tile_id] = consumption_by_tile.get(tile_id, 0) + consumption
            
            # æ›´æ–°èµ„æºåŠ¨æ€
            resource_mgr.update_resource_dynamics(all_tiles, consumption_by_tile, ctx.turn_index)
            
            # è®°å½•ç»Ÿè®¡
            stats = resource_mgr.get_stats()
            if stats.get("overgrazing_tiles", 0) > 0:
                logger.info(
                    f"[èµ„æºåŠ¨æ€] è¿‡é‡‡åœ°å—: {stats['overgrazing_tiles']}, "
                    f"å¹³å‡NPP: {stats['avg_npp']:.0f} kg"
                )
        
        except Exception as e:
            logger.warning(f"[èµ„æºåŠ¨æ€] æ›´æ–°å¤±è´¥: {e}")


# ============================================================================
# é—ä¼ ä¸æ¼”åŒ–é˜¶æ®µ
# ============================================================================

## ã€å·²åˆ é™¤ã€‘PreyDistributionStage, DispersalStage, HungerMigrationStage - å·²è¢« TensorEcologyStage æ›¿ä»£


class PostMigrationNicheStage(BaseStage):
    """è¿å¾™åç”Ÿæ€ä½é‡æ–°åˆ†æé˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.POST_MIGRATION_NICHE.value, "åè¿å¾™ç”Ÿæ€ä½")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},
            requires_fields={"species_batch"},
            writes_fields={"niche_metrics"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        if ctx.migration_count > 0:
            logger.info("é‡æ–°åˆ†æç”Ÿæ€ä½ï¼ˆè¿å¾™åï¼‰...")
            ctx.emit_event("stage", "ğŸ“Š åè¿å¾™ç”Ÿæ€ä½åˆ†æ", "ç”Ÿæ€")
            ctx.all_habitats = environment_repository.latest_habitats()
            ctx.niche_metrics = engine.niche_analyzer.analyze(
                ctx.species_batch, habitat_data=ctx.all_habitats
            )


class SpeciationDataTransferStage(BaseStage):
    """ç‰©ç§åˆ†åŒ–æ•°æ®ä¼ é€’é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.SPECIATION_DATA_TRANSFER.value, "åˆ†åŒ–æ•°æ®ä¼ é€’")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºä¾èµ–
            optional_stages={"AIçŠ¶æ€è¯„ä¼°"},  # AIçŠ¶æ€è¯„ä¼°å¯é€‰
            requires_fields={"combined_results", "modifiers"},
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        # ä¼ é€’æ•°æ®ç»™åˆ†åŒ–æœåŠ¡
        logger.debug("ä¼ é€’æ•°æ®ç»™åˆ†åŒ–æœåŠ¡...")
        
        # ã€ä¿®å¤ã€‘ä½¿ç”¨ is not None æ£€æŸ¥ï¼Œç¡®ä¿ç©ºåˆ—è¡¨ä¹Ÿèƒ½è¿›å…¥æ‰§è¡Œé€»è¾‘
        combined_results = getattr(ctx, "combined_results", None)
        if hasattr(engine, 'speciation') and combined_results is not None:
            tensor_state = getattr(ctx, "tensor_state", None)
            candidates = {}
            
            # ã€å¼ é‡ä¼˜å…ˆã€‘ç›´æ¥ä½¿ç”¨å¼ é‡çŠ¶æ€ç”Ÿæˆå€™é€‰
            # TileBasedMortalityEngine å·²è¢« TensorEcologyStage æ›¿ä»£
            if tensor_state is None:
                logger.warning("[åˆ†åŒ–æ•°æ®ä¼ é€’] ç¼ºå°‘å¼ é‡çŠ¶æ€ï¼Œåˆ†åŒ–å€™é€‰å¯èƒ½ä¸ºç©º")

            # ã€å¼ é‡åˆ†åŒ–å€™é€‰ç”Ÿæˆã€‘ä½¿ç”¨å¼ é‡æ•°æ®ç”Ÿæˆå€™é€‰
            if tensor_state is not None:
                try:
                    import numpy as np
                    from scipy.ndimage import label as scipy_label
                except Exception as e:
                    logger.warning(f"[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡å€™é€‰ç”Ÿæˆå¤±è´¥(ä¾èµ–ç¼ºå¤±): {e}")
                else:
                    death_rate_map = {
                        r.species.lineage_code: r.death_rate
                        for r in (ctx.combined_results or [])
                    }
                    tile_ids = tensor_state.masks.get("tile_ids") if hasattr(tensor_state, "masks") else None
                    if tile_ids is None:
                        logger.warning("[åˆ†åŒ–æ•°æ®ä¼ é€’] ç¼ºå°‘ tile_ids æ©ç ï¼Œæ— æ³•ç”Ÿæˆå¼ é‡å€™é€‰")
                    else:
                        pop = tensor_state.pop
                        H, W = pop.shape[1], pop.shape[2]
                        for lineage, idx in tensor_state.species_map.items():
                            layer = pop[idx]
                            presence = layer > 0
                            if not presence.any():
                                continue
                            labeled, num_regions = scipy_label(presence)
                            clusters: list[set[int]] = []
                            for reg in range(1, num_regions + 1):
                                ys, xs = np.where(labeled == reg)
                                if ys.size == 0:
                                    continue
                                cluster_ids = set(int(tile_ids[y, x]) for y, x in zip(ys, xs) if tile_ids[y, x] >= 0)
                                if cluster_ids:
                                    clusters.append(cluster_ids)

                            candidate_tiles: set[int] = set()
                            tile_populations: dict[int, float] = {}
                            tile_mortality: dict[int, float] = {}

                            ys, xs = np.where(presence)
                            for y, x in zip(ys, xs):
                                tid = int(tile_ids[y, x])
                                if tid < 0:
                                    continue
                                candidate_tiles.add(tid)
                                pop_val = float(layer[y, x])
                                tile_populations[tid] = tile_populations.get(tid, 0.0) + pop_val
                                tile_mortality[tid] = death_rate_map.get(lineage, 0.0)

                            if not candidate_tiles:
                                continue

                            total_candidate_population = int(sum(tile_populations.values()))
                            candidates[lineage] = {
                                "candidate_tiles": candidate_tiles,
                                "tile_populations": tile_populations,
                                "tile_mortality": tile_mortality,
                                "is_isolated": len(clusters) >= 2,
                                "mortality_gradient": 0.0,  # æš‚æ— é€æ ¼æ­»äº¡ç‡ï¼Œè®¾ä¸º0
                                "clusters": clusters,
                                "total_candidate_population": total_candidate_population,
                            }
                        if candidates:
                            # ç»Ÿè®¡éš”ç¦»çŠ¶æ€
                            isolated_count = sum(1 for c in candidates.values() if c.get("is_isolated", False))
                            logger.info(
                                f"[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡ç”Ÿæˆ {len(candidates)} ä¸ªåˆ†åŒ–å€™é€‰ "
                                f"(å…¶ä¸­ {isolated_count} ä¸ªåœ°ç†éš”ç¦»)"
                            )
                        else:
                            logger.warning("[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡çŠ¶æ€å­˜åœ¨ä½†æœªç”Ÿæˆä»»ä½•å€™é€‰")
            
            engine.speciation.set_speciation_candidates(candidates)
            if tensor_state is not None:
                ctx.tensor_state = tensor_state
                engine.speciation.set_tensor_state(tensor_state)
                try:
                    # ã€å¼ é‡åŒ–é‡æ„ã€‘ä½¿ç”¨ SpeciationMonitor æ£€æµ‹åˆ†åŒ–ä¿¡å·
                    from ..tensor import get_global_collector, TensorConfig
                    
                    # è·å–å¼ é‡é…ç½®
                    tensor_config = getattr(engine, "tensor_config", TensorConfig())
                    
                    if tensor_config.use_tensor_speciation:
                        collector = get_global_collector()
                        with collector.track_speciation_detection():
                            monitor = SpeciationMonitor(species_map=tensor_state.species_map)
                            triggers = monitor.get_speciation_triggers(
                                tensor_state,
                                threshold=tensor_config.divergence_threshold
                            )
                        
                        # ç»Ÿè®¡è§¦å‘ç±»å‹
                        isolation_count = sum(1 for t in triggers if t.type == "geographic_isolation")
                        divergence_count = sum(1 for t in triggers if t.type == "ecological_divergence")
                        
                        if isolation_count > 0:
                            collector.record_isolation_detection(isolation_count)
                        if divergence_count > 0:
                            collector.record_divergence_detection(divergence_count)
                        
                        ctx.tensor_trigger_codes = {t.lineage_code for t in triggers}
                        logger.info(
                            f"[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡è§¦å‘ä¿¡å·: {len(ctx.tensor_trigger_codes)} ä¸ªç‰©ç§ "
                            f"(åœ°ç†éš”ç¦»={isolation_count}, ç”Ÿæ€åˆ†æ­§={divergence_count})"
                        )
                    else:
                        ctx.tensor_trigger_codes = set()
                        logger.debug("[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡åˆ†åŒ–æ£€æµ‹å·²ç¦ç”¨")
                except Exception as e:
                    logger.warning(f"[åˆ†åŒ–æ•°æ®ä¼ é€’] å¼ é‡è§¦å‘æ£€æµ‹å¤±è´¥: {e}")
                    ctx.tensor_trigger_codes = set()
                    # è®°å½•å›é€€
                    try:
                        from ..tensor import get_global_collector
                        get_global_collector().record_ai_fallback()
                    except Exception:
                        pass


class GeneActivationStage(BaseStage):
    """åŸºå› æ¿€æ´»é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.GENE_ACTIVATION.value, "åŸºå› æ¿€æ´»")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},  # å¼ é‡è®¡ç®—å¯é€‰
            requires_fields={"species_batch", "modifiers"},
            writes_fields={"activation_events"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.info("åŸºå› æ¿€æ´»æ£€æŸ¥...")
        ctx.emit_event("stage", "ğŸ§¬ åŸºå› æ¿€æ´»", "è¿›åŒ–")
        
        try:
            # ä½¿ç”¨ batch_check æ–¹æ³•æ£€æŸ¥åŸºå› æ¿€æ´»
            ctx.activation_events = engine.gene_activation_service.batch_check(
                ctx.species_batch,
                ctx.combined_results,
                ctx.turn_index,
            )
            
            if ctx.activation_events:
                logger.info(f"[åŸºå› æ¿€æ´»] {len(ctx.activation_events)} ä¸ªç‰©ç§å‘ç”ŸåŸºå› æ¿€æ´»")
                for species in ctx.species_batch:
                    species_repository.upsert(species)
        except Exception as e:
            logger.warning(f"[åŸºå› æ¿€æ´»] å¤±è´¥: {e}")
            ctx.activation_events = []


class GeneDiversityStage(BaseStage):
    """åŸºå› å¤šæ ·æ€§åŠå¾„æ›´æ–°é˜¶æ®µ"""

    def __init__(self):
        super().__init__(StageOrder.GENE_DIVERSITY.value, "åŸºå› å¤šæ ·æ€§")

    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},  # å¼ é‡è®¡ç®—å¯é€‰
            requires_fields={"species_batch"},
            writes_fields={"gene_diversity_events"},
        )

    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository

        logger.info("æ›´æ–°åŸºå› å¤šæ ·æ€§åŠå¾„...")
        ctx.emit_event("stage", "ğŸ§¬ åŸºå› å¤šæ ·æ€§", "è¿›åŒ–")

        # æ„å»ºæ­»äº¡ç‡æ˜ å°„
        death_map = {}
        for result in ctx.combined_results:
            code = result.species.lineage_code if hasattr(result, "species") else result.get("lineage_code")
            if code:
                death_map[code] = getattr(result, "death_rate", 0.0) if not isinstance(result, dict) else result.get("death_rate", 0.0)

        events = []
        for sp in ctx.species_batch:
            pop = sp.morphology_stats.get("population", 0) or 0
            death_rate = death_map.get(sp.lineage_code, 0.0)
            try:
                change = engine.gene_diversity_service.update_per_turn(
                    sp, population=pop, death_rate=death_rate, turn_index=ctx.turn_index
                )
                if abs(change.get("delta", 0.0)) > 1e-4:
                    events.append(
                        {
                            "lineage_code": sp.lineage_code,
                            "name": sp.common_name,
                            "old": round(change["old"], 4),
                            "new": round(change["new"], 4),
                            "reason": change["reason"],
                        }
                    )
                species_repository.upsert(sp)
            except Exception as e:
                logger.warning(f"[åŸºå› å¤šæ ·æ€§] æ›´æ–° {sp.lineage_code} å¤±è´¥: {e}")

        ctx.plugin_data.setdefault("gene_diversity", {})["events"] = events


class GeneFlowStage(BaseStage):
    """åŸºå› æµåŠ¨é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.GENE_FLOW.value, "åŸºå› æµåŠ¨")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"åŸºå› æ¿€æ´»"},
            requires_fields={"species_batch"},
            writes_fields={"gene_flow_count"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        from ..repositories.genus_repository import genus_repository
        
        logger.info("åŸºå› æµåŠ¨è®¡ç®—...")
        ctx.emit_event("stage", "ğŸ”„ åŸºå› æµåŠ¨", "è¿›åŒ–")
        
        try:
            # æŒ‰å±åˆ†ç»„ç‰©ç§
            genus_groups: dict[str, list] = {}
            for species in ctx.species_batch:
                if not species.genus_code:
                    continue
                if species.genus_code not in genus_groups:
                    genus_groups[species.genus_code] = []
                genus_groups[species.genus_code].append(species)
            
            total_flow_count = 0
            for genus_code, species_list in genus_groups.items():
                if len(species_list) < 2:
                    continue
                genus = genus_repository.get_by_code(genus_code)
                if not genus:
                    continue
                flow_count = engine.gene_flow_service.apply_gene_flow(genus, species_list)
                total_flow_count += flow_count
            
            ctx.gene_flow_count = total_flow_count
            
            if ctx.gene_flow_count > 0:
                logger.info(f"[åŸºå› æµåŠ¨] å‘ç”Ÿäº† {ctx.gene_flow_count} å¯¹åŸºå› äº¤æµ")
                for species in ctx.species_batch:
                    species_repository.upsert(species)
        except Exception as e:
            logger.warning(f"[åŸºå› æµåŠ¨] å¤±è´¥: {e}")
            ctx.gene_flow_count = 0


class GeneticDriftStage(BaseStage):
    """é—ä¼ æ¼‚å˜é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.GENETIC_DRIFT.value, "é—ä¼ æ¼‚å˜")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"åŸºå› æµåŠ¨"},
            requires_fields={"species_batch"},
            writes_fields={"genetic_drift_count"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        import random
        from ..repositories.species_repository import species_repository
        
        logger.debug("é—ä¼ æ¼‚å˜æ£€æŸ¥...")
        
        ctx.genetic_drift_count = 0
        
        for sp in ctx.species_batch:
            if sp.status != "alive":
                continue
            
            population = sp.morphology_stats.get("population", 0) or 0
            
            # å°ç§ç¾¤æ›´å®¹æ˜“å‘ç”Ÿé—ä¼ æ¼‚å˜
            if population < 1000 and random.random() < 0.1:
                # éšæœºä¿®æ”¹ä¸€ä¸ªéšè—ç‰¹å¾
                if hasattr(sp, 'hidden_traits') and sp.hidden_traits:
                    trait_key = random.choice(list(sp.hidden_traits.keys()))
                    old_value = sp.hidden_traits[trait_key]
                    if isinstance(old_value, (int, float)):
                        drift = random.gauss(0, 0.1)
                        sp.hidden_traits[trait_key] = old_value * (1 + drift)
                        ctx.genetic_drift_count += 1
        
        if ctx.genetic_drift_count > 0:
            logger.info(f"[é—ä¼ æ¼‚å˜] {ctx.genetic_drift_count} ä¸ªç‰©ç§å‘ç”Ÿæ¼‚å˜")
            for sp in ctx.species_batch:
                species_repository.upsert(sp)


class AutoHybridizationStage(BaseStage):
    """è‡ªåŠ¨æ‚äº¤é˜¶æ®µ
    
    ã€å¼ é‡åŒ–ä¼˜åŒ–ã€‘ä½¿ç”¨æ‰¹é‡çŸ©é˜µè®¡ç®—æ›¿ä»£ O(nÂ²) å¾ªç¯ï¼š
    - æ‰¹é‡è®¡ç®—åŒåŸŸçŸ©é˜µï¼ˆåœ°å—é‡å ï¼‰
    - æ‰¹é‡è®¡ç®—é—ä¼ è·ç¦»çŸ©é˜µ
    - å‘é‡åŒ–ç­›é€‰æ‚äº¤å€™é€‰
    
    æ‚äº¤æ¡ä»¶ï¼š
    - ä¸¤ä¸ªç‰©ç§åˆ†å¸ƒåœ¨ç›¸åŒåœ°å—ï¼ˆåŒåŸŸï¼‰
    - é—ä¼ è·ç¦»åœ¨æ‚äº¤é˜ˆå€¼å†…ï¼ˆè¿‘ç¼˜ï¼‰
    - ç§ç¾¤è§„æ¨¡è¶³å¤Ÿå¤§
    - éšæœºæ¦‚ç‡æ£€æŸ¥ï¼ˆåŸºç¡€æ¦‚ç‡ï¼‰
    - æ‚äº¤æˆåŠŸç‡éª°ç‚¹ï¼ˆé€šè¿‡åŸºç¡€æ£€æŸ¥åè¿˜éœ€éª°ç‚¹æˆåŠŸï¼‰
    """
    
    # ã€å‚æ•°é…ç½®ã€‘ä» settings è¯»å–ï¼Œæ­¤å¤„ä»…å®šä¹‰å¤‡ç”¨é»˜è®¤å€¼
    MIN_POPULATION_FOR_HYBRIDIZATION = 500  # æœ€å°ç§ç¾¤æ‰èƒ½å‚ä¸æ‚äº¤
    SYMPATRIC_BONUS = 0.08  # å®Œå…¨åŒåŸŸæ—¶çš„æ¦‚ç‡åŠ æˆ
    
    def __init__(self):
        super().__init__(StageOrder.AUTO_HYBRIDIZATION.value, "è‡ªåŠ¨æ‚äº¤")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"é—ä¼ æ¼‚å˜"},
            requires_fields={"species_batch"},
            writes_fields={"auto_hybrids"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        import random
        from ..repositories.species_repository import species_repository
        from ..services.species.hybridization import HybridizationService
        from ..services.species.genetic_distance import GeneticDistanceCalculator
        
        logger.info("è‡ªåŠ¨æ‚äº¤æ£€æŸ¥...")
        ctx.emit_event("stage", "ğŸ§¬ è‡ªåŠ¨æ‚äº¤æ£€æŸ¥", "è¿›åŒ–")
        
        ctx.auto_hybrids = []
        
        # ä» SpeciationConfig è¯»å–æ‚äº¤å‚æ•°
        spec_config = engine.speciation._config
        base_chance = spec_config.auto_hybridization_chance
        success_rate = spec_config.hybridization_success_rate
        max_hybrids = spec_config.max_hybrids_per_turn
        min_pop_for_hybrid = spec_config.min_population_for_hybridization
        
        # è·å–æ‰€æœ‰å­˜æ´»ç‰©ç§
        alive_species = [sp for sp in ctx.species_batch if sp.status == "alive"]
        if len(alive_species) < 2:
            logger.debug("[è‡ªåŠ¨æ‚äº¤] ç‰©ç§æ•°é‡ä¸è¶³ï¼Œè·³è¿‡")
            return
        
        # åˆå§‹åŒ–æ‚äº¤æœåŠ¡
        genetic_calculator = GeneticDistanceCalculator()
        hybridization_service = HybridizationService(
            genetic_calculator, engine.router, gene_diversity_service=engine.gene_diversity_service
        )
        
        # ã€å¼ é‡åŒ–ã€‘ä½¿ç”¨æ‰¹é‡è®¡ç®—æŸ¥æ‰¾æ‚äº¤å€™é€‰
        try:
            from ..tensor.hybridization_tensor import get_hybridization_tensor_compute
            
            tensor_compute = get_hybridization_tensor_compute()
            candidates, metrics = tensor_compute.find_hybrid_candidates(
                species_list=alive_species,
                habitat_data=ctx.all_habitats,
                min_population=min_pop_for_hybrid,
                max_genetic_distance=0.70,
                min_shared_tiles=1,
                max_candidates=max_hybrids * 5,  # è·å–æ›´å¤šå€™é€‰ä»¥ä¾›éª°ç‚¹
            )
            
            if metrics.total_time_ms > 10:
                logger.info(
                    f"[è‡ªåŠ¨æ‚äº¤-å¼ é‡] ç‰©ç§={metrics.species_count}, "
                    f"å€™é€‰={metrics.candidate_pairs}, ç­›é€‰={metrics.filtered_pairs}, "
                    f"è€—æ—¶={metrics.total_time_ms:.1f}ms"
                )
            
            # æ„å»º lineage_code -> species æ˜ å°„
            code_to_species = {sp.lineage_code: sp for sp in alive_species}
            
        except ImportError:
            logger.debug("[è‡ªåŠ¨æ‚äº¤] å¼ é‡æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå¾ªç¯æ–¹æ³•")
            candidates = None
            code_to_species = None
        
        existing_codes = {sp.lineage_code for sp in ctx.species_batch}
        hybrids_created = 0
        
        # å…±äº«åˆ†åŒ–/æ‚äº¤çš„æœ¬å›åˆå­ä»£è®¡æ•°
        from collections import Counter
        turn_offspring_counts = getattr(ctx, "turn_offspring_counts", None)
        if not isinstance(turn_offspring_counts, Counter):
            turn_offspring_counts = Counter()
            for sp in ctx.species_batch:
                parent = getattr(sp, "parent_code", None)
                if parent and getattr(sp, "created_turn", -1) == ctx.turn_index:
                    turn_offspring_counts[parent] += 1
            try:
                ctx.turn_offspring_counts = turn_offspring_counts  # type: ignore[attr-defined]
            except Exception:
                pass
        max_hybrids_per_parent = spec_config.max_hybrids_per_parent_per_turn
        
        # ã€å¼ é‡åŒ–è·¯å¾„ã€‘ä½¿ç”¨é¢„ç­›é€‰çš„å€™é€‰
        if candidates is not None and code_to_species is not None:
            for candidate in candidates:
                if hybrids_created >= max_hybrids:
                    break
                
                sp1 = code_to_species.get(candidate.species1_code)
                sp2 = code_to_species.get(candidate.species2_code)
                if not sp1 or not sp2:
                    continue
                
                # äº²æœ¬æ‚äº¤å­ä»£æ•°é‡ä¸Šé™æ£€æŸ¥
                p1_code = sp1.lineage_code
                p2_code = sp2.lineage_code
                if turn_offspring_counts.get(p1_code, 0) >= max_hybrids_per_parent:
                    continue
                if turn_offspring_counts.get(p2_code, 0) >= max_hybrids_per_parent:
                    continue
                
                # è®¡ç®—æ‚äº¤æ£€æµ‹æ¦‚ç‡
                hybrid_chance = (
                    base_chance 
                    + self.SYMPATRIC_BONUS * candidate.sympatry_ratio
                    + 0.03 * candidate.fertility
                )
                
                # æ£€æµ‹æ¦‚ç‡éª°ç‚¹
                if random.random() > hybrid_chance:
                    continue
                
                # æ‚äº¤æˆåŠŸç‡éª°ç‚¹
                if random.random() > success_rate:
                    continue
                
                # ä½¿ç”¨ç²¾ç¡®çš„ can_hybridize æ£€æŸ¥ï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼‰
                can_hybrid, fertility = hybridization_service.can_hybridize(sp1, sp2)
                if not can_hybrid:
                    continue
                
                # åˆ›å»ºæ‚äº¤ç§
                hybrid = await self._create_hybrid(
                    sp1, sp2, fertility, ctx, engine, spec_config,
                    hybridization_service, species_repository, existing_codes,
                    turn_offspring_counts, max_hybrids_per_parent
                )
                
                if hybrid:
                    hybrids_created += 1
        else:
            # ã€åå¤‡è·¯å¾„ã€‘ä½¿ç”¨åŸå¾ªç¯æ–¹æ³•
            hybrids_created = await self._execute_loop_fallback(
                ctx, engine, alive_species, spec_config, hybridization_service,
                species_repository, existing_codes, turn_offspring_counts,
                max_hybrids, max_hybrids_per_parent, base_chance, success_rate, min_pop_for_hybrid
            )
        
        if ctx.auto_hybrids:
            logger.info(f"[è‡ªåŠ¨æ‚äº¤] æœ¬å›åˆäº§ç”Ÿäº† {len(ctx.auto_hybrids)} ä¸ªæ‚äº¤ç§")
            ctx.species_batch.extend(ctx.auto_hybrids)
            
            # ã€æè¿°å¢å¼ºã€‘ä¸ºæ‚äº¤ç§è¿›è¡ŒLLMæè¿°å¢å¼º
            await self._enhance_hybrid_descriptions(ctx, engine, species_repository)
    
    async def _create_hybrid(
        self, sp1, sp2, fertility, ctx, engine, spec_config,
        hybridization_service, species_repository, existing_codes,
        turn_offspring_counts, max_hybrids_per_parent
    ):
        """åˆ›å»ºæ‚äº¤ç§"""
        logger.info(
            f"[è‡ªåŠ¨æ‚äº¤] å°è¯•æ‚äº¤: {sp1.common_name} Ã— {sp2.common_name} "
            f"(å¯è‚²æ€§={fertility:.1%})"
        )
        
        hybrid = hybridization_service.create_hybrid(
            sp1, sp2, ctx.turn_index, 
            existing_codes=existing_codes
        )
        
        if hybrid:
            pop1 = sp1.morphology_stats.get("population", 0) or 0
            pop2 = sp2.morphology_stats.get("population", 0) or 0
            
            contribution_rate = 0.10
            pop1_contribution = int(pop1 * contribution_rate * fertility)
            pop2_contribution = int(pop2 * contribution_rate * fertility)
            hybrid_pop = pop1_contribution + pop2_contribution
            
            min_hybrid_pop = spec_config.min_offspring_population
            if hybrid_pop < min_hybrid_pop:
                logger.debug(
                    f"[è‡ªåŠ¨æ‚äº¤] ç§ç¾¤ä¸è¶³æ”¾å¼ƒ: {sp1.common_name} Ã— {sp2.common_name} "
                    f"(è®¡ç®—ç§ç¾¤={hybrid_pop:,} < é—¨æ§›={min_hybrid_pop:,})"
                )
                return None
            
            hybrid.morphology_stats["population"] = hybrid_pop
            sp1.morphology_stats["population"] = max(100, pop1 - pop1_contribution)
            sp2.morphology_stats["population"] = max(100, pop2 - pop2_contribution)
            
            species_repository.upsert(hybrid)
            species_repository.upsert(sp1)
            species_repository.upsert(sp2)
            
            ctx.auto_hybrids.append(hybrid)
            existing_codes.add(hybrid.lineage_code)
            
            p1_code = sp1.lineage_code
            p2_code = sp2.lineage_code
            turn_offspring_counts[p1_code] = turn_offspring_counts.get(p1_code, 0) + 1
            turn_offspring_counts[p2_code] = turn_offspring_counts.get(p2_code, 0) + 1
            try:
                ctx.turn_offspring_counts = turn_offspring_counts
            except Exception:
                pass
            
            logger.info(
                f"[è‡ªåŠ¨æ‚äº¤] æˆåŠŸ: {hybrid.common_name} "
                f"(ç§ç¾¤={hybrid_pop:,}, å¯è‚²æ€§={fertility:.1%})"
            )
            ctx.emit_event("speciation", f"ğŸ§¬ æ‚äº¤è¯ç”Ÿ: {hybrid.common_name}", "è¿›åŒ–")
            
            return hybrid
        return None
    
    async def _execute_loop_fallback(
        self, ctx, engine, alive_species, spec_config, hybridization_service,
        species_repository, existing_codes, turn_offspring_counts,
        max_hybrids, max_hybrids_per_parent, base_chance, success_rate, min_pop_for_hybrid
    ):
        """åå¤‡æ–¹æ³•ï¼šä½¿ç”¨åŸå¾ªç¯éå†ç‰©ç§å¯¹"""
        import random
        
        candidate_species = [
            sp for sp in alive_species
            if (sp.morphology_stats.get("population", 0) or 0) >= min_pop_for_hybrid
        ]
        
        if len(candidate_species) < 2:
            return 0
        
        # æ„å»ºæ –æ¯åœ°æ˜ å°„
        id_to_code: dict[int, str] = {}
        for sp in ctx.species_batch:
            if sp.id is not None:
                id_to_code[sp.id] = sp.lineage_code
        
        species_tiles: dict[str, set[int]] = {}
        if ctx.all_habitats:
            for hab in ctx.all_habitats:
                code = id_to_code.get(hab.species_id)
                if code:
                    if code not in species_tiles:
                        species_tiles[code] = set()
                    species_tiles[code].add(hab.tile_id)
        
        hybrids_created = 0
        checked_pairs = set()
        
        for i, sp1 in enumerate(candidate_species):
            if hybrids_created >= max_hybrids:
                break
                
            for sp2 in candidate_species[i+1:]:
                if hybrids_created >= max_hybrids:
                    break
                
                pair_key = tuple(sorted([sp1.lineage_code, sp2.lineage_code]))
                if pair_key in checked_pairs:
                    continue
                checked_pairs.add(pair_key)
                
                tiles1 = species_tiles.get(sp1.lineage_code, set())
                tiles2 = species_tiles.get(sp2.lineage_code, set())
                shared_tiles = tiles1 & tiles2
                
                if not shared_tiles:
                    continue
                
                can_hybrid, fertility = hybridization_service.can_hybridize(sp1, sp2)
                if not can_hybrid:
                    continue
                
                p1_code = sp1.lineage_code
                p2_code = sp2.lineage_code
                if turn_offspring_counts.get(p1_code, 0) >= max_hybrids_per_parent:
                    continue
                if turn_offspring_counts.get(p2_code, 0) >= max_hybrids_per_parent:
                    continue
                
                sympatry_ratio = len(shared_tiles) / max(1, min(len(tiles1), len(tiles2)))
                hybrid_chance = base_chance + self.SYMPATRIC_BONUS * sympatry_ratio + 0.03 * fertility
                
                if random.random() > hybrid_chance:
                    continue
                
                if random.random() > success_rate:
                    continue
                
                hybrid = await self._create_hybrid(
                    sp1, sp2, fertility, ctx, engine, spec_config,
                    hybridization_service, species_repository, existing_codes,
                    turn_offspring_counts, max_hybrids_per_parent
                )
                
                if hybrid:
                    hybrids_created += 1
        
        return hybrids_created
    
    async def _enhance_hybrid_descriptions(self, ctx, engine, species_repository):
        """ä¸ºæ‚äº¤ç§è¿›è¡Œæè¿°å¢å¼º"""
        try:
            from ..services.species.description_enhancer import DescriptionEnhancerService
            
            enhancer = DescriptionEnhancerService(engine.router)
            
            for hybrid in ctx.auto_hybrids:
                hybrid_parents = getattr(hybrid, 'hybrid_parent_codes', [])
                parent1 = None
                parent2 = None
                if hybrid_parents and len(hybrid_parents) >= 2:
                    for sp in ctx.species_batch:
                        if sp.lineage_code == hybrid_parents[0]:
                            parent1 = sp
                        elif sp.lineage_code == hybrid_parents[1]:
                            parent2 = sp
                
                enhancer.queue_for_enhancement(
                    species=hybrid,
                    parent=parent1,
                    parent2=parent2,
                    is_hybrid=True,
                    fertility=getattr(hybrid, 'hybrid_fertility', 1.0),
                )
            
            enhanced_list = await enhancer.process_queue_async(
                max_items=10,
                timeout_per_item=25.0,
            )
            
            if enhanced_list:
                for enhanced_sp in enhanced_list:
                    species_repository.upsert(enhanced_sp)
                logger.info(f"[æ‚äº¤æè¿°å¢å¼º] å®Œæˆ {len(enhanced_list)}/{len(ctx.auto_hybrids)} ä¸ªæ‚äº¤ç§æè¿°å¢å¼º")
        except Exception as e:
            logger.warning(f"[æ‚äº¤æè¿°å¢å¼º] å¤„ç†å¤±è´¥ï¼ˆä¸å½±å“æ‚äº¤ç»“æœï¼‰: {e}")


class SubspeciesPromotionStage(BaseStage):
    """äºšç§æ™‹å‡é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.SUBSPECIES_PROMOTION.value, "äºšç§æ™‹å‡")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"é—ä¼ æ¼‚å˜", "è‡ªåŠ¨æ‚äº¤"},
            requires_fields={"species_batch"},
            writes_fields={"promotion_count"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.debug("äºšç§æ™‹å‡æ£€æŸ¥...")
        
        ctx.promotion_count = 0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äºšç§éœ€è¦æ™‹å‡ä¸ºç‹¬ç«‹ç‰©ç§
        for sp in ctx.species_batch:
            if sp.status != "alive":
                continue
            
            # æ£€æŸ¥äºšç§éš”ç¦»æ—¶é—´å’Œé—ä¼ åˆ†åŒ–ç¨‹åº¦
            subspecies = getattr(sp, 'subspecies', [])
            for sub in subspecies:
                isolation_turns = ctx.turn_index - sub.get('created_turn', 0)
                genetic_distance = sub.get('genetic_distance', 0)
                
                # é•¿æœŸéš”ç¦»çš„äºšç§å¯èƒ½æ™‹å‡
                if isolation_turns > 50 and genetic_distance > 0.3:
                    ctx.promotion_count += 1
        
        if ctx.promotion_count > 0:
            logger.info(f"[äºšç§æ™‹å‡] {ctx.promotion_count} ä¸ªäºšç§å¯èƒ½æ™‹å‡")




class SpeciationStage(BaseStage):
    """ç‰©ç§åˆ†åŒ–é˜¶æ®µ
    
    å¤„ç†ç‰©ç§åˆ†åŒ–äº‹ä»¶ï¼Œåˆ›å»ºæ–°ç‰©ç§ã€‚
    
    ä½¿ç”¨ ModifierApplicator åº”ç”¨åˆ†åŒ–ä¿¡å·ä¿®æ­£ï¼š
    - speciation_signal > 0.7: é«˜æ¦‚ç‡è§¦å‘åˆ†åŒ–
    - speciation_signal < 0.3: ä½æ¦‚ç‡åˆ†åŒ–
    """
    
    def __init__(self):
        super().__init__(StageOrder.SPECIATION.value, "ç‰©ç§åˆ†åŒ–", is_async=True)
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},  # å¼ é‡è®¡ç®—å¯é€‰
            requires_fields={"species_batch", "modifiers"},
            writes_fields={"branching_events"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        logger.info("å¼€å§‹ç‰©ç§åˆ†åŒ–...")
        ctx.emit_event("stage", "ğŸŒ± ç‰©ç§åˆ†åŒ–", "åˆ†åŒ–")
        
        try:
            # ã€å¼ é‡åŒ–é‡æ„ã€‘åˆ†åŒ–å€™é€‰ä¸»è¦æ¥è‡ªå¼ é‡ç³»ç»Ÿ
            speciation_candidates = set()
            evolution_directions = {}
            
            # 1. è·å–å¼ é‡è§¦å‘ä¿¡å·ï¼ˆä¸»è¦æ¥æºï¼‰
            tensor_trigger_codes = getattr(ctx, "tensor_trigger_codes", set()) or set()
            if tensor_trigger_codes:
                speciation_candidates |= tensor_trigger_codes
                logger.info(f"[åˆ†åŒ–] å¼ é‡ç³»ç»Ÿè¯†åˆ« {len(tensor_trigger_codes)} ä¸ªåˆ†åŒ–å€™é€‰")
                ctx.emit_event(
                    "info",
                    f"ğŸ§¬ å¼ é‡ç³»ç»Ÿè¯†åˆ« {len(tensor_trigger_codes)} ä¸ªåˆ†åŒ–å€™é€‰",
                    "åˆ†åŒ–"
                )
            
            # 2. å¦‚æœæ²¡æœ‰å¼ é‡è§¦å‘ï¼ŒåŸºäºè§„åˆ™æ£€æµ‹
            if not speciation_candidates:
                # åŸºäºæ­»äº¡ç‡å’Œç§ç¾¤çš„è§„åˆ™æ£€æµ‹
                for result in ctx.critical_results + ctx.focus_results:
                    pop = result.species.morphology_stats.get("population", 0)
                    death_rate = result.death_rate
                    # é«˜ç§ç¾¤ + ä¸­ç­‰æ­»äº¡ç‡ = åˆ†åŒ–å€™é€‰
                    if pop >= 5000 and 0.1 <= death_rate <= 0.5:
                        speciation_candidates.add(result.species.lineage_code)
                        logger.debug(f"[åˆ†åŒ–å€™é€‰] è§„åˆ™æ£€æµ‹: {result.species.common_name}")
                
                if speciation_candidates:
                    logger.info(f"[åˆ†åŒ–] è§„åˆ™ç³»ç»Ÿè¯†åˆ« {len(speciation_candidates)} ä¸ªåˆ†åŒ–å€™é€‰")
            
            # Embedding é›†æˆï¼šè·å–æ¼”åŒ–æç¤º
            if engine._use_embedding_integration and hasattr(engine, 'embedding_integration'):
                try:
                    evolution_hints = {}
                    pressure_vectors = engine.embedding_integration.map_pressures_to_vectors(ctx.modifiers)
                    
                    for result in ctx.critical_results + ctx.focus_results:
                        sp = result.species
                        pop = sp.morphology_stats.get("population", 0)
                        # å¯¹é«˜åˆ†åŒ–ä¿¡å·ç‰©ç§é™ä½ç§ç¾¤è¦æ±‚
                        min_pop = 3000 if sp.lineage_code in speciation_candidates else 5000
                        if pop > min_pop and 0.05 < result.death_rate < 0.5:
                            hint = engine.embedding_integration.get_evolution_hints(sp, pressure_vectors)
                            if hint:
                                evolution_hints[sp.lineage_code] = hint
                    
                    # åˆå¹¶ AI æ¼”åŒ–æ–¹å‘
                    for code, directions in evolution_directions.items():
                        if code not in evolution_hints:
                            evolution_hints[code] = {}
                        evolution_hints[code]["ai_directions"] = directions
                    
                    if evolution_hints:
                        engine.speciation.set_evolution_hints(evolution_hints)
                        logger.info(f"[Embedding] ä¸º {len(evolution_hints)} ä¸ªç‰©ç§æä¾›æ¼”åŒ–æç¤º")
                except Exception as e:
                    logger.warning(f"[Embedding] è·å–æ¼”åŒ–æç¤ºå¤±è´¥: {e}")
            
            # ã€å…³é”®ä¿®å¤ã€‘æ‰§è¡Œåˆ†åŒ–æ—¶ä½¿ç”¨ combined_results è€Œä¸æ˜¯åªç”¨ critical + focus
            # åŸä»£ç åªå¤„ç† critical_results + focus_resultsï¼Œå¯¼è‡´å¤§é‡ background ç‰©ç§æ— æ³•åˆ†åŒ–
            # ç‰©ç§åˆ†åŒ–ä¸éœ€è¦ AI åšç­›é€‰å†³ç­–ï¼Œåªéœ€è¦ AI ç”Ÿæˆæ–°ç‰©ç§æè¿°ï¼Œæ‰€ä»¥å¤„ç†å…¨éƒ¨ç‰©ç§æ˜¯å®‰å…¨çš„
            
            # ã€å¿ƒè·³å›è°ƒã€‘å°† ctx.emit_event åŒ…è£…ä¸º stream_callbackï¼Œç”¨äº AI è°ƒç”¨å¿ƒè·³
            # ã€ä¿®å¤ã€‘æ¥æ”¶ event_type å’Œ categoryï¼Œæ­£ç¡®ä¼ é€’äº‹ä»¶ç±»å‹
            def speciation_stream_callback(event_type: str, message: str, category: str = "AI"):
                ctx.emit_event(event_type, message, category)
            
            ctx.branching_events = await asyncio.wait_for(
                engine.speciation.process_async(
                    mortality_results=ctx.combined_results,  # ã€ä¿®å¤ã€‘ä½¿ç”¨æ‰€æœ‰ç‰©ç§
                    existing_codes={s.lineage_code for s in ctx.species_batch},
                    average_pressure=sum(ctx.modifiers.values()) / (len(ctx.modifiers) or 1),
                    turn_index=ctx.turn_index,
                    map_changes=ctx.map_changes,
                    major_events=ctx.major_events,
                    pressures=ctx.pressures,
                    trophic_interactions=ctx.trophic_interactions,
                    stream_callback=speciation_stream_callback,  # ã€æ–°å¢ã€‘ä¼ é€’å¿ƒè·³å›è°ƒ
                    speciation_candidates=speciation_candidates if speciation_candidates else None,
                ),
                timeout=600
            )
            
            if ctx.branching_events:
                logger.info(f"[ç‰©ç§åˆ†åŒ–] å‘ç”Ÿäº† {len(ctx.branching_events)} æ¬¡åˆ†åŒ–")
                
                # å°†æ–°ç‰©ç§åŠ å…¥åˆ—è¡¨
                from ..repositories.species_repository import species_repository
                all_species_updated = species_repository.list_species()
                new_species = [
                    sp for sp in all_species_updated
                    if sp.status == "alive" and sp.lineage_code not in {s.lineage_code for s in ctx.species_batch}
                ]
                
                for sp in new_species:
                    ctx.emit_event("speciation", f"ğŸŒ± æ–°ç‰©ç§: {sp.common_name}", "åˆ†åŒ–")
                    
                    # Embedding è®°å½•
                    if engine._use_embedding_integration and hasattr(engine, 'embedding_integration'):
                        try:
                            parent_sp = next(
                                (s for s in ctx.species_batch if s.lineage_code == sp.parent_code),
                                None
                            )
                            if parent_sp:
                                engine.embedding_integration.on_speciation(
                                    ctx.turn_index, parent_sp, [sp], trigger_reason="ç¯å¢ƒå‹åŠ›åˆ†åŒ–"
                                )
                        except Exception as e:
                            logger.warning(f"[Embedding] è®°å½•åˆ†åŒ–äº‹ä»¶å¤±è´¥: {e}")
                
                ctx.species_batch.extend(new_species)
                logger.info(f"æ–°ç‰©ç§å·²åŠ å…¥ï¼Œæ€»æ•°: {len(ctx.species_batch)}")
                
                # ã€æ–°å¢ã€‘åˆ†åŒ–åè§¦å‘å±€éƒ¨é£Ÿç‰©ç½‘æ›´æ–°
                # å°†æ–°ç”Ÿäº§è€…/åˆçº§æ¶ˆè´¹è€…ç«‹å³é›†æˆåˆ°é£Ÿç‰©ç½‘ï¼Œä¸ç­‰ä¸‹ä¸€å›åˆå…¨é‡æ‰«æ
                if new_species:
                    self._integrate_new_species_to_food_web(
                        new_species, ctx, engine, species_repository
                    )
        
        except asyncio.TimeoutError:
            logger.warning("[ç‰©ç§åˆ†åŒ–] è¶…æ—¶")
            ctx.branching_events = []
        except Exception as e:
            logger.error(f"[ç‰©ç§åˆ†åŒ–] å¤±è´¥: {e}")
            ctx.branching_events = []
    
    def _integrate_new_species_to_food_web(
        self,
        new_species: list,
        ctx: "SimulationContext",
        engine: "SimulationEngine",
        species_repository,
    ) -> None:
        """å°†æ–°ç‰©ç§ç«‹å³é›†æˆåˆ°é£Ÿç‰©ç½‘
        
        ã€è§¦å‘æ¡ä»¶ã€‘
        - æ–°ç‰©ç§æ˜¯ T1/T2ï¼ˆç”Ÿäº§è€…æˆ–åˆçº§æ¶ˆè´¹è€…ï¼‰
        - æˆ–æ–°ç‰©ç§æ˜¯æ¶ˆè´¹è€…ä½†æ²¡æœ‰åˆ†é…çŒç‰©
        """
        from ..services.species.food_web_manager import FoodWebChange
        
        try:
            all_species = species_repository.list_species()
            alive_species = [s for s in all_species if s.status == "alive"]
            
            # æ„å»ºåœ°å—-ç‰©ç§æ˜ å°„
            species_tiles = {}
            tile_species_map = {}
            for sp in alive_species:
                tiles = set(sp.morphology_stats.get("tile_ids", []))
                if tiles:
                    species_tiles[sp.lineage_code] = tiles
                    for tid in tiles:
                        if tid not in tile_species_map:
                            tile_species_map[tid] = set()
                        tile_species_map[tid].add(sp.lineage_code)
            
            changes = []
            
            for sp in new_species:
                # ä¸ºæ–°æ¶ˆè´¹è€…åˆ†é…çŒç‰©
                if sp.trophic_level >= 2.0 and not sp.prey_species:
                    prey_changes = engine.food_web_manager.integrate_new_species(
                        sp, alive_species, species_repository
                    )
                    changes.extend(prey_changes)
                
                # å°†æ–° T1/T2 ç‰©ç§æ·»åŠ åˆ°ç°æœ‰æ¶ˆè´¹è€…çš„çŒç‰©åˆ—è¡¨
                if sp.trophic_level < 3.0:
                    # æ‰¾åˆ°çŒç‰©ä¸è¶³çš„æ¶ˆè´¹è€…
                    for consumer in alive_species:
                        if consumer.lineage_code == sp.lineage_code:
                            continue
                        if consumer.trophic_level < 2.0:
                            continue
                        
                        # æ£€æŸ¥è¥å…»çº§åŒ¹é…
                        trophic_diff = consumer.trophic_level - sp.trophic_level
                        if not (0.5 <= trophic_diff <= 1.5):
                            continue
                        
                        current_prey = consumer.prey_species or []
                        alive_codes = {s.lineage_code for s in alive_species}
                        valid_prey = [c for c in current_prey if c in alive_codes]
                        
                        # åªå¯¹çŒç‰©ä¸è¶³çš„æ¶ˆè´¹è€…æ·»åŠ 
                        if len(valid_prey) <= 3 and sp.lineage_code not in current_prey:
                            # æ£€æŸ¥æ –æ¯åœ°/ç“¦ç‰‡é‡å 
                            consumer_tiles = species_tiles.get(consumer.lineage_code, set())
                            sp_tiles = species_tiles.get(sp.lineage_code, set())
                            
                            if consumer_tiles and sp_tiles and not (consumer_tiles & sp_tiles):
                                continue  # æ— é‡å ï¼Œè·³è¿‡
                            
                            # æ·»åŠ ä¸ºæ–°çŒç‰©
                            new_prey_list = valid_prey + [sp.lineage_code]
                            consumer.prey_species = new_prey_list
                            species_repository.upsert(consumer)
                            
                            changes.append(FoodWebChange(
                                species_code=consumer.lineage_code,
                                species_name=consumer.common_name,
                                change_type="prey_added",
                                details=f"åˆ†åŒ–åæ·»åŠ æ–°çŒç‰© {sp.common_name}",
                                old_prey=current_prey,
                                new_prey=new_prey_list,
                            ))
            
            if changes:
                logger.info(f"[åˆ†åŒ–-é£Ÿç‰©ç½‘] æ›´æ–°äº† {len(changes)} æ¡é£Ÿç‰©å…³ç³»")
                ctx.emit_event("info", f"ğŸ•¸ï¸ åˆ†åŒ–åæ›´æ–° {len(changes)} æ¡é£Ÿç‰©é“¾", "ç”Ÿæ€")
        
        except Exception as e:
            logger.warning(f"[åˆ†åŒ–-é£Ÿç‰©ç½‘] é›†æˆå¤±è´¥: {e}")


class BackgroundManagementStage(BaseStage):
    """èƒŒæ™¯ç‰©ç§ç®¡ç†é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.BACKGROUND_MANAGEMENT.value, "èƒŒæ™¯ç‰©ç§ç®¡ç†")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ç‰©ç§åˆ†åŒ–", "ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},  # å¯é€‰é˜¶æ®µ
            requires_fields=set(),  # å­—æ®µå¯èƒ½æœªåˆå§‹åŒ–
            writes_fields={"background_summary", "mass_extinction", "reemergence_events"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.info("èƒŒæ™¯ç‰©ç§ç®¡ç†...")
        ctx.emit_event("stage", "ğŸŒ¾ èƒŒæ™¯ç‰©ç§ç®¡ç†", "ç”Ÿæ€")
        
        ctx.background_summary = engine.background_manager.summarize(ctx.background_results)
        ctx.mass_extinction = engine.background_manager.detect_mass_extinction(ctx.combined_results)
        
        if ctx.mass_extinction:
            promoted = engine.background_manager.promote_candidates(ctx.background_results)
            if promoted:
                # ä½¿ç”¨ ReemergenceService è¯„ä¼°ç‰©ç§é‡ç°
                reemergence_service = ReemergenceService(species_repository)
                ctx.reemergence_events = reemergence_service.evaluate_reemergence(promoted, ctx.modifiers)
                if ctx.reemergence_events:
                    ctx.emit_event("info", f"å¤§ç­ç»åé‡ç°: {len(ctx.reemergence_events)} ä¸ªç‰©ç§", "ç”Ÿæ€")


class BuildReportStage(BaseStage):
    """æ„å»ºæŠ¥å‘Šé˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.BUILD_REPORT.value, "æ„å»ºæŠ¥å‘Š", is_async=True)
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–ï¼ŒæŒ‰ order æ‰§è¡Œ
            optional_stages={"èƒŒæ™¯ç‰©ç§ç®¡ç†", "ç»Ÿä¸€å¼ é‡ç”Ÿæ€è®¡ç®—"},
            requires_fields={"pressures"},
            writes_fields={"report", "species_snapshots"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        from ..schemas.responses import TurnReport
        
        # ã€ä¼˜åŒ–ã€‘æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆæŠ¥å‘Šï¼ˆè‡ªåŠ¨è¿‡å›åˆ/éšæœºå›åˆå¯è·³è¿‡ï¼‰
        skip_report = False
        if ctx.command and hasattr(ctx.command, 'auto_reports'):
            skip_report = not ctx.command.auto_reports
        
        if skip_report:
            logger.info(f"[æŠ¥å‘Š] å›åˆ {ctx.turn_index} è·³è¿‡æŠ¥å‘Šç”Ÿæˆ (auto_reports=False)")
            # åˆ›å»ºä¸€ä¸ªæœ€ç®€æŠ¥å‘Šï¼Œä½†ä»åŒ…å«ç‰©ç§æ•°æ®
            species_data = self._build_simple_species_data(ctx)
            ctx.report = TurnReport(
                turn_index=ctx.turn_index,
                narrative=f"å›åˆ {ctx.turn_index} å®Œæˆã€‚",
                pressures_summary="",
                species=species_data,
                branching_events=ctx.branching_events or [],
                major_events=ctx.major_events or [],
                gene_diversity_events=ctx.plugin_data.get("gene_diversity", {}).get("events", []),
            )
            return
        
        logger.info("æ„å»ºå›åˆæŠ¥å‘Š...")
        ctx.emit_event("stage", "ğŸ“ æ„å»ºå›åˆæŠ¥å‘Š", "æŠ¥å‘Š")
        
        try:
            # å®šä¹‰æµå¼å›è°ƒ
            async def on_narrative_chunk(chunk: str):
                ctx.emit_event("narrative_token", chunk, "æŠ¥å‘Š")
            
            # ä½¿ç”¨ TurnReportService æ„å»ºæŠ¥å‘Š
            turn_report_service = TurnReportService(
                report_builder=engine.report_builder,
                environment_repository=environment_repository,
                trophic_service=engine.trophic_service,
                emit_event_fn=ctx.emit_event,
            )
            
            # åˆå¹¶ species_batchï¼ˆå­˜æ´»ï¼‰å’Œå·²ç­ç»ç‰©ç§ï¼Œæ„æˆå®Œæ•´çš„ç‰©ç§åˆ—è¡¨
            # ctx.species_batch åœ¨ SpeciationStage åå·²åŒ…å«æ–°åˆ†åŒ–çš„ç‰©ç§
            all_species_for_report = list(ctx.species_batch) if ctx.species_batch else []
            # æ·»åŠ ç­ç»ç‰©ç§ï¼ˆä» all_species ä¸­ç­›é€‰ï¼‰
            if ctx.all_species:
                extinct_species = [sp for sp in ctx.all_species if sp.status == "extinct"]
                all_species_for_report.extend(extinct_species)
            
            ctx.report = await asyncio.wait_for(
                turn_report_service.build_report(
                    turn_index=ctx.turn_index,
                    mortality_results=ctx.combined_results,
                    pressures=ctx.pressures,
                    branching_events=ctx.branching_events,
                    background_summary=ctx.background_summary,
                    reemergence_events=ctx.reemergence_events,
                    major_events=ctx.major_events,
                    map_changes=ctx.map_changes,
                    migration_events=ctx.migration_events,
                    stream_callback=on_narrative_chunk,
                    all_species=all_species_for_report,
                    ecological_realism_data=ctx.plugin_data.get("ecological_realism"),  # ã€æ–°å¢ã€‘
                    gene_diversity_events=ctx.plugin_data.get("gene_diversity", {}).get("events", []),
                ),
                timeout=90
            )
            ctx.emit_event("stage", "âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ", "æŠ¥å‘Š")
        
        except asyncio.TimeoutError:
            logger.warning("[æŠ¥å‘Šç”Ÿæˆ] è¶…æ—¶ï¼Œä½¿ç”¨ç®€å•æ¨¡å¼")
            ctx.emit_event("warning", "â±ï¸ AI è¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿæ¨¡å¼", "æŠ¥å‘Š")
            
            # æ„å»ºç®€å•æŠ¥å‘Šï¼Œä½†ä»åŒ…å«ç‰©ç§æ•°æ®
            from ..schemas.responses import TurnReport
            species_data = self._build_simple_species_data(ctx)
            ctx.report = TurnReport(
                turn_index=ctx.turn_index,
                narrative="æœ¬å›åˆæŠ¥å‘Šç”Ÿæˆè¶…æ—¶ã€‚",
                pressures_summary=str(ctx.modifiers),
                species=species_data,
                branching_events=ctx.branching_events,
                major_events=ctx.major_events,
            )
        except Exception as e:
            logger.error(f"[æŠ¥å‘Šç”Ÿæˆ] å¤±è´¥: {e}")
    
    def _build_simple_species_data(self, ctx: SimulationContext) -> list:
        """ä»ä¸Šä¸‹æ–‡ä¸­æ„å»ºç®€å•çš„ç‰©ç§å¿«ç…§åˆ—è¡¨ï¼ˆç”¨äºè·³è¿‡æŠ¥å‘Šæˆ–è¶…æ—¶æ—¶ï¼‰"""
        from ..schemas.responses import SpeciesSnapshot
        
        species_data = []
        
        # è®¡ç®—æ€»ç§ç¾¤ï¼ˆç”¨äºè®¡ç®— population_shareï¼‰
        total_population = 0
        if ctx.combined_results:
            for result in ctx.combined_results:
                if hasattr(result, 'final_population'):
                    total_population += result.final_population or 0
                elif hasattr(result, 'species'):
                    total_population += result.species.morphology_stats.get("population", 0)
        
        if total_population == 0:
            total_population = 1  # é¿å…é™¤é›¶
        
        # ä» combined_results æ„å»ºç‰©ç§å¿«ç…§
        if ctx.combined_results:
            for result in ctx.combined_results:
                if hasattr(result, 'species') and hasattr(result, 'death_rate'):
                    species = result.species
                    pop = getattr(result, 'final_population', 0) or species.morphology_stats.get("population", 0)
                    initial_pop = getattr(result, 'initial_population', 0) or pop
                    deaths = getattr(result, 'deaths', 0)
                    births = getattr(result, 'births', 0)
                    
                    species_data.append(SpeciesSnapshot(
                        lineage_code=species.lineage_code,
                        latin_name=species.latin_name,
                        common_name=species.common_name,
                        population=pop,
                        population_share=pop / total_population,
                        deaths=deaths,
                        death_rate=result.death_rate,
                        net_change_rate=(pop - initial_pop) / max(1, initial_pop),
                        ecological_role=self._get_ecological_role(species.trophic_level),
                        status=species.status,
                        notes=[],
                        is_background=getattr(result, 'is_background', False),
                        trophic_level=species.trophic_level,
                        initial_population=initial_pop,
                        births=births,
                        survivors=getattr(result, 'survivors', 0),
                        # ã€æ–°å¢ã€‘åŸºå› æ•°æ®ï¼ˆç”¨äºåŸºå› åº“æ˜¾ç¤ºï¼‰
                        abstract_traits=getattr(species, 'abstract_traits', None),
                        organs=getattr(species, 'organs', None),
                        capabilities=getattr(species, 'capabilities', None),
                    ))
        
        # å¦‚æœæ²¡æœ‰ combined_resultsï¼Œå°è¯•ä» species_batch æ„å»º
        if not species_data and ctx.species_batch:
            for species in ctx.species_batch:
                pop = species.morphology_stats.get("population", 0)
                species_data.append(SpeciesSnapshot(
                    lineage_code=species.lineage_code,
                    latin_name=species.latin_name,
                    common_name=species.common_name,
                    population=pop,
                    population_share=pop / total_population if total_population > 0 else 0,
                    deaths=0,
                    death_rate=0.0,
                    net_change_rate=0.0,
                    ecological_role=self._get_ecological_role(species.trophic_level),
                    status=species.status,
                    notes=[],
                    is_background=species.is_background,
                    trophic_level=species.trophic_level,
                    initial_population=pop,
                    births=0,
                    survivors=pop,
                    # ã€æ–°å¢ã€‘åŸºå› æ•°æ®ï¼ˆç”¨äºåŸºå› åº“æ˜¾ç¤ºï¼‰
                    abstract_traits=getattr(species, 'abstract_traits', None),
                    organs=getattr(species, 'organs', None),
                    capabilities=getattr(species, 'capabilities', None),
                ))
        
        # æ·»åŠ ç­ç»ç‰©ç§
        if ctx.all_species:
            existing_codes = {s.lineage_code for s in species_data}
            for species in ctx.all_species:
                if species.status == "extinct" and species.lineage_code not in existing_codes:
                    species_data.append(SpeciesSnapshot(
                        lineage_code=species.lineage_code,
                        latin_name=species.latin_name,
                        common_name=species.common_name,
                        population=0,
                        population_share=0,
                        deaths=0,
                        death_rate=1.0,
                        net_change_rate=-1.0,
                        ecological_role=self._get_ecological_role(species.trophic_level),
                        status="extinct",
                        notes=[],
                        is_background=species.is_background,
                        trophic_level=species.trophic_level,
                        initial_population=0,
                        births=0,
                        survivors=0,
                        # ã€æ–°å¢ã€‘åŸºå› æ•°æ®ï¼ˆç”¨äºåŸºå› åº“æ˜¾ç¤ºï¼‰
                        abstract_traits=getattr(species, 'abstract_traits', None),
                        organs=getattr(species, 'organs', None),
                        capabilities=getattr(species, 'capabilities', None),
                    ))
        
        logger.info(f"[æŠ¥å‘Š] ç®€å•æ¨¡å¼æ„å»ºç‰©ç§æ•°æ®: {len(species_data)} ä¸ªç‰©ç§")
        return species_data
    
    def _get_ecological_role(self, trophic_level: float) -> str:
        """æ ¹æ®è¥å…»çº§è·å–ç”Ÿæ€è§’è‰²"""
        if trophic_level <= 1.0:
            return "producer"
        elif trophic_level <= 2.0:
            return "primary_consumer"
        elif trophic_level <= 3.0:
            return "secondary_consumer"
        else:
            return "apex_predator"


class SaveMapSnapshotStage(BaseStage):
    """ä¿å­˜åœ°å›¾å¿«ç…§é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.SAVE_MAP_SNAPSHOT.value, "ä¿å­˜åœ°å›¾å¿«ç…§")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–ï¼ŒæŒ‰ order æ‰§è¡Œ
            optional_stages={"æ„å»ºæŠ¥å‘Š"},
            requires_fields={"species_batch"},
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.info("ä¿å­˜åœ°å›¾æ –æ¯åœ°å¿«ç…§...")
        ctx.emit_event("stage", "ğŸ’¾ ä¿å­˜åœ°å›¾å¿«ç…§", "ç³»ç»Ÿ")
        
        all_species_final = species_repository.list_species()
        
        # è·å–åœ°å—çº§å­˜æ´»æ•°æ®
        tile_survivors = {}
        if engine._use_tile_based_mortality and ctx.all_tiles:
            tile_survivors = engine.tile_mortality.get_all_species_tile_survivors()
        
        reproduction_gains = {}
        
        engine.map_manager.snapshot_habitats(
            all_species_final,
            turn_index=ctx.turn_index,
            tile_survivors=tile_survivors,
            reproduction_gains=reproduction_gains
        )


class VegetationCoverStage(BaseStage):
    """æ¤è¢«è¦†ç›–æ›´æ–°é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.VEGETATION_COVER.value, "æ¤è¢«è¦†ç›–æ›´æ–°")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ä¿å­˜åœ°å›¾å¿«ç…§"},
            requires_fields=set(),
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        from ..repositories.species_repository import species_repository
        from ..services.geo.vegetation_cover import vegetation_cover_service
        
        logger.info("æ›´æ–°æ¤è¢«è¦†ç›–...")
        ctx.emit_event("stage", "ğŸŒ¿ æ›´æ–°æ¤è¢«è¦†ç›–", "ç¯å¢ƒ")
        
        try:
            tiles = environment_repository.list_tiles()
            habitats = environment_repository.latest_habitats()
            all_species = species_repository.list_species()
            species_map = {sp.id: sp for sp in all_species if sp.id}
            
            updated_tiles = vegetation_cover_service.update_vegetation_cover(
                tiles, habitats, species_map
            )
            if updated_tiles:
                environment_repository.upsert_tiles(updated_tiles)
                logger.info(f"[æ¤è¢«è¦†ç›–] æ›´æ–°äº† {len(updated_tiles)} ä¸ªåœ°å—")
        except Exception as e:
            logger.warning(f"[æ¤è¢«è¦†ç›–] æ›´æ–°å¤±è´¥: {e}")


class SavePopulationSnapshotStage(BaseStage):
    """ä¿å­˜ç§ç¾¤å¿«ç…§é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.SAVE_POPULATION_SNAPSHOT.value, "ä¿å­˜ç§ç¾¤å¿«ç…§")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"å¼ é‡çŠ¶æ€åŒæ­¥"},  # å¯é€‰ï¼šç­‰å¾…å¼ é‡åŒæ­¥å®Œæˆ
            requires_fields=set(),
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.species_repository import species_repository
        
        logger.info("ä¿å­˜äººå£å¿«ç…§...")
        ctx.emit_event("stage", "ğŸ’¾ ä¿å­˜ç§ç¾¤å¿«ç…§", "ç³»ç»Ÿ")
        
        # ä½¿ç”¨ PopulationSnapshotService ä¿å­˜å¿«ç…§
        all_species_final = species_repository.list_species()
        snapshot_service = PopulationSnapshotService(species_repository)
        snapshot_service.save_snapshots(all_species_final, ctx.turn_index)


class EmbeddingStage(BaseStage):
    """Embedding é›†æˆé˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.EMBEDDING_INTEGRATION.value, "Embeddingé›†æˆ")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ä¿å­˜ç§ç¾¤å¿«ç…§"},
            requires_fields={"species_batch"},
            writes_fields={"embedding_turn_data"},
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        if not engine._use_embedding_integration:
            logger.debug("[Embedding] Embedding é›†æˆå·²ç¦ç”¨")
            return
        
        logger.info("Embedding é›†æˆé’©å­...")
        ctx.emit_event("stage", "ğŸ”— Embedding é›†æˆ", "AI")
        
        try:
            # è®°å½•ç­ç»äº‹ä»¶
            for result in ctx.combined_results:
                if result.species.status == "extinct":
                    cause = ""
                    if hasattr(result, 'death_causes') and result.death_causes:
                        cause = result.death_causes
                    elif result.species.morphology_stats.get("extinction_reason"):
                        cause = result.species.morphology_stats["extinction_reason"]
                    else:
                        cause = f"æ­»äº¡ç‡{result.death_rate:.1%}"
                    
                    engine.embedding_integration.on_extinction(
                        ctx.turn_index, result.species, cause=cause
                    )
            
            # å›åˆç»“æŸé’©å­
            ctx.embedding_turn_data = engine.embedding_integration.on_turn_end(
                ctx.turn_index, ctx.species_batch
            )
            
            if ctx.embedding_turn_data.get("taxonomy"):
                logger.info("[Embedding] åˆ†ç±»æ ‘å·²æ›´æ–°")
        
        except Exception as e:
            logger.warning(f"[Embedding] å¤±è´¥: {e}")
            ctx.embedding_turn_data = {}


class EmbeddingPluginsStage(BaseStage):
    """Embedding æ‰©å±•æ’ä»¶é˜¶æ®µ
    
    åŠ è½½å¹¶æ‰§è¡Œæ‰€æœ‰å¯ç”¨çš„ Embedding æ‰©å±•æ’ä»¶ï¼š
    - behavior_strategy: è¡Œä¸ºç­–ç•¥å‘é‡
    - food_web: ç”Ÿæ€ç½‘ç»œå‘é‡
    - tile_biome: åŒºåŸŸåœ°å—å‘é‡
    - prompt_optimizer: Prompt ä¼˜åŒ–
    - evolution_space: æ¼”åŒ–ç©ºé—´
    - ancestry: è¡€ç»Ÿå‹ç¼©
    
    æ¯ä¸ªæ’ä»¶åœ¨å›åˆç»“æŸæ—¶æ›´æ–°å…¶å‘é‡ç´¢å¼•ã€‚
    é…ç½®ä» stage_config.yaml åŠ è½½ã€‚
    """
    
    def __init__(self):
        super().__init__(StageOrder.EMBEDDING_PLUGINS.value, "Embeddingæ‰©å±•æ’ä»¶")
        self._manager = None
        self._initialized = False
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"Embeddingé›†æˆ", "ä¿å­˜ç§ç¾¤å¿«ç…§"},
            requires_fields=set(),
            writes_fields=set(),  # æ’ä»¶æ•°æ®å­˜å‚¨åœ¨å„è‡ªçš„ç´¢å¼•ä¸­
        )
    
    def _ensure_manager(self, engine: 'SimulationEngine') -> bool:
        """ç¡®ä¿æ’ä»¶ç®¡ç†å™¨å·²åˆå§‹åŒ–"""
        if self._initialized:
            return self._manager is not None
        
        self._initialized = True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ embedding_service
        embedding_service = getattr(engine, 'embedding_service', None)
        if not embedding_service:
            logger.debug("[EmbeddingPlugins] EmbeddingService ä¸å¯ç”¨ï¼Œè·³è¿‡")
            return False
        
        try:
            from ..services.embedding_plugins import (
                EmbeddingPluginManager,
                load_all_plugins
            )
            from pathlib import Path
            
            # åŠ è½½æ‰€æœ‰å†…ç½®æ’ä»¶
            loaded = load_all_plugins()
            if loaded:
                logger.info(f"[EmbeddingPlugins] å·²æ³¨å†Œæ’ä»¶: {loaded}")
            
            # è·å–å½“å‰æ¨¡å¼ï¼ˆä¼˜å…ˆä½¿ç”¨ _pipeline_modeï¼‰
            mode = getattr(engine, '_pipeline_mode', None) or \
                   getattr(engine, '_stage_mode', None) or 'full'
            
            # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
            config_path = Path(__file__).parent / "stage_config.yaml"
            
            # åˆ›å»ºç®¡ç†å™¨å¹¶åŠ è½½å¯ç”¨çš„æ’ä»¶
            self._manager = EmbeddingPluginManager(
                embedding_service, 
                mode=mode,
                config_path=config_path
            )
            count = self._manager.load_plugins()
            
            if count > 0:
                logger.info(f"[EmbeddingPlugins] å·²åŠ è½½ {count} ä¸ªæ’ä»¶ (æ¨¡å¼: {mode})")
                return True
            else:
                logger.debug(f"[EmbeddingPlugins] æ¨¡å¼ {mode} æ²¡æœ‰å¯ç”¨çš„æ’ä»¶")
                return False
                
        except Exception as e:
            logger.warning(f"[EmbeddingPlugins] åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        if not self._ensure_manager(engine):
            return
        
        logger.debug("[EmbeddingPlugins] æ‰§è¡Œæ’ä»¶å›åˆç»“æŸé’©å­...")
        ctx.emit_event("stage", "ğŸ”Œ Embedding æ‰©å±•æ’ä»¶", "AI")
        
        # ã€å¼ é‡é›†æˆã€‘é‡ç½®å¹¶åŒæ­¥å¼ é‡æ¡¥æ¥å™¨
        self._sync_tensor_bridge(ctx)
        
        try:
            # è°ƒç”¨æ‰€æœ‰æ’ä»¶çš„ on_turn_end
            self._manager.on_turn_end(ctx)
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self._manager.get_all_stats()
            plugin_count = stats.get("manager", {}).get("plugin_count", 0)
            
            if plugin_count > 0:
                logger.info(f"[EmbeddingPlugins] {plugin_count} ä¸ªæ’ä»¶å·²æ›´æ–°")
            
            # ã€å¼ é‡é›†æˆã€‘è®°å½•æ¡¥æ¥å™¨ç»Ÿè®¡
            self._log_tensor_bridge_stats()
                
        except Exception as e:
            logger.warning(f"[EmbeddingPlugins] æ‰§è¡Œå¤±è´¥: {e}")
    
    def _sync_tensor_bridge(self, ctx: SimulationContext) -> None:
        """åŒæ­¥å¼ é‡æ¡¥æ¥å™¨"""
        try:
            from ..services.embedding_plugins.tensor_bridge import reset_tensor_bridge, get_tensor_bridge
            
            # é‡ç½®å¹¶åŒæ­¥
            reset_tensor_bridge()
            bridge = get_tensor_bridge()
            
            if ctx.tensor_state is not None:
                success = bridge.sync_from_context(ctx)
                if success:
                    logger.debug("[EmbeddingPlugins] å¼ é‡æ¡¥æ¥å™¨å·²åŒæ­¥")
                else:
                    logger.debug("[EmbeddingPlugins] å¼ é‡æ¡¥æ¥å™¨åŒæ­¥å¤±è´¥ï¼ˆæ— æ•°æ®ï¼‰")
        except Exception as e:
            logger.debug(f"[EmbeddingPlugins] å¼ é‡æ¡¥æ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _log_tensor_bridge_stats(self) -> None:
        """è®°å½•å¼ é‡æ¡¥æ¥å™¨ç»Ÿè®¡"""
        try:
            from ..services.embedding_plugins.tensor_bridge import get_tensor_bridge
            bridge = get_tensor_bridge()
            if bridge.is_synced:
                summary = bridge.get_summary()
                logger.debug(
                    f"[EmbeddingPlugins] å¼ é‡æ¡¥æ¥: "
                    f"ç‰©ç§={summary['species_count']}, "
                    f"åœ°å—={summary['tile_count']}, "
                    f"åˆ†åŒ–ä¿¡å·={summary['speciation_signals']}"
                )
        except Exception:
            pass


class SaveHistoryStage(BaseStage):
    """ä¿å­˜å†å²è®°å½•é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.SAVE_HISTORY.value, "ä¿å­˜å†å²è®°å½•")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ä¿å­˜ç§ç¾¤å¿«ç…§", "Embeddingé›†æˆ"},
            requires_fields=set(),  # report å¯èƒ½ä¸å­˜åœ¨
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.history_repository import history_repository
        from ..models.history import TurnLog
        
        logger.info("ä¿å­˜å†å²è®°å½•...")
        ctx.emit_event("stage", "ğŸ’¾ ä¿å­˜å†å²è®°å½•", "ç³»ç»Ÿ")
        
        if not ctx.report:
            logger.warning("[å†å²è®°å½•] æ²¡æœ‰æŠ¥å‘Šå¯ä¿å­˜")
            return
        
        record_data = ctx.report.model_dump(mode="json")
        # å®‰å…¨è·å– embedding_turn_dataï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
        embedding_turn_data = getattr(ctx, 'embedding_turn_data', None)
        if embedding_turn_data:
            record_data["embedding_integration"] = {
                "has_taxonomy": "taxonomy" in embedding_turn_data,
                "has_narrative": "narrative" in embedding_turn_data,
            }
        
        history_repository.log_turn(
            TurnLog(
                turn_index=ctx.report.turn_index,
                pressures_summary=ctx.report.pressures_summary,
                narrative=ctx.report.narrative,
                record_data=record_data,
            )
        )


class ExportDataStage(BaseStage):
    """å¯¼å‡ºæ•°æ®é˜¶æ®µ"""
    
    def __init__(self):
        super().__init__(StageOrder.EXPORT_DATA.value, "å¯¼å‡ºæ•°æ®")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"ä¿å­˜å†å²è®°å½•"},
            requires_fields=set(),
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        logger.info("å¯¼å‡ºæ•°æ®...")
        ctx.emit_event("stage", "ğŸ’¾ å¯¼å‡ºæ•°æ®", "ç³»ç»Ÿ")
        
        if ctx.report:
            engine.exporter.export_turn(ctx.report, ctx.species_batch)


class FinalizeStage(BaseStage):
    """æœ€ç»ˆåŒ–é˜¶æ®µ
    
    æ›´æ–°å›åˆè®¡æ•°å™¨ï¼Œå®Œæˆå›åˆã€‚
    """
    
    def __init__(self):
        super().__init__(StageOrder.FINALIZE.value, "æœ€ç»ˆåŒ–")
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"å¯¼å‡ºæ•°æ®", "ä¿å­˜å†å²è®°å½•"},
            requires_fields=set(),
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        logger.info("æœ€ç»ˆåŒ–å›åˆ...")
        
        # æ›´æ–° MapState.turn_index - ä¿å­˜ä¸‹ä¸€ä¸ªå›åˆçš„ç´¢å¼•ï¼Œè¿™æ ·å¼•æ“æ¢å¤æ—¶å¯ä»¥ç›´æ¥ä½¿ç”¨
        # ã€å…³é”®ä¿®å¤ã€‘ä¿å­˜ ctx.turn_index + 1ï¼Œé¿å… hot reload åå›åˆæ•°é‡å¤
        map_state = environment_repository.get_state()
        if map_state:
            map_state.turn_index = ctx.turn_index + 1  # ä¿å­˜ä¸‹ä¸€ä¸ªå›åˆæ•°
            environment_repository.save_state(map_state)
            logger.debug(f"[FinalizeStage] å·²ä¿å­˜ä¸‹ä¸€å›åˆç´¢å¼•: {map_state.turn_index}")
        
        ctx.emit_event("turn_complete", f"âœ… å›åˆ {ctx.turn_index} å®Œæˆ", "ç³»ç»Ÿ")
        logger.info(f"å›åˆ {ctx.turn_index} å®Œæˆ")


class DatabaseMaintenanceStage(BaseStage):
    """æ•°æ®åº“è‡ªåŠ¨ç»´æŠ¤é˜¶æ®µ
    
    ã€æ€§èƒ½ä¼˜åŒ–ã€‘å®šæœŸæ‰§è¡Œæ•°æ®åº“ç»´æŠ¤ä»»åŠ¡ï¼š
    1. æ¸…ç†å†å²æ –æ¯åœ°æ•°æ®ï¼ˆæ§åˆ¶æ•°æ®åº“è†¨èƒ€ï¼‰
    2. æ‰§è¡Œ VACUUMï¼ˆå›æ”¶ç©ºé—´ï¼‰
    3. ç¡®ä¿ç´¢å¼•å­˜åœ¨ï¼ˆåŠ é€ŸæŸ¥è¯¢ï¼‰
    
    é…ç½®å‚æ•°ï¼š
    - maintenance_interval: ç»´æŠ¤é—´éš”ï¼ˆæ¯ N å›åˆæ‰§è¡Œä¸€æ¬¡ï¼‰
    - keep_habitat_turns: ä¿ç•™æœ€è¿‘å¤šå°‘å›åˆçš„æ –æ¯åœ°æ•°æ®
    - enable_vacuum: æ˜¯å¦æ‰§è¡Œ VACUUMï¼ˆè¾ƒæ…¢ä½†å¯å›æ”¶ç©ºé—´ï¼‰
    """
    
    # é»˜è®¤é…ç½®
    DEFAULT_MAINTENANCE_INTERVAL = 10  # æ¯ 10 å›åˆæ‰§è¡Œä¸€æ¬¡
    DEFAULT_KEEP_HABITAT_TURNS = 5     # ä¿ç•™æœ€è¿‘ 5 å›åˆçš„æ –æ¯åœ°æ•°æ®
    DEFAULT_ENABLE_VACUUM = False      # é»˜è®¤ä¸æ‰§è¡Œ VACUUMï¼ˆè¾ƒæ…¢ï¼‰
    
    def __init__(
        self,
        maintenance_interval: int | None = None,
        keep_habitat_turns: int | None = None,
        enable_vacuum: bool | None = None,
    ):
        super().__init__(StageOrder.DATABASE_MAINTENANCE.value, "æ•°æ®åº“ç»´æŠ¤")
        self.maintenance_interval = maintenance_interval or self.DEFAULT_MAINTENANCE_INTERVAL
        self.keep_habitat_turns = keep_habitat_turns or self.DEFAULT_KEEP_HABITAT_TURNS
        self.enable_vacuum = enable_vacuum if enable_vacuum is not None else self.DEFAULT_ENABLE_VACUUM
    
    def get_dependency(self) -> StageDependency:
        return StageDependency(
            requires_stages=set(),  # æ— å¼ºåˆ¶ä¾èµ–
            optional_stages={"æœ€ç»ˆåŒ–"},
            requires_fields=set(),
            writes_fields=set(),
        )
    
    async def execute(self, ctx: SimulationContext, engine: SimulationEngine) -> None:
        from ..repositories.environment_repository import environment_repository
        
        turn = ctx.turn_index
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œç»´æŠ¤
        if turn == 0 or turn % self.maintenance_interval != 0:
            return
        
        logger.info(f"[æ•°æ®åº“ç»´æŠ¤] å¼€å§‹è‡ªåŠ¨ç»´æŠ¤ (å›åˆ {turn})...")
        
        maintenance_results = {
            "turn": turn,
            "cleanup_deleted": 0,
            "indexes_created": 0,
            "vacuum_executed": False,
        }
        
        try:
            # 1. æ¸…ç†å†å²æ –æ¯åœ°æ•°æ®
            if hasattr(environment_repository, 'cleanup_old_habitats'):
                deleted = environment_repository.cleanup_old_habitats(self.keep_habitat_turns)
                maintenance_results["cleanup_deleted"] = deleted
                if deleted > 0:
                    logger.info(f"[æ•°æ®åº“ç»´æŠ¤] æ¸…ç†å†å²æ –æ¯åœ°: åˆ é™¤ {deleted} æ¡ (ä¿ç•™æœ€è¿‘ {self.keep_habitat_turns} å›åˆ)")
            
            # 2. ç¡®ä¿ç´¢å¼•å­˜åœ¨
            if hasattr(environment_repository, 'ensure_indexes'):
                results = environment_repository.ensure_indexes()
                created = sum(1 for v in results.values() if v)
                maintenance_results["indexes_created"] = created
                if created > 0:
                    logger.info(f"[æ•°æ®åº“ç»´æŠ¤] åˆ›å»ºç´¢å¼•: {created} ä¸ª")
            
            # 3. å¯é€‰ï¼šæ‰§è¡Œ VACUUMï¼ˆæ¯ 50 å›åˆæ‰§è¡Œä¸€æ¬¡ï¼Œå› ä¸ºè¾ƒæ…¢ï¼‰
            if self.enable_vacuum and turn % 50 == 0:
                if hasattr(environment_repository, 'optimize_database'):
                    opt_result = environment_repository.optimize_database()
                    maintenance_results["vacuum_executed"] = opt_result.get("vacuum", False)
                    if opt_result.get("vacuum"):
                        logger.info("[æ•°æ®åº“ç»´æŠ¤] VACUUM å®Œæˆ")
            
            # è®°å½•ç»´æŠ¤å®Œæˆ
            total_actions = (
                (1 if maintenance_results["cleanup_deleted"] > 0 else 0) +
                (1 if maintenance_results["indexes_created"] > 0 else 0) +
                (1 if maintenance_results["vacuum_executed"] else 0)
            )
            
            if total_actions > 0:
                ctx.emit_event(
                    "maintenance", 
                    f"ğŸ”§ æ•°æ®åº“ç»´æŠ¤å®Œæˆ (æ¸…ç† {maintenance_results['cleanup_deleted']} æ¡è®°å½•)",
                    "ç³»ç»Ÿ"
                )
            
        except Exception as e:
            logger.warning(f"[æ•°æ®åº“ç»´æŠ¤] è‡ªåŠ¨ç»´æŠ¤å¤±è´¥: {e}")
            # ç»´æŠ¤å¤±è´¥ä¸åº”å½±å“æ¸¸æˆè¿›ç¨‹ï¼Œåªè®°å½•è­¦å‘Š


# ============================================================================
# é˜¶æ®µæ³¨å†Œè¡¨
# ============================================================================

def get_default_stages(include_tensor: bool = True) -> list[BaseStage]:
    """è¿”å›é»˜è®¤é˜¶æ®µåˆ—è¡¨ï¼šæ ¸å¿ƒæ•°æ®é˜¶æ®µ + GPUå¼ é‡è®¡ç®—é˜¶æ®µ
    
    æ ¸å¿ƒé˜¶æ®µè´Ÿè´£æ•°æ®åŠ è½½ã€æŒä¹…åŒ–ã€æŠ¥å‘Šç”Ÿæˆã€‚
    GPUå¼ é‡é˜¶æ®µè´Ÿè´£æ­»äº¡ç‡ã€è¿å¾™ã€ç¹æ®–ç­‰ç”Ÿæ€è®¡ç®—ã€‚
    """
    from .tensor_stages import get_tensor_stages
    
    # æ ¸å¿ƒæ•°æ®é˜¶æ®µ
    core_stages = [
        InitStage(),
        ParsePressuresStage(),
        MapEvolutionStage(),
        FetchSpeciesStage(),
        FoodWebStage(),
        TieringAndNicheStage(),
        GeneDiversityStage(),
        GeneActivationStage(),
        SpeciationDataTransferStage(),  # å¿…é¡»åœ¨ SpeciationStage ä¹‹å‰æ‰§è¡Œ
        SpeciationStage(),
        BackgroundManagementStage(),
        BuildReportStage(),
        SaveMapSnapshotStage(),
        SavePopulationSnapshotStage(),
        SaveHistoryStage(),
    ]
    
    # GPUå¼ é‡è®¡ç®—é˜¶æ®µ
    if include_tensor:
        core_stages.extend(get_tensor_stages())
    
    return sorted(core_stages, key=lambda s: s.order)

